[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spatial Data Analysis",
    "section": "",
    "text": "Introduction\nThis course materials are designed for a 1-day workshop on spatial data analysis. Rüttenauer (2024) provides a handbook chapter accompanying these workshop materials.\nIn recent years, more and more spatial data has become available, providing the possibility to combine otherwise unrelated data, such as social, economic, and environmental data. This also opens up the possibility of analysing spatial patterns and processes (e.g., spillover effects or diffusion).\nMany social science research questions are spatially dependent such as voting outcomes, housing prices, labour markets, protest behaviour, or migration decisions. Observing an event in one region or neighbourhood increases the likelihood that we observe similar processes in proximate areas. As Tobler’s first law of geography puts it: “Everything is related to everything else, but near things are more related than distant things”. This dependence can stem from spatial contagion, spatial spillovers, or common confounders. Therefore, basic assumptions of standard regression models are violated when analysing spatial data. However, more importantly, spatial processes are interesting for their own sake. Spatial regression models can detect spatial dependence and explicitly model spatial relations, identifying spatial clustering, spillovers or diffusion processes.\nThe main objective of the course is the theoretical understanding and practical application of spatial regression models. This course will first give an overview on how to perform common spatial operations using spatial information, such as aggregating spatial units, calculating distances, merging spatial data as well as visualizing them. The course will further focus on the analysis of geographic data and the application of spatial regression techniques to model and analyze spatial processes, and furthermore, the course addresses several methods for defining spatial relationships, detecting and diagnosing spatial dependence and autocorrelation. Finally, we will discuss various spatial regression techniques to model processes, clarify the assumptions of these models, and show how they differ in their applications and interpretations.\nThe field has developed very quickly over the past few years, and R now provides a rich set of packages for various spatial data operations. For a more in-depth introduction into spatial data analysis in R, have a look into the materials references below.\nThe material introduces the use of geographical information to connect and analyze different spatial data sources very briefly. This introduction is limited to the fundamentals of using geographical information in R. Stefan Jünger & Anne-Kathrin Stroppe have provided a comprehensive GESIS workshop on geospatial techniques in R. The focus of this workshop will be on techniques for spatial data analysis, such as spatial regression models."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Spatial Data Analysis",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime\nSession\n\n\n\n\n09:00 – 09:30\nRefresher on R for spatial data\n\n\n09:30 – 11:00\nSpatial Relationships (W) and Spatial Dependence\n\n\n11:15 – 12:00\nPractical exercise\n\n\nLunch break\n\n\n\n13:00 – 14:30\nSpatial Regression Models (SLX, Error, lagged DV)\n\n\n14:45 – 16:00\nInterpreting Results: Spatial Impacts\n\n\n16:15 – 18:00\nPractical exercise"
  },
  {
    "objectID": "index.html#some-useful-packages",
    "href": "index.html#some-useful-packages",
    "title": "Spatial Data Analysis",
    "section": "Some useful packages",
    "text": "Some useful packages\nBy now, R provides a lot of functionalities for GIS applications and spatial econometrics, and further extensions. There are lots of packages providing a huge variety of spatial functionalities and methods (see e.g. R. Bivand, Millo, and Piras 2021). Important packages for fundamental spatial operations are:\n\nSpatial data workhorses: sf (Pebesma 2018) and terra\nVisualization: mapview (Appelhans et al. 2021) and tmap (Tennekes 2018)\nSpatial weights and other relations: spdep (R. S. Bivand and Rudel 2018)\nSpatial interpolation and kriging: gstat (Gräler, Pebesma, and Heuvelink 2016)\nSpatial regression models: spatialreg and sphet (R. Bivand and Piras 2015)\nThe packages have constantly developed over the past years, and older packages such as rgdal, rgeos, and sp are currently retiring (Blog post)"
  },
  {
    "objectID": "index.html#further-readings",
    "href": "index.html#further-readings",
    "title": "Spatial Data Analysis",
    "section": "Further Readings",
    "text": "Further Readings\n\nGreat up-to-date introduction to spatial R: Lovelace, Nowosad, and Muenchow (2019), updated version available online\nGreat open-science book on Spatial Data Science Pebesma and Bivand (2023)\nComprehensive introduction to spatial econometrics: LeSage and Pace (2009)\nRelative intuitive introduction to spatial econometrics: Ward and Gleditsch (2008)\nArticle-length introductions to spatial econometrics: Elhorst (2012), Halleck Vega and Elhorst (2015), LeSage (2014), Rüttenauer (2024), and Rüttenauer (2022)"
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "Spatial Data Analysis",
    "section": "Course materials",
    "text": "Course materials\n\nI highly recommend the great Introduction to Geospatial Techniques for Social Scientists in R including, see Stefan Jünger & Anne-Kathrin Stroppe’s GESIS workshop materials. Nice materials on GIS, spatial operations and spatial data visualisation!\nFor those looking for a more in-depth introduction, I highly recommend Roger Bivand’s course on Spatial Data Analysis: Youtube recordings, Course Materials\nI’ve learned most of what I know about spatial econometrics from Scott J. Cook and his workshop on Spatial Econometrics at the Essex Summer school.\n\n\n\n\n\n\n\nAppelhans, Tim, Florian Detsch, Chritoph Reudenbach, and Stefan Woellauer. 2021. “Mapview: Interactive Viewing of Spatial Data in R.”\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos: Interface to Geometry Engine - Open Source (’GEOS’).”\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A Review of Software for Spatial Econometrics in R.” Mathematics 9 (11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBivand, Roger, and Gianfranco Piras. 2015. “Comparing Implementations of Estimation Methods for Spatial Econometrics.” Journal of Statistical Software 63 (18): 1–36. https://doi.org/10.18637/jss.v063.i18.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods, and Inferences.” Journal of Geographical Systems 14 (1): 5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\nGräler, Benedikt, Edzer Pebesma, and Gerard Heuvelink. 2016. “Spatio-Temporal Interpolation Using Gstat.” The R Journal 8 (1): 204–18.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. Chapman & Hall/CRC the R Series. Boca Raton: Chapman & Hall/CRC.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “Spatial Data Analysis.” arXiv. https://arxiv.org/abs/2402.09895.\n\n\nTennekes, Martijn. 2018. “Tmap : Thematic Maps in R.” Journal of Statistical Software 84 (6). https://doi.org/10.18637/jss.v084.i06.\n\n\nWard, Michael Don, and Kristian Skrede Gleditsch. 2008. Spatial Regression Models. Vol. 155. Quantitative Applications in the Social Sciences. Thousand Oaks: Sage."
  },
  {
    "objectID": "01_refresher_short.html#packages",
    "href": "01_refresher_short.html#packages",
    "title": "\n1  Refresher\n",
    "section": "\n1.1 Packages",
    "text": "1.1 Packages\nPlease make sure that you have installed the following packages:\n\npks &lt;- c(\"dplyr\",\n\"gstat\",\n\"mapview\",\n\"nngeo\",\n\"nomisr\",\n\"osmdata\",\n\"rnaturalearth\",\n\"sf\",\n\"spatialreg\",\n\"spdep\",\n\"texreg\",\n\"tidyr\",\n\"tmap\",\n\"viridisLite\")\n\nThe most important package is sf: Simple Features for R. users are strongly encouraged to install the sf binary packages from CRAN. If that does not work, please have a look at the installation instructions. It requires software packages GEOS, GDAL and PROJ."
  },
  {
    "objectID": "01_refresher_short.html#coordinates",
    "href": "01_refresher_short.html#coordinates",
    "title": "\n1  Refresher\n",
    "section": "\n1.2 Coordinates",
    "text": "1.2 Coordinates\nIn general, spatial data is structured like conventional/tidy data (e.g. data.frames, matrices), but has one additional dimension: every observation is linked to some sort of geo-spatial information. Most common types of spatial information are:\n\nPoints (one coordinate pair)\nLines (two coordinate pairs)\nPolygons (at least three coordinate pairs)\nRegular grids (one coordinate pair for centroid + raster / grid size)\n\n\n1.2.1 Coordinate reference system (CRS)\nIn its raw form, a pair of coordinates consists of two numerical values. For instance, the pair c(51.752595, -1.262801) describes the location of Nuffield College in Oxford (one point). The fist number represents the latitude (north-south direction), the second number is the longitude (west-east direction), both are in decimal degrees.\n\n\nFigure: Latitude and longitude, Source: Wikipedia\n\nHowever, we need to specify a reference point for latitudes and longitudes (in the Figure above: equator and Greenwich). For instance, the pair of coordinates above comes from Google Maps which returns GPS coordinates in ‘WGS 84’ (EPSG:4326).\n\n# Coordinate pairs of two locations\ncoords1 &lt;- c(51.752595, -1.262801)\ncoords2 &lt;- c(51.753237, -1.253904)\ncoords &lt;- rbind(coords1, coords2)\n\n# Conventional data frame\nnuffield.df &lt;- data.frame(name = c(\"Nuffield College\", \"Radcliffe Camera\"),\n                          address = c(\"New Road\", \"Radcliffe Sq\"),\n                          lat = coords[,1], lon = coords[,2])\n\nhead(nuffield.df)\n\n                    name      address      lat       lon\ncoords1 Nuffield College     New Road 51.75259 -1.262801\ncoords2 Radcliffe Camera Radcliffe Sq 51.75324 -1.253904\n\n# Combine to spatial data frame\nnuffield.spdf &lt;- st_as_sf(nuffield.df, \n                          coords = c(\"lon\", \"lat\"), # Order is important\n                          crs = 4326) # EPSG number of CRS\n\n# Map\nmapview(nuffield.spdf, zcol = \"name\")\n\n\n\n\n\n\n\n1.2.2 Projected CRS\nHowever, different data providers use different CRS. For instance, spatial data in the UK usually uses ‘OSGB 1936 / British National Grid’ (EPSG:27700). Here, coordinates are in meters, and projected onto a planar 2D space.\nThere are a lot of different CRS projections, and different national statistics offices provide data in different projections. Data providers usually specify which reference system they use. This is important as using the correct reference system and projection is crucial for plotting and manipulating spatial data.\nIf you do not know the correct CRS, try starting with a standards CRS like EPSG:4326 if you have decimal degree like coordinates. If it looks like projected coordinates, try searching for the country or region in CRS libraries like https://epsg.io/. However, you must check if the projected coordinates match their real location, e.g. using mapview().\n\n1.2.3 Why different projections?\nBy now, (most) people agree that the earth is not flat. So, to plot data on a 2D planar surface and to perform certain operations on a planar world, we need to make some re-projections. Depending on where we are, different re-projections of our data (globe in this case) might work better than others.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nclass(world)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(world)\n\nCoordinate Reference System:\n  User input: +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \n  wkt:\nBOUNDCRS[\n    SOURCECRS[\n        GEOGCRS[\"unknown\",\n            DATUM[\"World Geodetic System 1984\",\n                ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                    LENGTHUNIT[\"metre\",1]],\n                ID[\"EPSG\",6326]],\n            PRIMEM[\"Greenwich\",0,\n                ANGLEUNIT[\"degree\",0.0174532925199433],\n                ID[\"EPSG\",8901]],\n            CS[ellipsoidal,2],\n                AXIS[\"longitude\",east,\n                    ORDER[1],\n                    ANGLEUNIT[\"degree\",0.0174532925199433,\n                        ID[\"EPSG\",9122]]],\n                AXIS[\"latitude\",north,\n                    ORDER[2],\n                    ANGLEUNIT[\"degree\",0.0174532925199433,\n                        ID[\"EPSG\",9122]]]]],\n    TARGETCRS[\n        GEOGCRS[\"WGS 84\",\n            DATUM[\"World Geodetic System 1984\",\n                ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                    LENGTHUNIT[\"metre\",1]]],\n            PRIMEM[\"Greenwich\",0,\n                ANGLEUNIT[\"degree\",0.0174532925199433]],\n            CS[ellipsoidal,2],\n                AXIS[\"latitude\",north,\n                    ORDER[1],\n                    ANGLEUNIT[\"degree\",0.0174532925199433]],\n                AXIS[\"longitude\",east,\n                    ORDER[2],\n                    ANGLEUNIT[\"degree\",0.0174532925199433]],\n            ID[\"EPSG\",4326]]],\n    ABRIDGEDTRANSFORMATION[\"Transformation from unknown to WGS84\",\n        METHOD[\"Geocentric translations (geog2D domain)\",\n            ID[\"EPSG\",9603]],\n        PARAMETER[\"X-axis translation\",0,\n            ID[\"EPSG\",8605]],\n        PARAMETER[\"Y-axis translation\",0,\n            ID[\"EPSG\",8606]],\n        PARAMETER[\"Z-axis translation\",0,\n            ID[\"EPSG\",8607]]]]\n\n# Extract a country and plot in current CRS (WGS84)\nger.spdf &lt;- world[world$name == \"Germany\", ]\nplot(st_geometry(ger.spdf))\n\n\n\n# Now, let's transform Germany into a CRS optimized for Iceland\nger_rep.spdf &lt;- st_transform(ger.spdf, crs = 5325)\nplot(st_geometry(ger_rep.spdf))\n\n\n\n\nDepending on the angle, a 2D projection of the earth looks different. It is important to choose a suitable projection for the available spatial data. For more information on CRS and re-projection, see e.g. Lovelace, Nowosad, and Muenchow (2019) or Stefan Jünger & Anne-Kathrin Stroppe’s GESIS workshop materials."
  },
  {
    "objectID": "01_refresher_short.html#importing-some-real-world-data",
    "href": "01_refresher_short.html#importing-some-real-world-data",
    "title": "\n1  Refresher\n",
    "section": "\n1.3 Importing some real world data",
    "text": "1.3 Importing some real world data\nsf imports many of the most common spatial data files, like geojson, gpkg, or shp.\n\n1.3.1 London shapefile (polygon)\nLet’s get some administrative boundaries for London from the London Datastore. We use the sf package and its funtion st_read() to import the data.\n\n# Create subdir (all data withh be stored in \"_data\")\ndn &lt;- \"_data\"\nifelse(dir.exists(dn), \"Exists\", dir.create(dn))\n\n[1] \"Exists\"\n\n# Download zip file and unzip\ntmpf &lt;- tempfile()\nboundary.link &lt;- \"https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip\"\ndownload.file(boundary.link, tmpf)\nunzip(zipfile = tmpf, exdir = paste0(dn))\nunlink(tmpf)\n\n# This is a shapefile\n# We only need the MSOA layer for now\nmsoa.spdf &lt;- st_read(dsn = paste0(dn, \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"MSOA_2011_London_gen_MHW\" # Note: no file ending\n                     )\n\nReading layer `MSOA_2011_London_gen_MHW' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\statistical-gis-boundaries-london\\ESRI' \n  using driver `ESRI Shapefile'\nSimple feature collection with 983 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n\nThe object msoa.spdf is our spatial data.frame. It looks essentially like a conventional data.frame, but has some additional attributes and geo-graphical information stored with it. Most importantly, notice the column geometry, which contains a list of polygons. In most cases, we have one polygon for each line / observation.\n\nhead(msoa.spdf)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180510.7 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   MSOA11CD                 MSOA11NM   LAD11CD              LAD11NM\n1 E02000001       City of London 001 E09000001       City of London\n2 E02000002 Barking and Dagenham 001 E09000002 Barking and Dagenham\n3 E02000003 Barking and Dagenham 002 E09000002 Barking and Dagenham\n4 E02000004 Barking and Dagenham 003 E09000002 Barking and Dagenham\n5 E02000005 Barking and Dagenham 004 E09000002 Barking and Dagenham\n6 E02000007 Barking and Dagenham 006 E09000002 Barking and Dagenham\n    RGN11CD RGN11NM USUALRES HHOLDRES COMESTRES POPDEN HHOLDS\n1 E12000007  London     7375     7187       188   25.5   4385\n2 E12000007  London     6775     6724        51   31.3   2713\n3 E12000007  London    10045    10033        12   46.9   3834\n4 E12000007  London     6182     5937       245   24.8   2318\n5 E12000007  London     8562     8562         0   72.1   3183\n6 E12000007  London     8791     8672       119   50.6   3441\n  AVHHOLDSZ                       geometry\n1       1.6 MULTIPOLYGON (((531667.6 18...\n2       2.5 MULTIPOLYGON (((548881.6 19...\n3       2.6 MULTIPOLYGON (((549102.4 18...\n4       2.6 MULTIPOLYGON (((551550 1873...\n5       2.7 MULTIPOLYGON (((549099.6 18...\n6       2.5 MULTIPOLYGON (((549819.9 18...\n\n\nShapefiles are still among the most common formats to store and transmit spatial data, despite them being inefficient (file size and file number).\nHowever, sf reads everything spatial, such as geo.json, which usually is more efficient, but less common (but we’re getting there).\n\n# Download file\nulez.link &lt;- \"https://data.london.gov.uk/download/ultra_low_emissions_zone/936d71d8-c5fc-40ad-a392-6bec86413b48/CentralUltraLowEmissionZone.geojson\"\ndownload.file(ulez.link, paste0(dn, \"/ulez.json\"))\n\n# Read geo.json\nst_layers(paste0(dn, \"/ulez.json\"))\n\nDriver: GeoJSON \nAvailable layers:\n                   layer_name geometry_type features fields\n1 CentralUltraLowEmissionZone Multi Polygon        1      4\n                        crs_name\n1 OSGB36 / British National Grid\n\nulez.spdf &lt;- st_read(dsn = paste0(dn, \"/ulez.json\")) # here dsn is simply the file\n\nReading layer `CentralUltraLowEmissionZone' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\ulez.json' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 527271.5 ymin: 178041.5 xmax: 533866.3 ymax: 183133.4\nProjected CRS: OSGB36 / British National Grid\n\nhead(ulez.spdf)\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 527271.5 ymin: 178041.5 xmax: 533866.3 ymax: 183133.4\nProjected CRS: OSGB36 / British National Grid\n  fid OBJECTID BOUNDARY Shape_Area                       geometry\n1   1        1 CSS Area   21.37557 MULTIPOLYGON (((531562.7 18...\n\n\nAgain, this looks like a conventional data.frame but has the additional column geometry containing the coordinates of each observation. st_geometry() returns only the geographic object and st_drop_geometry() only the data.frame without the coordinates. We can plot the object using mapview().\n\nmapview(msoa.spdf[, \"POPDEN\"])\n\n\n\n\n\n\n\n1.3.2 Census API (admin units)\nNow that we have some boundaries and shapes of spatial units in London, we can start looking for different data sources to populate the geometries.\nA good source for demographic data is for instance the 2011 census. Below we use the nomis API to retrieve population data for London, See the Vignette for more information (Guest users are limited to 25,000 rows per query). Below is a wrapper to avoid some errors with sex and urban-rural cross-tabulation in some of the data.\n\n### For larger request, register and set key\n# Sys.setenv(NOMIS_API_KEY = \"XXX\")\n# nomis_api_key(check_env = TRUE)\n\nx &lt;- nomis_data_info()\n\n# Get London ids\nlondon_ids &lt;- msoa.spdf$MSOA11CD\n\n### Get key statistics ids\n# select requires tables (https://www.nomisweb.co.uk/sources/census_2011_ks)\n# Let's get KS201EW (ethnic group), KS205EW (passport held), and KS402EW (housing tenure)\n\n# Get internal ids\nstats &lt;- c(\"KS201EW\", \"KS402EW\", \"KS205EW\")\noo &lt;- which(grepl(paste(stats, collapse = \"|\"), x$name.value))\nksids &lt;- x$id[oo]\nksids # This are the internal ids\n\n[1] \"NM_608_1\" \"NM_612_1\" \"NM_619_1\"\n\n### look at meta information\nq &lt;- nomis_overview(ksids[1])\nhead(q)\n\n# A tibble: 6 × 2\n  name           value           \n  &lt;chr&gt;          &lt;list&gt;          \n1 analyses       &lt;named list [1]&gt;\n2 analysisname   &lt;chr [1]&gt;       \n3 analysisnumber &lt;int [1]&gt;       \n4 contact        &lt;named list [4]&gt;\n5 contenttypes   &lt;named list [1]&gt;\n6 coverage       &lt;chr [1]&gt;       \n\na &lt;- nomis_get_metadata(id = ksids[1], concept = \"GEOGRAPHY\", type = \"type\")\na # TYPE297 is MSOA level\n\n# A tibble: 24 × 3\n   id      label.en                                   description.en\n   &lt;chr&gt;   &lt;chr&gt;                                      &lt;chr&gt;         \n 1 TYPE265 NHS area teams                             NHS area teams\n 2 TYPE266 clinical commissioning groups              clinical comm…\n 3 TYPE267 built-up areas including subdivisions      built-up area…\n 4 TYPE269 built-up areas                             built-up areas\n 5 TYPE273 national assembly for wales electoral reg… national asse…\n 6 TYPE274 postcode areas                             postcode areas\n 7 TYPE275 postcode districts                         postcode dist…\n 8 TYPE276 postcode sectors                           postcode sect…\n 9 TYPE277 national assembly for wales constituencie… national asse…\n10 TYPE279 parishes 2011                              parishes 2011 \n# ℹ 14 more rows\n\nb &lt;- nomis_get_metadata(id = ksids[1], concept = \"MEASURES\", type = \"TYPE297\")\nb # 20100 is the measure of absolute numbers\n\n# A tibble: 2 × 3\n  id    label.en description.en\n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         \n1 20100 value    value         \n2 20301 percent  percent       \n\n### Query data in loop over the required statistics\nfor(i in ksids){\n\n  # Determin if data is divided by sex or urban-rural\n  nd &lt;- nomis_get_metadata(id = i)\n  if(\"RURAL_URBAN\" %in% nd$conceptref){\n    UR &lt;- TRUE\n  }else{\n    UR &lt;- FALSE\n  }\n  if(\"C_SEX\" %in% nd$conceptref){\n    SEX &lt;- TRUE\n  }else{\n    SEX &lt;- FALSE\n  }\n\n  # make data request\n  if(UR == TRUE){\n    if(SEX == TRUE){\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, RURAL_URBAN = 0, C_SEX = 0)\n    }else{\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, RURAL_URBAN = 0)\n    }\n  }else{\n    if(SEX == TRUE){\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, C_SEX = 0)\n    }else{\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100)\n    }\n\n  }\n\n  # Append (in case of different regions)\n  ks_tmp &lt;- tmp_en\n\n  # Make lower case names\n  names(ks_tmp) &lt;- tolower(names(ks_tmp))\n  names(ks_tmp)[names(ks_tmp) == \"geography_code\"] &lt;- \"msoa11\"\n  names(ks_tmp)[names(ks_tmp) == \"geography_name\"] &lt;- \"name\"\n\n  # replace weird cell codes\n  onlynum &lt;- which(grepl(\"^[[:digit:]]+$\", ks_tmp$cell_code))\n  if(length(onlynum) != 0){\n    code &lt;- substr(ks_tmp$cell_code[-onlynum][1], 1, 7)\n    if(is.na(code)){\n      code &lt;- i\n    }\n    ks_tmp$cell_code[onlynum] &lt;- paste0(code, \"_\", ks_tmp$cell_code[onlynum])\n  }\n\n  # save codebook\n  ks_cb &lt;- unique(ks_tmp[, c(\"date\", \"cell_type\", \"cell\", \"cell_code\", \"cell_name\")])\n\n  ### Reshape\n  ks_res &lt;- tidyr::pivot_wider(ks_tmp, id_cols = c(\"msoa11\", \"name\"),\n                               names_from = \"cell_code\",\n                               values_from = \"obs_value\")\n\n  ### Merge\n  if(i == ksids[1]){\n    census_keystat.df &lt;- ks_res\n    census_keystat_cb.df &lt;- ks_cb\n  }else{\n    census_keystat.df &lt;- merge(census_keystat.df, ks_res, by = c(\"msoa11\", \"name\"), all = TRUE)\n    census_keystat_cb.df &lt;- rbind(census_keystat_cb.df, ks_cb)\n  }\n\n}\n\n\n# Descriptions are saved in the codebook\nhead(census_keystat_cb.df)\n\n# A tibble: 6 × 5\n   date cell_type     cell cell_code   cell_name                    \n  &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;                        \n1  2011 Ethnic Group     0 KS201EW0001 All usual residents          \n2  2011 Ethnic Group   100 KS201EW_100 White                        \n3  2011 Ethnic Group     1 KS201EW0002 White: English/Welsh/Scottis…\n4  2011 Ethnic Group     2 KS201EW0003 White: Irish                 \n5  2011 Ethnic Group     3 KS201EW0004 White: Gypsy or Irish Travel…\n6  2011 Ethnic Group     4 KS201EW0005 White: Other White           \n\nsave(census_keystat_cb.df, file = \"_data/Census_codebook.RData\")\n\nNow, we have one file containing the geometries of MSOAs and one file with the census information on ethnic groups. Obviously, we can easily merge them together using the MSOA identifiers.\n\nmsoa.spdf &lt;- merge(msoa.spdf, census_keystat.df,\n                   by.x = \"MSOA11CD\", by.y = \"msoa11\", all.x = TRUE)\n\nAnd we can, for instance, plot the spatial distribution of ethnic groups.\n\nmsoa.spdf$per_white &lt;- msoa.spdf$KS201EW_100 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_mixed &lt;- msoa.spdf$KS201EW_200 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_asian &lt;- msoa.spdf$KS201EW_300 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_black &lt;- msoa.spdf$KS201EW_400 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_other &lt;- msoa.spdf$KS201EW_500 / msoa.spdf$KS201EW0001 * 100\n\nmapview(msoa.spdf[, \"per_white\"])\n\n\n\n\n\n\nIf you’re interested in more data sources, see for instance APIs for social scientists: A collaborative review by Paul C. Bauer, Camille Landesvatter, Lion Behrens. It’s a collection of several APIs for social sciences.\n\n1.3.3 Gridded data\nSo far, we have queried data on administrative units. However, often data comes on other spatial scales. For instance, we might be interested in the amount of air pollution, which is provided on a regular grid across the UK from Defra.\n\n# Download\npol.link &lt;- \"https://uk-air.defra.gov.uk/datastore/pcm/mapno22011.csv\"\ndownload.file(pol.link, paste0(dn, \"/mapno22011.csv\"))\npol.df &lt;- read.csv(paste0(dn, \"/mapno22011.csv\"), skip = 5, header = T, sep = \",\",\n                      stringsAsFactors = F, na.strings = \"MISSING\")\n\nhead(pol.df)\n\n  ukgridcode      x       y no22011\n1      54291 460500 1221500      NA\n2      54292 461500 1221500      NA\n3      54294 463500 1221500      NA\n4      54979 458500 1220500      NA\n5      54980 459500 1220500      NA\n6      54981 460500 1220500      NA\n\n\nThe data comes as point data with x and y as coordinates. We have to transform this into spatial data first. We first setup a spatial points object with st_as_sf. Subsequently, we transform the point coordinates into a regular grid. We use a buffer method st_buffer with “diameter”, and only one segment per quadrant (nQuadSegs). This gives us a 1x1km regular grid.\n\n# Build spatial object\npol.spdf &lt;- st_as_sf(pol.df, coords = c(\"x\", \"y\"),\n                    crs = 27700)\n\n# we transform the point coordinates into a regular grid with \"diameter\" 500m\npol.spdf &lt;- st_buffer(pol.spdf, dist = 500, nQuadSegs  = 1,\n                      endCapStyle = 'SQUARE')\n\n# Plot NO2\nplot(pol.spdf[, \"no22011\"], border = NA)\n\n\n\n\n\n1.3.4 OpenStreetMap (points)\nAnother interesting data source is the OpenStreetMap API, which provides information about the geographical location of a serious of different indicators. Robin Lovelace provides a nice introduction to the osmdata API. Available features can be found on OSM wiki.\nFirst we create a bounding box of where we want to query data. st_bbox() can be used to get bounding boxes of an existing spatial object (needs CRS = 4326). An alternative would be to use opq(bbox = 'greater london uk').\n\n# bounding box of where we want to query data\nq &lt;- opq(bbox = st_bbox(st_transform(msoa.spdf, 4326)))\n\nAnd we want to get data for all pubs and bars which are within this bounding box.\n\n# First build the query of location of pubs in London\nosmq &lt;- add_osm_feature(q, key = \"amenity\", value = \"pub\")\n\n# And then query the data\npubs.osm &lt;- osmdata_sf(osmq)\n\nRight now there are some results in polygons, some in points, and they overlap. Often, data from OSM needs some manual cleaning. Sometimes the same features are represented by different spatial objects (e.g. points + polygons).\n\n# Make unique points / polygons\npubs.osm &lt;- unique_osmdata(pubs.osm)\n\n# Get points and polygons (there are barley any pubs as polygons, so we ignore them)\npubs.points &lt;- pubs.osm$osm_points\npubs.polys &lt;- pubs.osm$osm_multipolygons\n\n# # Drop OSM file\n# rm(pubs.osm); gc()\n\n# Reduce to point object only\npubs.spdf &lt;- pubs.points\n\n# Reduce to a few variables\npubs.spdf &lt;- pubs.spdf[, c(\"osm_id\", \"name\", \"addr:postcode\", \"diet:vegan\")]\n\nAgain, we can inspect the results with mapview.\n\nmapview(st_geometry(pubs.spdf))\n\n\n\n\n\nNote that OSM is solely based on contribution by users, and the quality of OSM data varies. Usually data quality is better in larger cities, and better for more stable features (such as hospitals, train stations, highways) rahter than pubs or restaurants which regularly appear and disappear. However, data from London Datastore would indicate more pubs than what we find with OSM.\n\n1.3.5 Save\nWe will store the created data to use them again in the next session.\n\nsave(msoa.spdf, file = \"_data/msoa_spatial.RData\")\nsave(ulez.spdf, file = \"_data/ulez_spatial.RData\")\nsave(pol.spdf, file = \"_data/pollution_spatial.RData\")\nsave(pubs.spdf, file = \"_data/pubs_spatial.RData\")"
  },
  {
    "objectID": "01_refresher_short.html#data-manipulation",
    "href": "01_refresher_short.html#data-manipulation",
    "title": "\n1  Refresher\n",
    "section": "\n1.4 Data Manipulation",
    "text": "1.4 Data Manipulation\nRequired packages\n\npkgs &lt;- c(\"sf\", \"gstat\", \"mapview\", \"nngeo\", \"rnaturalearth\", \"dplyr\",\n          \"nomisr\", \"osmdata\", \"tidyr\", \"texreg\", \"downlit\", \"xml2\") \nlapply(pkgs, require, character.only = TRUE)\n\nHaving data with geo-spatial information allows to perform a variety of methods to manipulate and link different data sources. Commonly used methods include 1) subsetting, 2) point-in-polygon operations, 3) distance measures, 4) intersections or buffer methods.\nThe online Vignettes of the sf package provide a comprehensive overview of the multiple ways of spatial manipulations.\nCheck if data is on common projection\n\nst_crs(msoa.spdf) == st_crs(pol.spdf)\n\n[1] FALSE\n\nst_crs(msoa.spdf) == st_crs(pubs.spdf)\n\n[1] FALSE\n\nst_crs(msoa.spdf) == st_crs(ulez.spdf)\n\n[1] FALSE\n\n\nThe spatial data files are on different projections. Before we can do any spatial operations with them, we have to transform them into a common projection.\n\n# MSOA in different crs --&gt; transform\npol.spdf &lt;- st_transform(pol.spdf, crs = st_crs(msoa.spdf))\npubs.spdf &lt;- st_transform(pubs.spdf, crs = st_crs(msoa.spdf))\nulez.spdf &lt;- st_transform(ulez.spdf, crs = st_crs(msoa.spdf))\n\n\n# Check if all geometries are valid, and make valid if needed\nmsoa.spdf &lt;- st_make_valid(msoa.spdf)\n\nThe st_make_valid() can help if the spatial geometries have some problems such as holes or points that don’t match exactly.\n\n1.4.1 Subsetting\nWe can subset spatial data in a similar way as we subset conventional data.frames or matrices. For instance, below we simply reduce the pollution grid across the UK to observations in London only.\n\n# Subset to pollution estimates in London\npol_sub.spdf &lt;- pol.spdf[msoa.spdf, ] # or:\npol_sub.spdf &lt;- st_filter(pol.spdf, msoa.spdf)\nmapview(pol_sub.spdf)\n\n\n\n\n\n\nOr we can reverse the above and exclude all intersecting units by specifying st_disjoint as alternative spatial operation using the op = option (note the empty space for column selection). st_filter() with the .predicate option does the same job. See the sf Vignette for more operations.\n\n# Subset pubs to pubs not in the ulez area\nsub2.spdf &lt;- pubs.spdf[ulez.spdf, , op = st_disjoint] # or:\nsub2.spdf &lt;- st_filter(pubs.spdf, ulez.spdf, .predicate = st_disjoint)\nmapview(sub2.spdf)\n\n\n\n\n\n\nWe can easily create indicators of whether an MSOA is within ulez or not.\n\nmsoa.spdf$ulez &lt;- 0\n\n# intersecting lsoas\nwithin &lt;- msoa.spdf[ulez.spdf,]\n\n# use their ids to create binary indicator \nmsoa.spdf$ulez[which(msoa.spdf$MSOA11CD %in% within$MSOA11CD)] &lt;- 1\ntable(msoa.spdf$ulez)\n\n\n  0   1 \n955  28 \n\n\n\n1.4.2 Point in polygon\nWe are interested in the number of pubs in each MSOA. So, we count the number of points in each polygon.\n\n# Assign MSOA to each point\npubs_msoa.join &lt;- st_join(pubs.spdf, msoa.spdf, join = st_within)\n\n# Count N by MSOA code (drop geometry to speed up)\npubs_msoa.join &lt;- dplyr::count(st_drop_geometry(pubs_msoa.join),\n                               MSOA11CD = pubs_msoa.join$MSOA11CD,\n                               name = \"pubs_count\")\nsum(pubs_msoa.join$pubs_count)\n\n[1] 1601\n\n# Merge and replace NAs with zero (no matches, no pubs)\nmsoa.spdf &lt;- merge(msoa.spdf, pubs_msoa.join,\n                   by = \"MSOA11CD\", all.x = TRUE)\nmsoa.spdf$pubs_count[is.na(msoa.spdf$pubs_count)] &lt;- 0\n\n\n1.4.3 Distance measures\nWe might be interested in the distance to the nearest pub. Here, we use the package nngeo to find k nearest neighbours with the respective distance.\n\n# Use geometric centroid of each MSOA\ncent.sp &lt;- st_centroid(msoa.spdf[, \"MSOA11CD\"])\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Get K nearest neighbour with distance\nknb.dist &lt;- st_nn(cent.sp, \n                  pubs.spdf,\n                  k = 1,             # number of nearest neighbours\n                  returnDist = TRUE, # we also want the distance\n                  progress = FALSE)\n\nprojected points\n\nmsoa.spdf$dist_pubs &lt;- unlist(knb.dist$dist)\nsummary(msoa.spdf$dist_pubs)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   9.079  305.149  565.018  701.961  948.047 3735.478 \n\n\n\n1.4.4 Intersections + Buffers\nWe may also want the average pollution within 1 km radius around each MSOA centroid. Note that it is usually better to use a ego-centric method where you calculate the average within a distance rather than using the characteristic of the intersecting cells only (Lee et al. 2008; Mohai and Saha 2007).\nTherefore, we first create a buffer with st_buffer() around each midpoint and subsequently use st_intersetion() to calculate the overlap.\n\n# Create buffer (1km radius)\ncent.buf &lt;- st_buffer(cent.sp, \n                      dist = 1000) # dist in meters\nmapview(cent.buf)\n\n\n\n\n\n# Add area of each buffer (in this constant) \ncent.buf$area &lt;- as.numeric(st_area(cent.buf))\n\n# Calculate intersection of pollution grid and buffer\nint.df &lt;- st_intersection(cent.buf, pol.spdf)\n\nWarning: attribute variables are assumed to be spatially constant\nthroughout all geometries\n\nint.df$int_area &lt;- as.numeric(st_area(int.df)) # area of intersection\n\n# Area of intersection as share of buffer\nint.df$area_per &lt;- int.df$int_area / int.df$area\n\nAnd we use the percent overalp areas as the weights to calculate a weighted mean.\n\n# Aggregate as weighted mean\nint.df &lt;- st_drop_geometry(int.df)\nint.df$no2_weighted &lt;- int.df$no22011 * int.df$area_per\nint.df &lt;- aggregate(list(no2 = int.df[, \"no2_weighted\"]), \n                    by = list(MSOA11CD = int.df$MSOA11CD),\n                    sum)\n\n# Merge back to spatial data.frame\nmsoa.spdf &lt;- merge(msoa.spdf, int.df, by = \"MSOA11CD\", all.x = TRUE)\n\nmapview(msoa.spdf[, \"no2\"])\n\n\n\n\n\n\nNote: for buffer related methods, it often makes sense to use population weighted centroids instead of geographic centroids (see here for MSOA population weighted centroids). However, often this information is not available.\n\n1.4.5 and more\nThere are more spatial operation possible using sf. Have a look at the sf Cheatsheet."
  },
  {
    "objectID": "01_refresher_short.html#data-visualisation",
    "href": "01_refresher_short.html#data-visualisation",
    "title": "\n1  Refresher\n",
    "section": "\n1.5 Data visualisation",
    "text": "1.5 Data visualisation\nFor mapping\n\npkgs &lt;- c(\"tmap\", \"tmaptools\", \"viridisLite\", \n          \"ggplot2\", \"ggthemes\", \"rmapshaper\") \nlapply(pkgs, require, character.only = TRUE)\n\nA large advantage of spatial data is that different data sources can be connected and combined. Another nice advantage is: you can create very nice maps. And it’s quite easy to do! Stefan Jünger & Anne-Kathrin Stroppe provide more comprehensive materials on mapping in their GESIS workshop on geospatial techniques in R.\nMany packages and functions can be used to plot maps of spatial data. For instance, ggplot as a function to plot spatial data using geom_sf(). I am personally a fan of tmap, which makes many steps easier (but sometimes is less flexible).\nA great tool for choosing coulour is for instance Colorbrewer. viridisLite provides another great resource to chose colours.\n\n1.5.1 Tmaps\nFor instance, lets plot the NO2 estimates using tmap + tm_fill() (there are lots of alternatives like tm_shape, tm_points(), tm_dots()).\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"no2\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 7, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"NO2\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) \n\nmp1\n\n\n\n\nTmap allows to easily combine different objects by defining a new object via tm_shape().\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"no2\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 7, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"NO2\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_shape(ulez.spdf) +\n  tm_borders(col = \"red\", lwd = 1, alpha = 1) \n\nmp1\n\n\n\n\nAnd it is easy to change the layout.\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"no2\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 7, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = expression('in'~mu*'g'/m^{3}), \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_shape(ulez.spdf) +\n  tm_borders(col = \"red\", lwd = 1, alpha = 1) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"NO2\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\nmp1\n\n\n\n\n\n1.5.2 ggplot\nFor those of you have rather stick with the basic ggplot package, we can also use ggplot for spatial maps.\n\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = no2))+\n    scale_fill_viridis_c(option = \"B\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .6))\ngp\n\n\n\n\n\n# Get some larger scale boundaries\nborough.spdf &lt;- st_read(dsn = paste0(\"_data\", \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"London_Borough_Excluding_MHW\" # Note: no file ending\n                     )\n\nReading layer `London_Borough_Excluding_MHW' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\statistical-gis-boundaries-london\\ESRI' \n  using driver `ESRI Shapefile'\nSimple feature collection with 33 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n# transform to only inner lines\nborough_inner &lt;- ms_innerlines(borough.spdf)\n\n# Plot with inner lines\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = no2), color = NA)+\n    scale_fill_viridis_c(option = \"A\")+\n    geom_sf(data = borough_inner, color = \"gray92\")+\n    geom_sf(data = ulez.spdf, color = \"red\", fill = NA)+\n    coord_sf(datum = NA)+\n    theme_map()+\n    labs(fill = \"NO2\")+\n    theme(legend.position = c(.9, .6))\ngp"
  },
  {
    "objectID": "01_refresher_short.html#exercise",
    "href": "01_refresher_short.html#exercise",
    "title": "\n1  Refresher\n",
    "section": "\n1.6 Exercise",
    "text": "1.6 Exercise\n\nWhat is the difference between a spatial “sf” object and a conventional “data.frame”? What’s the purpose of the function st_drop_geometry()?\n\nIt’s the same. A spatial “sf” object just has an additional column containing the spatial coordinates.\n\nUsing msoa.spdf, please create a spatial data frame that contains only the MSOA areas that are within the ulez zone.\n\n\nsub4.spdf &lt;- msoa.spdf[ulez.spdf, ]\n\n\nPlease create a map for London (or only the msoa-ulez subset) which shows the share of Asian residents (or any other ethnic group).\n\n\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = per_asian))+\n    scale_fill_viridis_c(option = \"E\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .6))\ngp\n\n\n\n\n\nPlease calculate the distance of each MSOA to the London city centre\n\n\nuse google maps to get lon and lat,\nuse st_as_sf() to create the spatial point\nuse st_distance() to calculate the distance\n\n\n### Distance to city center\n# Define centre\ncentre &lt;- st_as_sf(data.frame(lon = -0.128120855701165, \n                              lat = 51.50725909644806),\n                   coords = c(\"lon\", \"lat\"), \n                   crs = 4326)\n# Reproject\ncentre &lt;- st_transform(centre, crs = st_crs(msoa.spdf))\n# Calculate distance\nmsoa.spdf$dist_centre &lt;- as.numeric(st_distance(msoa.spdf, centre)) / 1000\n# hist(msoa.spdf$dist_centre)\n\n\nCan you create a plot with the distance to the city centre and pub counts next to each other?\n\n\n# Define colours\ncols &lt;- viridis(n = 10, direction = 1, option = \"B\")\ncols2 &lt;- viridis(n = 10, direction = 1, option = \"E\")\n\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"dist_centre\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 10, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"Distance\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Dist centre\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\n\nmp2 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"dist_centre\", \n          style = \"quantile\", # algorithm to def cut points\n          n = 10, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"Distance\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Dist centre\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\n\nmp3 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"pubs_count\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 10, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"Count\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Pubs\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\n\nmp4 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"pubs_count\", \n          style = \"quantile\", # algorithm to def cut points\n          n = 10, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"Count\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Pubs\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\n\ntmap_arrange(mp1, mp2, mp3, mp4, ncol = 2, nrow = 2)\n\n\n\n\n\n1.6.1 Geogrphic cter\n\n# Make one single schape\nlondon &lt;- st_union(msoa.spdf)\n\n# Calculate center\ncent &lt;- st_centroid(london)\n\nmapview(cent)\n\n\n\n\n\n\n\n\n\n\n\nLee, Barrett A., Sean F. Reardon, Glenn Firebaugh, Chad R. Farrell, Stephen A. Matthews, and David O’Sullivan. 2008. “Beyond the Census Tract: Patterns and Determinants of Racial Segregation at Multiple Geographic Scales.” American Sociological Review 73 (5): 766–91. https://doi.org/10.1177/000312240807300504.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. Chapman & Hall/CRC the R Series. Boca Raton: Chapman & Hall/CRC.\n\n\nMohai, Paul, and Robin Saha. 2007. “Racial Inequality in the Distribution of Hazardous Waste: A National-Level Reassessment.” Social Problems 54 (3): 343–70. https://doi.org/10.1525/sp.2007.54.3.343."
  },
  {
    "objectID": "03_weights_short.html#spatial-interdependence",
    "href": "03_weights_short.html#spatial-interdependence",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.1 Spatial interdependence",
    "text": "2.1 Spatial interdependence\nWe can not only use coordinates and geo-spatial information to connect different data sources, we can also explicitly model spatial (inter)dependence in the analysis of our data. In many instance, accounting for spatial dependence might even be necessary to avoid biased point estimates and standard errors, as observations are often not independent and identically distributed.\nTobler’s first law of geography has been used extensively (11,584 citation in 2023-06) to describe spatial dependence: ‘Everything is related to everything else, but near things are more related than distant things’ (Tobler 1970).\n\n\n\n\n\n\nNote\n\n\n\nTobler’s first law is a bit of story\nAnd it has been labeled as an excuse to not think too much about the reasons for spatial dependence or auto-correlation. For instance, measurement error, omitted variables, or inappropriate levels of aggregation are among reasons for auto-correlation (Pebesma and Bivand 2023).\n\n\nWe will come back to the reasons of spatial dependence. However, for now, we are interested in some tools to detect and analyse spatial relations.\nTo analyse spatial relations, we first need to define some sort of connectivity between units (e.g. similar to network analysis). There are some obvious candidates that be used to define these relations here: adjacency and proximity."
  },
  {
    "objectID": "03_weights_short.html#bm-w-connectivity-between-units",
    "href": "03_weights_short.html#bm-w-connectivity-between-units",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.2 \\(\\bm W\\): Connectivity between units",
    "text": "2.2 \\(\\bm W\\): Connectivity between units\nThe connectivity between units is usually represented in a matrix \\(\\bm W\\). There is an ongoing debate about the importance of spatial weights for spatial econometrics and about the right way to specify weights matrices (LeSage and Pace 2014; Neumayer and Plümper 2016). The following graph shows some possible options in how to define connectivity between units.\n\n\nFigure: Different measures of connectivity, Source: R. S. Bivand and Rudel (2018)\n\nIn spatial econometrics, the spatial connectivity (as shown above) is usually represented by a spatial weights matrix \\({\\boldsymbol{\\mathbf{W}}}\\):\n$$\n    \\boldsymbol{\\mathbf{W}} = \\begin{bmatrix} \n        w_{11} & w_{12} & \\dots & w_{1n} \\\\\n        w_{21} & w_{22} & \\dots & w_{2n} \\\\\n        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n        w_{n1} & w_{n2} & \\dots     & w_{nn} \n        \\end{bmatrix}\n$$ The spatial weights matrix \\(\\bm W\\) is an \\(N \\times N\\) dimensional matrix with elements \\(w_{ij}\\) specifying the relation or connectivity between each pair of units \\(i\\) and \\(j\\).\nNote: The diagonal elements \\(w_{i,i}= w_{1,1}, w_{2,2}, \\dots, w_{n,n}\\) of \\(\\bm W\\) are always zero. No unit is a neighbour of itself. This is not true for spatial multiplier matrices (as we will see later).\n\n2.2.1 Contiguity weights\nA very common type of spatial weights. Binary specification, taking the value 1 for neighbouring units (queens: sharing a common edge; rook: sharing a common border), and 0 otherwise.\nContiguity weights \\(w_{i,j}\\), where\n\\[\n  w_{i,j} =\n    \\begin{cases}\n      1 & \\text{if $i$ and $j$ neighbours}\\\\\n      0 & \\text{otherwise}\n    \\end{cases}       \n\\]\nA contiguity weights matrix with three units, where unit 1 and unit 3 are neighbours, while unit 2 has no neighbours would look like this:\n\\[\n        \\boldsymbol{\\mathbf{W}}  = \\begin{bmatrix}\n            0 & 0 & 1  \\\\\n            0 & 0 & 0  \\\\\n            1 & 0 & 0  \n           \\end{bmatrix}   \\nonumber\n\\]\n\nSparse matrices\nProblem of `island’: units without neighbours (if I calculate an average of their neigbours, would that be zero, or NA, or a mean?)\n\nLets create a contiguity weights matrix (Queens neighbours) for the London MSOAs: we create a neighbours list (nb) using poly2nb(), which is an efficient way of storing \\({\\boldsymbol{\\mathbf{W}}}\\). A snap of 1 meter accounts for potential lacks of accuracy between lines and points.\n\n# Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, # a single shared boundary point meets the contiguity condition\n                     snap = 1) # we consider points in 1m distance as 'touching'\nsummary(queens.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 5648 \nPercentage nonzero weights: 0.5845042 \nAverage number of links: 5.745677 \nLink number distribution:\n\n  2   3   4   5   6   7   8   9  10  11  12  13 \n  9  39 130 264 273 169  66  19   5   6   2   1 \n9 least connected regions:\n160 270 475 490 597 729 755 778 861 with 2 links\n1 most connected region:\n946 with 13 links\n\n# Lets plot that\nplot(st_geometry(msoa.spdf), border = \"grey60\")\nplot(queens.nb, st_centroid(st_geometry(msoa.spdf)), \n     add = TRUE, pch = 19, cex = 0.6)\n\n\n\n# We can also transform this into a matrix W\nW &lt;- nb2mat(queens.nb, style = \"B\")\nprint(W[1:10, 1:10])\n\n   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n1     0    0    0    0    0    0    0    0    0     0\n2     0    0    1    0    0    0    0    0    0     0\n3     0    1    0    0    1    0    0    0    0     0\n4     0    0    0    0    0    1    0    0    0     1\n5     0    0    1    0    0    1    1    0    0     0\n6     0    0    0    1    1    0    1    0    1     1\n7     0    0    0    0    1    1    0    1    1     0\n8     0    0    0    0    0    0    1    0    0     0\n9     0    0    0    0    0    1    1    0    0     1\n10    0    0    0    1    0    1    0    0    1     0\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAmong those first 10 units that you see above, which are the neighbours of unit number 6?\nWhy is the diagonal of this matrix all zero?\n\n\nOverall, the matrix W has dimensions \\(N \\times N\\), a row and a column for each observation. The value in a cell shows how units \\(i\\) (row number) and \\(j\\) (column number) are related to each other.\n\ndim(W)\n\n[1] 983 983\n\n\nThe row and column sums indicate the number of neighbours of each observation.\n\nrowSums(W)[1:10]\n\n 1  2  3  4  5  6  7  8  9 10 \n11  6  7  5  5  6  6  6  6  5 \n\ncolSums(W)[1:10]\n\n [1] 11  6  7  5  5  6  6  6  6  5\n\n\nAdjacency or graph-based neighbour’s weights matrices are usually symmetric. If unit 1 is a neighbour of unit 55, then unit 55 is also a neighbour of unit 1.\n\n\n\n\n\n\nHigher Order Neighbours\n\n\n\nYour neighbours have neighbours too, and they are called higher (second) order neighbours. The neighbours of your neighbour’s neighbours are third order neighbours.\nYou can use nblag() to calculate higher order neighbour relations.\n\n\n\n2.2.2 Distance based weights\nAnother common type uses the distance \\(d_{ij}\\) between each unit \\(i\\) and \\(j\\).\n\nInverse distance weights \\(w_{i,j} = \\frac{1}{d_{ij}^\\alpha}\\), where \\(\\alpha\\) define the strength of the spatial decay.\n\n\\[\n        \\boldsymbol{\\mathbf{W}} = \\begin{bmatrix}\n            0 & \\frac{1}{d_{ij}^\\alpha} & \\frac{1}{d_{ij}^\\alpha}  \\\\\n            \\frac{1}{d_{ij}^\\alpha} & 0 & \\frac{1}{d_{ij}^\\alpha}  \\\\\n            \\frac{1}{d_{ij}^\\alpha} & \\frac{1}{d_{ij}^\\alpha} & 0  \n            \\end{bmatrix}   \\nonumber\n\\]\n\nDense matrices\nSpecifying thresholds may be useful (to get rid of very small non-zero weights)\n\nFor now, we will just specify a neighbours list with a distance threshold of 3km using dnearneigh(). An alternative would be k nearest neighbours using knearneigh(). We will do the inverse weighting later.\n\n# Crease centroids\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Neighbours within 3km distance\ndist_3.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 3000)\nsummary(dist_3.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 22086 \nPercentage nonzero weights: 2.285652 \nAverage number of links: 22.46796 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 4  3  7 13 11 14 14 17 26 22 26 30 33 34 46 34 59 43 38 30 25 19 \n23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \n22 15 21 14 23 17 17 23 28 19 26 24 29 24 27 25 22 18  8 10 12  5 \n45 46 47 \n 3  2  1 \n4 least connected regions:\n158 160 463 959 with 1 link\n1 most connected region:\n545 with 47 links\n\n# Lets plot that\nplot(st_geometry(msoa.spdf), border = \"grey60\")\nplot(dist_3.nb, coords, \n     add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\nAnd you can see that the matrix is not so sparse anymore:\n\nW2 &lt;- nb2mat(dist_3.nb, style = \"B\")\nW2[1:10, 1:10]\n\n   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n1     0    0    0    0    0    0    0    0    0     0\n2     0    0    1    0    1    0    0    0    0     0\n3     0    1    0    0    1    1    1    0    0     0\n4     0    0    0    0    1    1    1    0    1     1\n5     0    1    1    1    0    1    1    1    1     1\n6     0    0    1    1    1    0    1    1    1     1\n7     0    0    1    1    1    1    0    1    1     1\n8     0    0    0    0    1    1    1    0    1     0\n9     0    0    0    1    1    1    1    1    0     1\n10    0    0    0    1    1    1    1    0    1     0"
  },
  {
    "objectID": "03_weights_short.html#normalization-of-boldsymbolmathbfw",
    "href": "03_weights_short.html#normalization-of-boldsymbolmathbfw",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.3 Normalization of \\({\\boldsymbol{\\mathbf{W}}}\\)\n",
    "text": "2.3 Normalization of \\({\\boldsymbol{\\mathbf{W}}}\\)\n\nNormalizing ensures that the parameter space of the spatial multiplier is restricted to \\(-1 &lt; \\rho &gt; 1\\), and the multiplier matrix is non-singular (don’t worry, more on this later).\nThe main message: Normalizing your weights matrix is always a good idea. Otherwise, the spatial parameters might blow up – if you can estimate the model at all. It also ensure easy interpretation of spillover effects.\nAgain, how to normalize a weights matrix is subject of debate (LeSage and Pace 2014; Neumayer and Plümper 2016).\n\n2.3.1 Row-normalization\nRow-normalization divides each non-zero weight by the sum of all weights of unit \\(i\\), which is the sum of the row.\n\\[\n\\frac{w_{ij}}{\\sum_j^n w_{ij}}\n\\]\n\nWith contiguity weights, spatially lagged variables contain mean of this variable among the neighbours of \\(i\\)\nProportions between units such as distances get lost (can be bad!)\nCan induce asymmetries: \\(w_{ij} \\neq w_{ji}\\)\n\nFor instance, we can use row-normalization for the Queens neighbours created above, and create a neighbours list with spatial weights.\n\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\") # W ist row-normalization\nsummary(queens.lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 5648 \nPercentage nonzero weights: 0.5845042 \nAverage number of links: 5.745677 \nLink number distribution:\n\n  2   3   4   5   6   7   8   9  10  11  12  13 \n  9  39 130 264 273 169  66  19   5   6   2   1 \n9 least connected regions:\n160 270 475 490 597 729 755 778 861 with 2 links\n1 most connected region:\n946 with 13 links\n\nWeights style: W \nWeights constants summary:\n    n     nn  S0       S1      S2\nW 983 966289 983 355.1333 4017.47\n\n\nTo see what happened, let’s look at our example in matrix format again.\n\n# transform into matrix with row-normalization\nW_norm &lt;- nb2mat(queens.nb, style = \"W\")\nprint(W_norm[1:10, 1:10])\n\n   [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n1     0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\n2     0 0.0000000 0.1666667 0.0000000 0.0000000 0.0000000 0.0000000\n3     0 0.1428571 0.0000000 0.0000000 0.1428571 0.0000000 0.0000000\n4     0 0.0000000 0.0000000 0.0000000 0.0000000 0.2000000 0.0000000\n5     0 0.0000000 0.2000000 0.0000000 0.0000000 0.2000000 0.2000000\n6     0 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000 0.1666667\n7     0 0.0000000 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000\n8     0 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.1666667\n9     0 0.0000000 0.0000000 0.0000000 0.0000000 0.1666667 0.1666667\n10    0 0.0000000 0.0000000 0.2000000 0.0000000 0.2000000 0.0000000\n        [,8]      [,9]     [,10]\n1  0.0000000 0.0000000 0.0000000\n2  0.0000000 0.0000000 0.0000000\n3  0.0000000 0.0000000 0.0000000\n4  0.0000000 0.0000000 0.2000000\n5  0.0000000 0.0000000 0.0000000\n6  0.0000000 0.1666667 0.1666667\n7  0.1666667 0.1666667 0.0000000\n8  0.0000000 0.0000000 0.0000000\n9  0.0000000 0.0000000 0.1666667\n10 0.0000000 0.2000000 0.0000000\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nOverall, how many neighbours does unit 9 have (including all columns)? How do you know?\n\n\n\nrowSums(W)[9]\n\nWe can also use the nb object to see which ones the neighbours are. Here, for instance, neighbours of unit 6:\n\nqueens.nb[6]\n\n[[1]]\n[1]   4   5   7   9  10 462\n\n\nThis fits to what we see in the matrix above.\n\n\n\n\n\n\nWarning\n\n\n\nNote that row-normalization has some undesirable properties when we use some non-contigutiy based neighbour relations, such as distance based neighbours.\nThe problem: It obscures the proportion due to dividing by a row-specific value.\n\n\nLet’s construct a hypothetical example\n\n# Subset of 5 units\nsub.spdf &lt;- msoa.spdf[c(4, 5, 6, 102, 150), ]\nmapview(sub.spdf)\n\n\n\n\n\n\nWe construct the inverse-distance weighted 2 nearest neighbors.\n\n# 2 closest neighbours\nsub.coords &lt;- st_geometry(st_centroid(sub.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nknn.nb &lt;- knearneigh(sub.coords, \n                     k = 2) # number of nearest neighbours\n\nWarning in knearneigh(sub.coords, k = 2): k greater than one-third\nof the number of data points\n\nknn.nb &lt;- knn2nb(knn.nb)\nsummary(knn.nb)\n\nNeighbour list object:\nNumber of regions: 5 \nNumber of nonzero links: 10 \nPercentage nonzero weights: 40 \nAverage number of links: 2 \nNon-symmetric neighbours list\nLink number distribution:\n\n2 \n5 \n5 least connected regions:\n1 2 3 4 5 with 2 links\n5 most connected regions:\n1 2 3 4 5 with 2 links\n\n# listw with inverse-distance based weights\nsub.lw &lt;- nb2listwdist(knn.nb,\n                       x = sub.coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"raw\") # without normalization\nW_sub &lt;- listw2mat(sub.lw)\nformatC(W_sub, format = \"f\", digits = 6)\n\n  [,1]       [,2]       [,3]       [,4]       [,5]      \n1 \"0.000000\" \"0.000414\" \"0.000723\" \"0.000000\" \"0.000000\"\n2 \"0.000414\" \"0.000000\" \"0.000962\" \"0.000000\" \"0.000000\"\n3 \"0.000723\" \"0.000962\" \"0.000000\" \"0.000000\" \"0.000000\"\n4 \"0.000000\" \"0.000033\" \"0.000032\" \"0.000000\" \"0.000000\"\n5 \"0.000049\" \"0.000000\" \"0.000049\" \"0.000000\" \"0.000000\"\n\n\nAs you can see, units 1, 2, 3 have relatively proximate neighbours (.e.g inverse distance 0.000962: 3 zeros). Units 4 and 5, in contrast, have only very distant neighbours (e.g. inverse distance 0.000049: 4 zeros).\nNow, see what happens when we use row-normalization.\n\nsub.lw &lt;- nb2listwdist(knn.nb,\n                       x = sub.coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"W\") # for row normalization\nW_sub &lt;- listw2mat(sub.lw)\nformatC(W_sub, format = \"f\", digits = 6)\n\n  [,1]       [,2]       [,3]       [,4]       [,5]      \n1 \"0.000000\" \"0.364083\" \"0.635917\" \"0.000000\" \"0.000000\"\n2 \"0.300879\" \"0.000000\" \"0.699121\" \"0.000000\" \"0.000000\"\n3 \"0.429123\" \"0.570877\" \"0.000000\" \"0.000000\" \"0.000000\"\n4 \"0.000000\" \"0.507955\" \"0.492045\" \"0.000000\" \"0.000000\"\n5 \"0.499360\" \"0.000000\" \"0.500640\" \"0.000000\" \"0.000000\"\n\n\nAll rows sum up to 1, but the strength of the relation is now similar for the distant units 4 and 5, and the proximate units 1, 2, 3.\n\n2.3.2 Maximum eigenvalues normalization\nMaximum eigenvalues normalization divides each non-zero weight by the overall maximum eigenvalue \\(\\lambda_{max}\\). Each element of \\(\\boldsymbol{\\mathbf{W}}\\) is divided by the same scalar parameter, which preserves the relations.\n\\[\n\\frac{\\boldsymbol{\\mathbf{W}}}{\\lambda_{max}}\n\\]\n\nInterpretation may become more complicated\nKeeps proportions of connectivity strengths across units (relevant esp. for distance based \\(\\boldsymbol{\\mathbf{W}}\\))\n\nWe use eigenvalue normalization for the inverse distance neighbours. We use nb2listwdist() to create weight inverse distance based weights and normalize in one step.\n\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nidw.lw &lt;- nb2listwdist(dist_3.nb,\n                       x = coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\nsummary(idw.lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 22086 \nPercentage nonzero weights: 2.285652 \nAverage number of links: 22.46796 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 4  3  7 13 11 14 14 17 26 22 26 30 33 34 46 34 59 43 38 30 25 19 \n23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \n22 15 21 14 23 17 17 23 28 19 26 24 29 24 27 25 22 18  8 10 12  5 \n45 46 47 \n 3  2  1 \n4 least connected regions:\n158 160 463 959 with 1 link\n1 most connected region:\n545 with 47 links\n\nWeights style: minmax \nWeights constants summary:\n         n     nn       S0       S1       S2\nminmax 983 966289 463.6269 23.92505 1117.636\n\n\nExamples from above: See how this keeps the proportions in our example. Instead of transforming values to sum up to 1 in each row, we now have much smaller values for 4 and 5 then we have for the proximate units 1, 2, 3.\n\nsub.lw &lt;- nb2listwdist(knn.nb,\n                       x = sub.coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\nW_sub &lt;- listw2mat(sub.lw)\nformatC(W_sub, format = \"f\", digits = 6)\n\n  [,1]       [,2]       [,3]       [,4]       [,5]      \n1 \"0.000000\" \"0.245687\" \"0.429123\" \"0.000000\" \"0.000000\"\n2 \"0.245687\" \"0.000000\" \"0.570877\" \"0.000000\" \"0.000000\"\n3 \"0.429123\" \"0.570877\" \"0.000000\" \"0.000000\" \"0.000000\"\n4 \"0.000000\" \"0.019663\" \"0.019047\" \"0.000000\" \"0.000000\"\n5 \"0.029099\" \"0.000000\" \"0.029174\" \"0.000000\" \"0.000000\""
  },
  {
    "objectID": "03_weights_short.html#islands-missings",
    "href": "03_weights_short.html#islands-missings",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.4 Islands / missings",
    "text": "2.4 Islands / missings\nIn practice, we often have a problem with islands. If we use contiguity based or distance based neighbour definitions, some units may end up with empty neighbours sets: they just do not touch any other unit and do not have a neighbour within a specific distance. This however creates a problem: what is the value in the neighbouring units?\nThe zero.policy option in spdep allows to proceed with empty neighbours sets. However, many further functions may run into problems and return errors. It often makes sense to either drop islands, to choose weights which always have neighbours (e.g. k nearest), or impute empty neighbours sets by using the nearest neighbours."
  },
  {
    "objectID": "03_weights_short.html#global-autocorrelation",
    "href": "03_weights_short.html#global-autocorrelation",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.5 Global Autocorrelation",
    "text": "2.5 Global Autocorrelation\nIf spatially close observations are more likely to exhibit similar values, we cannot handle observations as if they were independent.\n\\[\n\\Exp(\\varepsilon_i\\varepsilon_j)\\neq \\Exp(\\varepsilon_i)\\Exp(\\varepsilon_j) = 0\n\\]\nThis violates a basic assumption of the conventional OLS model. We will talk more about whether that is good or bad (any guess?).\n\n2.5.1 Visualization\nThere is one very easy and intuitive way of detecting spatial autocorrelation: Just look at the map. We do so by using tmap for plotting the share of home owners.\n\nmp1 &lt;- tm_shape(msoa.spdf) +\n  tm_fill(col = \"per_owner\", \n          #style = \"cont\",\n          style = \"fisher\", n = 8,\n          title = \"Median\", \n          palette = viridis(n = 8, direction = -1, option = \"C\"),\n          legend.hist = TRUE) +\n  tm_borders(col = \"black\", lwd = 1) +\n  tm_layout(legend.frame = TRUE, legend.bg.color = TRUE,\n            #legend.position = c(\"right\", \"bottom\"),\n            legend.outside = TRUE,\n            main.title = \"Percent home owners\", \n            main.title.position = \"center\",\n            title.snap.to.legend = TRUE) \n\nmp1 \n\n\n\n\nWe definitely see some clusters with spatial units having a low share of home owner (e.g. in the city center), and other clusters where home ownership is high (e.g. suburbs in the south and east, such as Bromley or Havering).\nHowever, this is (to some degree) dependent on how we define cutoffs and coloring of the map: the Modifiable Areal Unit Problem (Wong 2009).\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the following three checkerboards has no (or the lowest) autocorrelation?\n\n\n\nWould your answer be the same if we would aggregate the data to four larger areas / districts using the average within each of the four districts?\n\n2.5.2 Moran’s I\nThe most common and well known statistic for spatial dependence or autocorrelation is Moran’s I, which goes back to Moran (1950) and Cliff and Ord (1972). For more extensive materials on Moran’s I see for instance Kelejian and Piras (2017), Chapter 11.\nTo calculate Moran’s I, we first define a neighbours weights matrix W.\nGlobal Moran’s I test statistic:\n\\[      \n        \\bm I  = \\frac{N}{S_0}  \n        \\frac{\\sum_i\\sum_j w_{ij}(y_i-\\bar{y})(y_j-\\bar{y})}\n            {\\sum_i (y_i-\\bar{y})^2}, \\text{where } S_0 = \\sum_{i=1}^N\\sum_{j=1}^N w_{ij}\n\\] It is often written with deviations \\(z\\)\n$$\n    \\bm I  = \\frac{N}{S_0}  \n    \\frac{\\sum_i\\sum_j w_{ij}(z_i)(z_j)}\n        {\\sum_i (z_i)^2}, \\text{where } S_0 = \\sum_{i=1}^N\\sum_{j=1}^N w_{ij}\n$$\nNote that in the case of row-standardized weights, \\(S_0 = N\\). The \\(I\\) can be interpreted as: Relation of the deviation from the mean value between unit \\(i\\) and neighbours of unit \\(i\\). Basically, this measures correlation between neighbouring values.\n\nNegative values: negative autocorrelation\nAround zero: no autocorrelation\nPositive values: positive autocorrelation\n\nTo calculate Moran’s I, we first need to define the relationship between units. As in the previous example, we define contiguity weights and distance-based weights.\n\n# Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, \n                     snap = 1) # we consider points in 1m distance as 'touching'\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\n\n# Neighbours within 3km distance\ncoords &lt;- st_geometry(st_centroid(msoa.spdf))\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\ndist_3.nb &lt;- dnearneigh(coords, \n                        d1 = 0, d2 = 3000)\nidw.lw &lt;- nb2listwdist(dist_3.nb,\n                       x = coords, # needed for idw\n                       type = \"idw\", # inverse distance weighting\n                       alpha = 1, # the decay parameter for distance weighting\n                       style = \"minmax\") # for eigenvalue normalization\n\nSubsequently, we can calculate the average correlation between neighbouring units.\nFor contiguity weights, we get:\n\n# Global Morans I test of housing values based on contiguity weights\nmoran.test(msoa.spdf$per_owner, listw = queens.lw, alternative = \"two.sided\")\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$per_owner  \nweights: queens.lw    \n\nMoran I statistic standard deviate = 38.161, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.728706855      -0.001018330       0.000365663 \n\n\nAnd for inverse distance weighting, we get:\n\n# Global Morans I test of housing values based on idw\nmoran.test(msoa.spdf$per_owner, listw = idw.lw, alternative = \"two.sided\")\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$per_owner  \nweights: idw.lw    \n\nMoran I statistic standard deviate = 65.853, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.6838957350     -0.0010183299      0.0001081719 \n\n\nInterpretation: In both cases, we have very strong autocorrelation between neighbouring/closer units (~.7). It barely matters which of the weights matrices we use. This autocorrelation is highly significant. we can thus reject the Null that units are independent of each other (at least at this spatial level and for the share of home owners).\n\n2.5.3 Residual-based Moran’s I\nWe can also use the same Moran’s I test to inspect spatial autocorrelation in residuals from an estimated linear model.\nLet’s start with an intercept only model.\n\nlm0 &lt;- lm(per_owner ~ 1, msoa.spdf)\nlm.morantest(lm0, listw = queens.lw, alternative = \"two.sided\")\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = per_owner ~ 1, data = msoa.spdf)\nweights: queens.lw\n\nMoran I statistic standard deviate = 38.177, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nObserved Moran I      Expectation         Variance \n    0.7287068548    -0.0010183299     0.0003653613 \n\n\nThis is exactly what we have received in the general case of Moran’s I.\nNow, lets add some predictors. For instance, the distance to the city centre, and the population density may be strongly related to the home ownership rates and explain parts of the spatial dependence.\n\n### Distance to city center\n# Define centre\ncentre &lt;- st_as_sf(data.frame(lon = -0.128120855701165, \n                              lat = 51.50725909644806),\n                   coords = c(\"lon\", \"lat\"), \n                   crs = 4326)\n# Reproject\ncentre &lt;- st_transform(centre, crs = st_crs(msoa.spdf))\n# Calculate distance\nmsoa.spdf$dist_centre &lt;- as.numeric(st_distance(msoa.spdf, centre)) / 1000\n# hist(msoa.spdf$dist_centre)\n\n### Run model with predictors\nlm1 &lt;- lm(per_owner ~ dist_centre + POPDEN, msoa.spdf)\nlm.morantest(lm1, listw = queens.lw, alternative = \"two.sided\")\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = per_owner ~ dist_centre + POPDEN, data =\nmsoa.spdf)\nweights: queens.lw\n\nMoran I statistic standard deviate = 22.674, p-value &lt;\n2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\nObserved Moran I      Expectation         Variance \n    0.4298146060    -0.0024065617     0.0003633607 \n\n\nThere is still considerable auto-correlation in the residuals. However, we have reduce it by a substantial amount with two very simple control variables."
  },
  {
    "objectID": "03_weights_short.html#local-autocorrelation",
    "href": "03_weights_short.html#local-autocorrelation",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.6 Local Autocorrelation",
    "text": "2.6 Local Autocorrelation\nThe Global Moran’s I statistic above summarizes the spatial pattern by a single value. Although this is helpful to get a feeling of the strength of the general spatial association, it is often more helpful to inspect the spatial pattern in more detail.\nThe most prominent measure is the Local Indicators of Spatial Association (LISA) (Anselin 1995). LISA measures assess the importance and significance of a satistic at different spatial locations. For more information see for instance the GeoData Materials by Luc Anselin.\nFor instance, we can use the Moran Plot to identify how single (pairs of) units contribute to the overall dependence.\n\nmp &lt;- moran.plot(msoa.spdf$per_owner, queens.lw)\n\n\n\n\nIn the lower left corner, we see units with a low-low share of home ownership: focal and neighbouring units have a low share of home owners. In the top right corner, by contrast, we see high-high units.\nAnd we can plot influence values on the Overall Moran statistic.\n\nmsoa.spdf$hat_value &lt;- mp$hat \nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"hat_value\", \n          palette = viridis(n = 10, direction = -1, option = \"C\"),\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Influence\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\nmp1"
  },
  {
    "objectID": "03_weights_short.html#local-morans-i",
    "href": "03_weights_short.html#local-morans-i",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.7 Local Moran’s I",
    "text": "2.7 Local Moran’s I\nLocal Moran’s I is a local version of the overall Moran’s I to identify local clusters and local spatial outliers (Anselin 1995). The Local Moran’s I is just a local version which is calculated for each location:\n$$\n    \\bm I_i  =  \n    \\frac{z_i \\sum_j w_{ij}z_j}\n        {\\sum_i (z_i)^2 / (n-1)}, \\text{where }\n$$ We use the unfction localmoran() to calculate the local test statistic .\n\nloci &lt;- localmoran(msoa.spdf$per_owner, listw = queens.lw)\nhead(loci)\n\n           Ii          E.Ii      Var.Ii       Z.Ii Pr(z != E(Ii))\n1  0.42322928 -1.285364e-04 0.011367934  3.9706976   7.166249e-05\n2 -0.12775982 -2.229957e-05 0.003634711 -2.1187688   3.411001e-02\n3  0.38111534 -6.569549e-04 0.091630752  1.2611995   2.072370e-01\n4  1.02874685 -1.428679e-03 0.279333375  1.9491704   5.127507e-02\n5  0.08553291 -2.108521e-04 0.041275789  0.4220412   6.729949e-01\n6 -0.24014505 -2.228818e-04 0.036321252 -1.2588964   2.080678e-01\n\n\nIt also has an attribute with the Moran plot quadrant of each observation.\n\nhead(attr(loci, \"quadr\"))\n\n       mean    median     pysal\n1   Low-Low   Low-Low   Low-Low\n2  Low-High  Low-High  Low-High\n3 High-High High-High High-High\n4 High-High High-High High-High\n5 High-High High-High High-High\n6  Low-High  Low-High  Low-High\n\n\nThis returns a data.frame with local moran statisic, the expectation of local moran statistic, its variance, and a p value for the satistical significance of each unit. Note that we obviously have a problem of multiple comparisons here and thus may want to correct the significance level, e.g. by Bonferroni adjustment (R. Bivand and Wong 2018).\n\nloci.df &lt;- data.frame(loci)\nnames(loci.df) &lt;- gsub(\"\\\\.\", \"\", names(loci.df))\nmsoa.spdf$loci &lt;- loci.df$Ii\nmsoa.spdf$p_value &lt;- loci.df$PrzEIi\nmsoa.spdf$p_value_adj1 &lt;- p.adjust(loci.df$PrzEIi, \"BY\")\nmsoa.spdf$p_value_adj2 &lt;- p.adjust(loci.df$PrzEIi, \"bonferroni\")\n\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = c(\"loci\", \"p_value\", \"p_value_adj1\", \"p_value_adj2\"),\n          palette = viridis(n = 10, direction = -1, option = \"C\"),\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"left\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Local Morans I\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8,\n            panel.labels = c(\"Morans I\",\n                               \"P value\",\n                               \"p value BY\",\n                             \"p value Bonferroni\"))\n\nmp1\n\n\n\n\nSomething you can often see are so called LISA hotspot maps. They are based on the same idea as the moran plot, and show cluster of high-high and low-low values. We can use the hotspot function to identify the clusters, with a cutoff for singificance and the adjustment for multiple testing.\n\n# Calculate clusters\nmsoa.spdf$lisa_cluster &lt;- hotspot(loci, \n                                  \"Pr(z != E(Ii))\", \n                                  cutoff = 0.05, \n                                  quadrant.type = \"mean\",\n                                  p.adjust = \"BY\")\n\n# Map\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = c(\"lisa_cluster\"),\n          palette = viridis(n = 3, direction = -1, option = \"D\"),\n          colorNA = \"white\") +\n  tm_borders(col = \"grey70\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"left\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Home Ownership \\n LISA Clusters p(BY) &lt; 0.05\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8,)\n\nmp1\n\n\n\n\nNote that it is not suggested to interpret those cluster as significant in the strict statistical sense. Pebesma and Bivand (2023) suggest to speak of interesting clusters. After all, this is an explorative approach. Nevertheless, it can help to identify spatial patterns and clusters.\nThere are more ways of calculating these hotspot maps and more choices on the cutoffs and calculation of the statistical significance. For more materials see Chapter 15 of Pebesma and Bivand (2023)."
  },
  {
    "objectID": "03_weights_short.html#example",
    "href": "03_weights_short.html#example",
    "title": "\n2  Spatial Relationships\n",
    "section": "\n2.8 Example",
    "text": "2.8 Example\nTate.2021\nThis study explores the geography of flood exposure and social vulnerability in the conterminous United States based on spatial analysis of fluvial and pluvial flood extent, land cover, and social vulnerability.\nMobile homes and racial minorities are most overrepresented in hotspots compared to elsewhere. The results identify priority locations where interventions can mitigate both physical and social aspects of flood vulnerability.\n\n\n\n\n\n\n\nAnselin, Luc. 1995. “Local Indicators of Spatial Association-LISA.” Geographical Analysis 27 (2): 93–115. https://doi.org/10.1111/j.1538-4632.1995.tb00338.x.\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos: Interface to Geometry Engine - Open Source (’GEOS’).”\n\n\nBivand, Roger, and David W. S. Wong. 2018. “Comparing Implementations of Global and Local Indicators of Spatial Association.” TEST 27 (3): 716–48. https://doi.org/10.1007/s11749-018-0599-x.\n\n\nCliff, Andrew, and Keith Ord. 1972. “Testing for Spatial Autocorrelation Among Regression Residuals.” Geographical Analysis 4 (3): 267–84. https://doi.org/10.1111/j.1538-4632.1972.tb00475.x.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial Econometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nLeSage, James P., and R. Kelley Pace. 2014. “The Biggest Myth in Spatial Econometrics.” Econometrics 2 (4): 217–49. https://doi.org/10.3390/econometrics2040217.\n\n\nMoran, P. A. P. 1950. “Notes on Continuous Stochastic Phenomena.” Biometrika 37 (1/2): 17. https://doi.org/10.2307/2332142.\n\n\nNeumayer, Eric, and Thomas Plümper. 2016. “W.” Political Science Research and Methods 4 (01): 175–93. https://doi.org/10.1017/psrm.2014.40.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nTobler, Waldo R. 1970. “A Computer Movie Simulating Urban Growth in the Detroit Region.” Economic Geography 46: 234–40. https://doi.org/10.2307/143141.\n\n\nWong, David. 2009. “The Modifiable Areal Unit Problem (MAUP).” In The Sage Handbook of Spatial Analysis, edited by A. Stewart Fotheringham and Peter Rogerson, 105–24. Los Angeles and London: Sage."
  },
  {
    "objectID": "04_exercise1_short.html#general-exercises",
    "href": "04_exercise1_short.html#general-exercises",
    "title": "\n3  Exercise I\n",
    "section": "\n3.1 General Exercises",
    "text": "3.1 General Exercises\n\nPlease calculate a neighbours weights matrix of the nearest 10 neighbours (see spdep::knearneigh()), and create a listw object using row normalization.\n\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nk10.nb &lt;- knearneigh(coords, k = 10)\n\n\nCan you create a map containing the City of London (MSOA11CD = “E02000001”) and its ten nearest neighbours?\n\n\ni &lt;- which(msoa.spdf$MSOA11CD == \"E02000001\")\n\n# Extract neigbours\nj &lt;- k10.nb$nn[i,]\n\nmapview(list(msoa.spdf[i,], msoa.spdf[j,]), col.regions = c(\"red\", \"blue\"))\n\n\n\n\n\n\n\nChose another characteristics from the data (e.g. ethnic groups or house prices) and calculate global Moran’s I for it.\n\n\n# Gen nb object\nk10.nb &lt;- knn2nb(k10.nb)\n\n# Gen listw object\nk10.listw &lt;- nb2listw(k10.nb, style = \"W\")\n\n# MOran test\nmoran.test(msoa.spdf$per_white, listw = k10.listw)\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$per_white  \nweights: k10.listw    \n\nMoran I statistic standard deviate = 55.733, p-value &lt;\n2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.7623842505     -0.0010183299      0.0001876235 \n\n\n\nProduce a LISA cluster map for the characteristic you have chosen.\n\n\nloci2 &lt;- localmoran(msoa.spdf$per_white, listw = k10.listw)\n\n# Calculate clusters\nmsoa.spdf$lisa_cluster &lt;- hotspot(loci2, \n                                  \"Pr(z != E(Ii))\", \n                                  cutoff = 0.05, \n                                  quadrant.type = \"mean\",\n                                  p.adjust = \"BY\")\n\n# Map\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = c(\"lisa_cluster\"),\n          palette = viridis(n = 3, direction = -1, option = \"D\"),\n          colorNA = \"white\") +\n  tm_borders(col = \"grey70\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"left\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Percentage White \\n LISA Clusters p(BY) &lt; 0.05\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8,)\n\nmp1"
  },
  {
    "objectID": "04_exercise1_short.html#environmental-inequality",
    "href": "04_exercise1_short.html#environmental-inequality",
    "title": "\n3  Exercise I\n",
    "section": "\n3.2 Environmental inequality",
    "text": "3.2 Environmental inequality\nHow would you investigate the following descriptive research question: Are ethnic (and immigrant) minorities in London exposed to higher levels of pollution? Also consider the spatial structure. What’s your dependent and what’s your independent variable?\n1) Define a neigbours weights object of your choice\nYou can choose any preferred neighbours-weights definition, such as for instance contiguity neighbours or all neighbourhoods within 2.5km.\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Neighbours within 3km distance\ndist_15.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 2500)\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15266 \nPercentage nonzero weights: 1.579859 \nAverage number of links: 15.53001 \n4 regions with no links:\n158 463 478 505\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 \n 4  5  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 \n22 23 24 25 26 27 28 29 30 31 32 33 34 \n25 19 38 29 32 38 26 16 20 10  8  1  2 \n5 least connected regions:\n160 469 474 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# There are some mpty one. Lets impute with the nearest neighbour\nk2.nb &lt;- knearneigh(coords, k = 1)\n\n# Replace zero\nnolink_ids &lt;- which(card(dist_15.nb) == 0)\ndist_15.nb[card(dist_15.nb) == 0] &lt;- k2.nb$nn[nolink_ids, ]\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15270 \nPercentage nonzero weights: 1.580273 \nAverage number of links: 15.53408 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 9  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 25 \n23 24 25 26 27 28 29 30 31 32 33 34 \n19 38 29 32 38 26 16 20 10  8  1  2 \n9 least connected regions:\n158 160 463 469 474 478 505 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# listw object with row-normalization\ndist_15.lw &lt;- nb2listw(dist_15.nb, style = \"W\")\n\n2) Estimate the extent of spatial auto-correlation\nThe most common way would be to calculate Global Moran’s I.\n\nmoran.test(msoa.spdf$no2, listw = dist_15.lw)\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$no2  \nweights: dist_15.lw    \n\nMoran I statistic standard deviate = 65.197, p-value &lt;\n2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.891520698      -0.001018330       0.000187411"
  },
  {
    "objectID": "05_regression-theory_short.html#why-do-we-need-spatial-regression-models",
    "href": "05_regression-theory_short.html#why-do-we-need-spatial-regression-models",
    "title": "\n4  Spatial Regression Models\n",
    "section": "\n4.1 Why do we need spatial regression models",
    "text": "4.1 Why do we need spatial regression models\n\n4.1.1 Non-spatial OLS\nLet us start with a linear model, where \\(\\bm y\\) is the outcome or dependent variable (\\(N \\times 1\\)), \\(\\bm X\\) are various exogenous covariates (\\(N \\times k\\)), and \\(\\bm \\varepsilon\\) (\\(N \\times 1\\)) is the error term. We are usually interested in the coefficient vector \\(\\bm \\beta\\) (\\(k \\times 1\\)) and its insecurity estimates.\n\\[\n{\\bm y}={\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}\n\\] The work-horse for estimating \\(\\bm \\beta\\) in the social science is the OLS estimator (Wooldridge 2010).\n\\[\n\\hat{\\beta}=({\\bm X}^\\intercal{\\bm X})^{-1}{\\bm X}^\\intercal{\\bm y}.\n\\]\n\n\n\n\n\n\nOLS assumptions I\n\n\n\n\n\\(\\Exp(\\epsilon_i|\\bm X_i) = 0\\): for every value of \\(X\\), the average / expectation of the error term \\(\\bm \\varepsilon\\) equals zero – put differently: the error term is independent of \\(X\\),\nthe observations of the sample are independent and identically distributed (i.i.d),\nthe fourth moments of the variables \\(\\bm X_i\\) and \\(Y_i\\) are positive and definite – put differently: extreme values / outliers are very very rare,\n\\(\\text{rank}(\\bm X) = K\\): the matrix \\(\\bm X\\) has full rank – put differently: no perfect multicollinearity between the covariates,\n\n\n\n\n\n\n\n\n\nOLS assumptions II\n\n\n\n\n\\(\\Var(\\varepsilon|x) = \\sigma^2\\): the error terms \\(\\varepsilon\\) are homoskedastic / have the same variance given any value of the explanatory variable,\n\\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)\\): the error terms \\(\\varepsilon\\) are normally distributed (conditional on the explanatory variables \\(X_i\\)).\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the six assumptions above may be violated by spatial dependence?\n\n\n\n\n4.1.2 Problem of ignoring spatial dependence\nDoes spatial dependence influence the results / coefficient estimates of non-spatial regression models, or in other words: is ignoring spatial dependence harmful?\nI’ve heard different answers, ranging from “It only affects the standard errors” to “it always introduces bias”. As so often, the true (or best?) answer is somewhere in the middle: it depends (Betz, Cook, and Hollenbach 2020; Cook, Hays, and Franzese 2020; Pace and LeSage 2010; Rüttenauer 2022).\nThe easiest way to think of it is analogous to the omit variable bias (Betz, Cook, and Hollenbach 2020; Cook, Hays, and Franzese 2020):\n\\[\nplim~\\hat{\\beta}_{OLS}= \\beta  + \\gamma \\frac{\\Cov(\\bm x, \\bm z)}{\\Var(\\bm x)},\n\\]\nwhere \\(z\\) is some omit variable, and \\(\\gamma\\) is the conditional effect of \\(\\bm z\\) on \\(\\bm y\\). Now imagine that the neighbouring values of the dependent variable \\(\\bm W \\bm y\\) are autocorrelated to focal unit which we denote with \\(\\rho &gt; 0\\), and that the covariance between the focal unit’s exogenous covariates and \\(\\bm W \\bm y\\) is not zero. Then we will have an omitted variable bias due to spatial dependence:\n\\[\nplim~\\hat{\\beta}_{OLS}= \\beta  + \\rho \\frac{\\Cov(\\bm x, \\bm W \\bm y)}{\\Var(\\bm x)} \\neq \\beta,\n\\]\nFor completeness, the entire bias is a bit more complicated (Pace and LeSage 2010; Rüttenauer 2022) and looks like:\n\\[\nplim~\\hat{\\beta}=\\frac{\\sum_{ij}({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal\\circ{\\bm M}(\\rho))_{ij}}\n{\\tr({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal)}\\beta \\\\\n+\\frac{\\sum_{ij}({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal\\circ{\\bm M}(\\rho){\\bm W})_{ij}}\n{\\tr({\\bm M}(\\delta){\\bm M}(\\delta)^\\intercal)}\\theta,\n\\] where \\(\\circ\\) denotes the Hadamard product, \\({\\bm M}(\\delta)=({\\bm I}_N-\\delta{\\bm W})^{-1}\\), and \\({\\bm M}(\\rho)=({\\bm I}_N-\\rho{\\bm W})^{-1}\\).\n\n\n\n(Don’t worry, no need to learn by hard!!)\n\n\nEssentially, the non-spatial OLS estimator \\(\\beta_{OLS}\\) is biased in the presence of either (Pace and LeSage 2010; Rüttenauer 2022):\n\nSpatial autocorrelation in the dependent variable (\\(\\rho\\neq0\\)) and spatial autocorrelation in the covariate (\\(\\delta\\neq0\\)). This bias increases with \\(\\rho\\), \\(\\delta\\), and \\(\\beta\\).\nLocal spatial spillover effects (\\(\\theta\\neq0\\)) and spatial autocorrelation in the covariate (\\(\\delta\\neq0\\)). This is analogous to the omitted variable bias resulting from the omission of \\({\\bm W} {\\bm x}\\). It increases with \\(\\theta\\) and \\(\\delta\\), but additionally with \\(\\rho\\) if \\(\\theta\\neq0\\) and \\(\\delta\\neq0\\).\nAn omitted variable and \\(\\mathrm{E}({\\bm \\varepsilon}|{\\bm x})\\neq0\\). This non-spatial omitted variable bias \\(\\gamma\\) is amplified by spatial dependence in the disturbances (\\(\\lambda\\)) and spatial autocorrelation in the dependent variable (\\(\\rho\\)), but also increases with positive values of \\(\\delta\\) if either \\(\\rho\\neq 0\\) or \\(\\lambda\\neq 0\\). Obviously, it also increases with \\(\\gamma\\)."
  },
  {
    "objectID": "05_regression-theory_short.html#spatial-regression-models",
    "href": "05_regression-theory_short.html#spatial-regression-models",
    "title": "\n4  Spatial Regression Models\n",
    "section": "\n4.2 Spatial Regression Models",
    "text": "4.2 Spatial Regression Models\nBroadly, spatial dependence or clustering in some characteristic can be the result of three different processes:\n\n\n\n\nflowchart TD\n  id1{Spatial dependence} --&gt; A[Spatial interdepence]\n  id1 --&gt; B[Spillovers from covariates]\n  id1 --&gt; C[Clustering unobservables]\n\n\n\n\n\nStrictly speaking, there are some other possibilities too, such as measurement error or the wrong choice on the spatial level. For instance, imagine we have a city-specific characteristic (e.g. public spending) allocated to neighbourhood units. Obviously, this will introduce heavy autocorrelation on the neigbourhood level by construction.\nThere are three basic ways of incorporating spatial dependence, which then can be further combined. As before, the \\(N \\times N\\) spatial weights matrix \\(\\bm W\\) defines the spatial relationship between units.\n\n4.2.1 Spatial Error Model (SEM)\n\nClustering on Unobservables\n\n$$\n    \\begin{split}\n    {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm u},\\\\\n    {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n    \\end{split} \n$$\n\\(\\lambda\\) denotes the strength of the spatial correlation in the errors of the model: your errors influence my errors.\n\n\n\\(&gt; 0\\): positive error dependence,\n\n\\(&lt; 0\\): negative error dependence,\n\n\\(= 0\\): traditional OLS model.\n\n\\(\\lambda\\) is defined in the range \\([-1, +1]\\).\n\n4.2.2 Spatial Autoregressive Model (SAR)\n\nInterdependence\n\n$$\n    {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}\n$$\n\\(\\rho\\) denotes the strength of the spatial correlation in the dependent variable (spatial autocorrelation): your outcome influences my outcome.\n\n\n\\(&gt; 0\\): positive spatial dependence,\n\n\\(&lt; 0\\): negative spatial dependence,\n\n\\(= 0\\): traditional OLS model.\n\n\\(\\rho\\) is defined in the range \\([-1, +1]\\).\n\n4.2.3 Spatially lagged X Model (SLX)\n\nSpillovers in Covariates\n\n$$\n    {\\bm y}=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm \\varepsilon}\n$$\n\\(\\theta\\) denotes the strength of the spatial spillover effects from covariate(s) on the dependent variable: your covariates influence my outcome.\n\\(\\theta\\) is basically like any other coefficient from a covariate. It is thus not bound to any range.\nMoreover, there are models combining two sets of the above specifications.\n\n4.2.4 Spatial Durbin Model (SDM)\n\nInterdependence\nSpillovers in Covariates\n\n$$\n    {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm \\varepsilon}\n$$\n\n4.2.5 Spatial Durbin Error Model (SDEM)\n\nClustering on Unobservables\nSpillovers in Covariates\n\n$$\n    \\begin{split}\n    {\\bm y}&=\\alpha{\\bm \\iota}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm u},\\\\\n    {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n    \\end{split}\n$$\n\n4.2.6 Combined Spatial Autocorrelation Model (SAC)\n\nClustering on Unobservables\nInterdependence\n\n$$\n    \\begin{split}\n    {\\bm y}&=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm u},\\\\\n    {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n    \\end{split}\n$$\n\n4.2.7 General Nesting Spatial Model (GNS)\n\nClustering on Unobservables\nInterdependence\nSpillovers in Covariates\n\n$$\n    \\begin{split}\n    {\\bm y}&=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+{\\bm W}{\\bm X}{\\bm \\theta}+ {\\bm u},\\\\\n    {\\bm u}&=\\lambda{\\bm W}{\\bm u}+{\\bm \\varepsilon}\n    \\end{split}\n$$\n\n\n\n\n\n\nManski’s reflection problem\n\n\n\nThe General Nesting Spatial Model (GNS) is only weakly (or not?) identifiable (Gibbons and Overman 2012).\nIt’s analogous to Manski’s reflection problem on neighbourhood effects (Manski 1993): If people in the same group behave similar, this can be because a) imitating behaviour of the group, b) exogenous characteristics of the group influence the behaviour, and c) members of the same group are exposed to the same external circumstances. We just cannot separate those in observational data.\n\n\nNote that all of these models assume different data generating processes (DGP) leading to the spatial pattern. Although there are specifications tests, it is generally not possible to let the data decide which one is the true underlying DGP (Cook, Hays, and Franzese 2020; Rüttenauer 2022). However, there might be theoretical reasons to guide the model specification (Cook, Hays, and Franzese 2020).\nJust because SAR is probably the most commonly used model does not make it the best choice. In contrast, various studies (Halleck Vega and Elhorst 2015; Rüttenauer 2022; Wimpy, Whitten, and Williams 2021) highlight the advantages of the relative simple SLX model. Moreover, this specification can basically be incorporated in any other statistical method.\n\n4.2.8 A note on missings\nMissing values create a problem in spatial data analysis. For instance, in a local spillover model with an average of 10 neighbours, two initial missing values will lead to 20 missing values in the spatially lagged variable. For global spillover models, one initial missing will ‘flow’ through the neighbourhood system until the cutoff point (and create an excess amount of missings).\nDepending on the data, units with missings can either be dropped and omitted from the initial weights creation, or we need to impute the data first, e.g. using interpolation or Kriging."
  },
  {
    "objectID": "05_regression-theory_short.html#mini-example",
    "href": "05_regression-theory_short.html#mini-example",
    "title": "\n4  Spatial Regression Models\n",
    "section": "\n4.3 Mini Example",
    "text": "4.3 Mini Example\nLet’s try to make sense of this. We rely on a mini example using a few units in Camden\n\nsub.spdf &lt;- msoa.spdf[c(172, 175, 178, 179, 181, 182), ]\nmapview(sub.spdf)\n\n\n\n\n\n\nWe then construct queens neighbours, and have a look at the resulting non-normalized matrix \\(\\bm W\\).\n\nqueens.nb &lt;- poly2nb(sub.spdf, queen = TRUE, snap = 1)\nW &lt;- nb2mat(queens.nb, style = \"B\")\nW\n\n    [,1] [,2] [,3] [,4] [,5] [,6]\n172    0    0    1    0    0    0\n175    0    0    0    1    0    1\n178    1    0    0    1    1    0\n179    0    1    1    0    1    1\n181    0    0    1    1    0    1\n182    0    1    0    1    1    0\nattr(,\"call\")\nnb2mat(neighbours = queens.nb, style = \"B\")\n\n\nWe have selected 6 units. So, \\(\\bm W\\) is a \\(6 \\times 6\\) matrix. we see that observation 1 has one neighbour: observation 3. Observation 2 has two neighbours: observation 4 and observation 6. The diagonal is zero: no unit is a neighbour of themselves.\nNo we row-normalize this matrix.\n\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\nW_rn &lt;- listw2mat(queens.lw)\nW_rn\n\n         [,1]      [,2]      [,3]      [,4]      [,5]      [,6]\n172 0.0000000 0.0000000 1.0000000 0.0000000 0.0000000 0.0000000\n175 0.0000000 0.0000000 0.0000000 0.5000000 0.0000000 0.5000000\n178 0.3333333 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000\n179 0.0000000 0.2500000 0.2500000 0.0000000 0.2500000 0.2500000\n181 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000 0.3333333\n182 0.0000000 0.3333333 0.0000000 0.3333333 0.3333333 0.0000000\n\n\nNo every single weight \\(w_{ij}\\) is divided by the total number of neighbours \\(n_i\\) of the focal unit. For observation 1, observation 3 is the only neighbour, thus a weight = 1. For observation two, both neighbours have a weight of 1/2. For observation 3 (with three neighbours) each neighbour got a weight of 1/3.\n\n\n\n\n\n\nQuestion\n\n\n\nWhat happens if we multiply this matrix \\(\\bm W\\) with a \\(N \\times 1\\) vector \\(\\bm y\\) or \\(\\bm x\\)?\n\n\nA short reminder on matrix multiplication.\n\\[\n\\bm W * \\bm y =\n\\begin{bmatrix}\nw_{11} & w_{12} & w_{13}\\\\\nw_{21} & w_{22} & w_{23}\\\\\nw_{31} & w_{32} & w_{33}\n\\end{bmatrix} *\n\\begin{bmatrix}\ny_{11} \\\\\ny_{21} \\\\\ny_{31}  \n\\end{bmatrix}\\\\\n= \\begin{bmatrix}\nw_{11}y_{11} + w_{12}y_{21} + w_{13}y_{31}\\\\\nw_{21}y_{11} + w_{22}y_{21} + w_{23}y_{31}\\\\\nw_{31}y_{11} + w_{32}y_{21} + w_{33}y_{31}  \n\\end{bmatrix}\n\\]\nEach line of \\(\\bm W * \\bm y\\) just gives a weighted average of the other \\(y\\)-values \\(y_j\\) in the sample. In case of the row-normalization, each neighbour gets the same weight \\(\\frac{1}{n_i}\\). This is simply the mean of \\(y_j\\) of the neighbours in case of a row-normalized contiguity weights matrix.\nNote that the mean interpretation is only valid with row-normalization. What would we get with inverse-distance based weights?\nLet’s look at this in our example\n\ny &lt;- sub.spdf$med_house_price\nx &lt;- sub.spdf$pubs_count\n\nW_rn\n\n         [,1]      [,2]      [,3]      [,4]      [,5]      [,6]\n172 0.0000000 0.0000000 1.0000000 0.0000000 0.0000000 0.0000000\n175 0.0000000 0.0000000 0.0000000 0.5000000 0.0000000 0.5000000\n178 0.3333333 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000\n179 0.0000000 0.2500000 0.2500000 0.0000000 0.2500000 0.2500000\n181 0.0000000 0.0000000 0.3333333 0.3333333 0.0000000 0.3333333\n182 0.0000000 0.3333333 0.0000000 0.3333333 0.3333333 0.0000000\n\ny\n\n[1] 376812.5 414625.0 713125.0 322750.0 495000.0 364000.0\n\nx\n\n[1] 1 3 3 1 9 7\n\nW_rn_y &lt;- W_rn %*% y\nW_rn_x &lt;- W_rn %*% x\nW_rn_y\n\n        [,1]\n172 713125.0\n175 343375.0\n178 398187.5\n179 496687.5\n181 466625.0\n182 410791.7\n\nW_rn_x\n\n        [,1]\n172 3.000000\n175 4.000000\n178 3.666667\n179 5.500000\n181 3.666667\n182 4.333333\n\n\nLet’s check if our interpretation is true\n\nW_rn_y[1] == y[3]\n\n[1] TRUE\n\nW_rn_y[2] == mean(y[c(4, 6)])\n\n[1] TRUE\n\nW_rn_y[4] == mean(y[c(2, 3, 5, 6)])\n\n[1] TRUE"
  },
  {
    "objectID": "05_regression-theory_short.html#real-example",
    "href": "05_regression-theory_short.html#real-example",
    "title": "\n4  Spatial Regression Models\n",
    "section": "\n4.4 Real Example",
    "text": "4.4 Real Example\nFirst, we need the a spatial weights matrix.\n\n# Contiguity (Queens) neighbours weights\nqueens.nb &lt;- poly2nb(msoa.spdf, \n                     queen = TRUE, \n                     snap = 1) # we consider points in 1m distance as 'touching'\nqueens.lw &lt;- nb2listw(queens.nb,\n                      style = \"W\")\n\nWe can estimate spatial models using spatialreg.\n\n4.4.1 SAR\nLets estimate a spatial SAR model using the lagsarlm() with contiguity weights. We use median house value as depended variable, and include population density (POPDEN), the air pollution (no2), and the share of ethnic minorities (per_mixed, per_asian, per_black, per_other).\n\nmod_1.sar &lt;- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5281789 -0.1220524 -0.0099245  0.0992203  1.0936745 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)  3.17383180  0.29041604  10.9286 &lt; 2.2e-16\nlog(no2)     0.39705423  0.04452880   8.9168 &lt; 2.2e-16\nlog(POPDEN) -0.05583014  0.01242876  -4.4920 7.055e-06\nper_mixed    0.01851577  0.00579832   3.1933  0.001407\nper_asian   -0.00228346  0.00045876  -4.9775 6.442e-07\nper_black   -0.01263650  0.00100282 -12.6009 &lt; 2.2e-16\nper_other   -0.00161419  0.00289082  -0.5584  0.576582\n\nRho: 0.66976, LR test value: 473.23, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.025311\n    z-value: 26.461, p-value: &lt; 2.22e-16\nWald statistic: 700.19, p-value: &lt; 2.22e-16\n\nLog likelihood: 196.7203 for lag model\nML residual variance (sigma squared): 0.035402, (sigma: 0.18815)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -375.44, (AIC for lm: 95.786)\nLM test for residual autocorrelation\ntest value: 8.609, p-value: 0.0033451\n\n\nThis looks pretty much like a conventional model output, with some additional information: a highly significant mod_1.sar$rho of 0.67 indicates strong positive spatial autocorrelation.\nRemember that is the coefficient for the term \\(\\bm y = \\rho \\bm W \\bm y \\ldots\\). It is bound to be below 1 for positive autocorrelation.\nIn substantive terms, house prices in the focal unit positively influence house prices in neighbouring units, which again influences house prices among the neighbours of these neighbours, and so on (we’ll get back to this).\n\n\n\n\n\n\nWarning\n\n\n\nThe coefficients of covariates in a SAR model are not marginal or partial effects, because of the spillovers and feedback loops in \\(\\bm y\\) (see below)!\nFrom the coefficient, we can only interpret the direction: there’s a positive effect of air pollution and a negative effect of population sensitivity, and so on…\n\n\n\n4.4.2 SEM\nSEM models can be estimated using errorsarlm().\n\nmod_1.sem &lt;- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = FALSE) # we could here extend to SDEM\nsummary(mod_1.sem)\n\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.581785 -0.105218 -0.012758  0.094430  0.913425 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept) 12.92801104  0.35239139  36.6865 &lt; 2.2e-16\nlog(no2)     0.15735296  0.10880727   1.4462 0.1481317\nlog(POPDEN) -0.08316270  0.01254315  -6.6301 3.354e-11\nper_mixed   -0.03377962  0.00811054  -4.1649 3.115e-05\nper_asian   -0.00413115  0.00096849  -4.2656 1.994e-05\nper_black   -0.01653816  0.00126741 -13.0488 &lt; 2.2e-16\nper_other   -0.01693012  0.00462999  -3.6566 0.0002556\n\nLambda: 0.88605, LR test value: 623.55, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.015803\n    z-value: 56.068, p-value: &lt; 2.22e-16\nWald statistic: 3143.6, p-value: &lt; 2.22e-16\n\nLog likelihood: 271.8839 for error model\nML residual variance (sigma squared): 0.026911, (sigma: 0.16405)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: NA (not available for weighted model), (AIC for lm: 95.786)\n\n\nIn this case mod_1.sem$lambda gives us the spatial parameter. A highly significant lambda of 0.89 indicates that the errors are highly spatially correlated (e.g. due to correlated unobservables). Again, $= 1 $ would be the maximum.\nIn spatial error models, we can interpret the coefficients directly, as in a conventional linear model.\n\n4.4.3 SLX\nSLX models can either be estimated with lmSLX() directly, or by creating \\(\\bm W \\bm X\\) manually and plugging it into any available model-fitting function.\n\nmod_1.slx &lt;- lmSLX(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw, \n                   Durbin = TRUE) # use a formula to lag only specific covariates\nsummary(mod_1.slx)\n\n\nCall:\nlm(formula = formula(paste(\"y ~ \", paste(colnames(x)[-1], collapse = \"+\"))), \n    data = as.data.frame(x), weights = weights)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.50809 -0.16605 -0.01817  0.13055  1.09039 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     10.582440   0.153862  68.779  &lt; 2e-16 ***\nlog.no2.        -0.440727   0.181063  -2.434  0.01511 *  \nlog.POPDEN.     -0.076840   0.017345  -4.430 1.05e-05 ***\nper_mixed       -0.033042   0.011298  -2.925  0.00353 ** \nper_asian       -0.002381   0.001474  -1.615  0.10655    \nper_black       -0.016229   0.001801  -9.009  &lt; 2e-16 ***\nper_other       -0.020391   0.006564  -3.107  0.00195 ** \nlag.log.no2.     0.993602   0.199370   4.984 7.38e-07 ***\nlag.log.POPDEN.  0.113262   0.028752   3.939 8.76e-05 ***\nlag.per_mixed    0.126069   0.014294   8.820  &lt; 2e-16 ***\nlag.per_asian   -0.003828   0.001661  -2.305  0.02140 *  \nlag.per_black   -0.018054   0.002241  -8.056 2.30e-15 ***\nlag.per_other    0.048139   0.007971   6.039 2.20e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2262 on 970 degrees of freedom\nMultiple R-squared:  0.653, Adjusted R-squared:  0.6487 \nF-statistic: 152.1 on 12 and 970 DF,  p-value: &lt; 2.2e-16\n\n\nIn SLX models, we can simply interpret the coefficients of direct and indirect (spatially lagged) covariates.\nFor instance, lets look at population density:\n\n\n\n\n\n\nInterpretaion SLX\n\n\n\n\nA high population density in the focal unit is related to lower house prices (a 1% increase in population density decreses house prices by -0.08%), but\nA high population density in the neighbouring areas is related to higher house prices (while keeping population density in the focal unit constant). A 1% increase in the average population density across the adjacent neighbourhoods increases house prices in the focal unit by 0.11%)\n\nPotential interpretation: areas with a low population density in central regions of the city (high pop density in surrounding neighbourhoods) have higher house prices. We could try testing this interpretation by including the distance to the city center as a control.\n\n\nAlso note how the air pollution coefficient has changed here, with a negative effect in the focal unit and positive one amonf the neighbouring units.\nAn alternative way of estimating the same model is lagging the covariates first.\n\n# Loop through vars and create lagged variables\nmsoa.spdf$log_POPDEN &lt;- log(msoa.spdf$POPDEN)\nmsoa.spdf$log_no2 &lt;- log(msoa.spdf$no2)\nmsoa.spdf$log_med_house_price &lt;- log(msoa.spdf$med_house_price)\n\nvars &lt;- c(\"log_med_house_price\", \"log_no2\", \"log_POPDEN\", \n          \"per_mixed\", \"per_asian\", \"per_black\", \"per_other\",\n          \"per_owner\", \"per_social\", \"pubs_count\")\nfor(v in vars){\n  msoa.spdf[, paste0(\"w.\", v)] &lt;- lag.listw(queens.lw,\n                                            var = st_drop_geometry(msoa.spdf)[, v])\n}\n\n# Alternatively:\nw_vars &lt;- create_WX(st_drop_geometry(msoa.spdf[, vars]),\n                    listw = queens.lw,\n                    prefix = \"w\")\n\nhead(w_vars)\n\n  w.log_med_house_price w.log_no2 w.log_POPDEN w.per_mixed\n1              12.98382  3.843750     4.662014    4.748368\n2              12.28730  3.098960     3.300901    3.978275\n3              12.21207  3.206338     4.009795    3.997487\n4              12.18176  3.169934     3.630360    2.759082\n5              12.11159  3.221203     3.993660    3.930061\n6              12.08393  3.217865     3.876070    3.419488\n  w.per_asian w.per_black w.per_other w.per_owner w.per_social\n1   23.899916    7.879758   3.2080074    25.75738     33.85580\n2   19.951593   10.451828   1.6368986    66.42278     15.75042\n3   20.793559   12.965863   1.7526693    58.72637     21.38169\n4    7.633439   12.135478   0.6992118    66.52519     19.70500\n5   12.791140   16.108948   1.3817357    53.05539     29.44022\n6    8.997514   15.312652   0.9611710    59.49460     23.81126\n  w.pubs_count\n1    8.5454545\n2    0.6666667\n3    0.2857143\n4    0.2000000\n5    0.4000000\n6    0.1666667\n\n\nAnd subsequently we use those new variables in a linear model.\n\nmod_1.lm &lt;- lm (log(med_house_price) ~ log(no2) + log(POPDEN) + \n                  per_mixed + per_asian + per_black + per_other +\n                  w.log_no2 + w.log_POPDEN +\n                  w.per_mixed + w.per_asian + w.per_black + w.per_other,\n                data = msoa.spdf)\nsummary(mod_1.lm)\n\n\nCall:\nlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other + w.log_no2 + \n    w.log_POPDEN + w.per_mixed + w.per_asian + w.per_black + \n    w.per_other, data = msoa.spdf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.50809 -0.16605 -0.01817  0.13055  1.09039 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  10.582440   0.153862  68.779  &lt; 2e-16 ***\nlog(no2)     -0.440727   0.181063  -2.434  0.01511 *  \nlog(POPDEN)  -0.076840   0.017345  -4.430 1.05e-05 ***\nper_mixed    -0.033042   0.011298  -2.925  0.00353 ** \nper_asian    -0.002381   0.001474  -1.615  0.10655    \nper_black    -0.016229   0.001801  -9.009  &lt; 2e-16 ***\nper_other    -0.020391   0.006564  -3.107  0.00195 ** \nw.log_no2     0.993602   0.199370   4.984 7.38e-07 ***\nw.log_POPDEN  0.113262   0.028752   3.939 8.76e-05 ***\nw.per_mixed   0.126069   0.014294   8.820  &lt; 2e-16 ***\nw.per_asian  -0.003828   0.001661  -2.305  0.02140 *  \nw.per_black  -0.018054   0.002241  -8.056 2.30e-15 ***\nw.per_other   0.048139   0.007971   6.039 2.20e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2262 on 970 degrees of freedom\nMultiple R-squared:  0.653, Adjusted R-squared:  0.6487 \nF-statistic: 152.1 on 12 and 970 DF,  p-value: &lt; 2.2e-16\n\n\nLooks pretty similar to lmSLX() results, and it should! A big advantage of the SLX specification is that we can use the lagged variables in basically all methods which take variables as inputs, such as non-linear models, matching algorithms, and machine learning tools.\nMoreover, using the lagged variables gives a high degree of freedom. For instance, we could (not saying that it necessarily makes sense):\n\nUse different weights matrices for different variables\nInclude higher order neighbours using nblag() (with an increasing number of orders we go towards a more global model, but we estimate a coefficient for each spillover, instead of estimating just one)\nUse machine learning techniques to determine the best fitting weights specification.\n\n4.4.4 SDEM\nSDEM models can be estimated using errorsarlm() with the additional option Durbin = TRUE.\n\nmod_1.sdem &lt;- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = TRUE) # we could here extend to SDEM\nsummary(mod_1.sdem)\n\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.617795 -0.106380 -0.014832  0.095826  0.927446 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                  Estimate Std. Error  z value  Pr(&gt;|z|)\n(Intercept)     10.4422703  0.3652148  28.5921 &lt; 2.2e-16\nlog(no2)        -0.2057493  0.1264914  -1.6266 0.1038248\nlog(POPDEN)     -0.0769743  0.0132094  -5.8272 5.635e-09\nper_mixed       -0.0222406  0.0079705  -2.7904 0.0052649\nper_asian       -0.0037484  0.0010054  -3.7284 0.0001927\nper_black       -0.0179751  0.0012383 -14.5161 &lt; 2.2e-16\nper_other       -0.0150218  0.0044895  -3.3460 0.0008199\nlag.log(no2)     1.0004491  0.1739833   5.7503 8.911e-09\nlag.log(POPDEN) -0.0054241  0.0327802  -0.1655 0.8685763\nlag.per_mixed    0.0669699  0.0169349   3.9545 7.668e-05\nlag.per_asian   -0.0018566  0.0015957  -1.1635 0.2446368\nlag.per_black   -0.0079949  0.0024833  -3.2195 0.0012842\nlag.per_other    0.0273378  0.0087430   3.1268 0.0017671\n\nLambda: 0.76173, LR test value: 455.7, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.024949\n    z-value: 30.531, p-value: &lt; 2.22e-16\nWald statistic: 932.15, p-value: &lt; 2.22e-16\n\nLog likelihood: 300.847 for error model\nML residual variance (sigma squared): 0.027504, (sigma: 0.16584)\nNumber of observations: 983 \nNumber of parameters estimated: 15 \nAIC: NA (not available for weighted model), (AIC for lm: -117.99)\n\n\nAnd this SDEM can be interpreted like a combination of SEM and SLX.\nFirst, we still see highly significant auto-correlation in the error term. However, it’s lower in magnitude now that we also include the \\(\\bm W X\\) terms.\nSecond, the coefficients tell a smimilar story as in the SLX (use the same interpretation), but some coefficient magnitudes have become smaller.\n\n4.4.5 SDM\nSDM models can be estimated using lagsarlm() with the additional option Durbin = TRUE.\n\nmod_1.sdm &lt;- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = TRUE) # we could here extend to SDM\nsummary(mod_1.sdm)\n\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.614314 -0.107947 -0.013509  0.092234  0.917398 \n\nType: mixed \nCoefficients: (asymptotic standard errors) \n                  Estimate Std. Error  z value  Pr(&gt;|z|)\n(Intercept)      2.7843426  0.2944721   9.4554 &lt; 2.2e-16\nlog(no2)        -0.3112762  0.1308101  -2.3796 0.0173312\nlog(POPDEN)     -0.0802866  0.0125213  -6.4120 1.436e-10\nper_mixed       -0.0368998  0.0081596  -4.5223 6.118e-06\nper_asian       -0.0033726  0.0010636  -3.1711 0.0015189\nper_black       -0.0159770  0.0013006 -12.2848 &lt; 2.2e-16\nper_other       -0.0209743  0.0047369  -4.4279 9.516e-06\nlag.log(no2)     0.4880923  0.1456778   3.3505 0.0008067\nlag.log(POPDEN)  0.0781188  0.0207600   3.7629 0.0001679\nlag.per_mixed    0.0640880  0.0104646   6.1243 9.110e-10\nlag.per_asian    0.0017665  0.0012101   1.4598 0.1443498\nlag.per_black    0.0070487  0.0017938   3.9295 8.511e-05\nlag.per_other    0.0284822  0.0057774   4.9299 8.226e-07\n\nRho: 0.73126, LR test value: 501.83, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.025889\n    z-value: 28.246, p-value: &lt; 2.22e-16\nWald statistic: 797.86, p-value: &lt; 2.22e-16\n\nLog likelihood: 323.9111 for mixed model\nML residual variance (sigma squared): 0.026633, (sigma: 0.1632)\nNumber of observations: 983 \nNumber of parameters estimated: 15 \nAIC: -617.82, (AIC for lm: -117.99)\nLM test for residual autocorrelation\ntest value: 36.704, p-value: 1.3747e-09\n\n\nAnd this SDM can be interpreted like a combination of SAR and SLX.\nFirst, there’s still substantial auto-correlation in \\(\\bm y\\), and this has become even stronger as compared to SAR.\nSecond, we can interpret the direction of the effect, but we cannot interpret the coefficient as marginal effects."
  },
  {
    "objectID": "05_regression-theory_short.html#estimation",
    "href": "05_regression-theory_short.html#estimation",
    "title": "\n4  Spatial Regression Models\n",
    "section": "\n4.5 Estimation",
    "text": "4.5 Estimation\nNote that most of the spatial model specifications can not be estimated by Least Squares (LS), as using (constrained) LS estimators for models containing a spatially lagged dependent variable or disturbance leads to inconsistent results (Anselin and Bera 1998; Franzese and Hays 2007). However, an extensive amount of econometric literature discusses different estimation methods based on (quasi-) maximum likelihood (Anselin 1988; Lee 2004; Ord 1975) or instrumental variable approaches using generalized methods of moments (Drukker, Egger, and Prucha 2013; Kelejian and Prucha 1998, 2010), in which the endogenous lagged variables can be instrumented by \\(q\\) higher order lags of the exogenous regressors \\(({\\bm X}, {\\bm W \\bm X}, {\\bm W^2 \\bm X},..., {\\bm W^q \\bm X})\\) (Kelejian and Prucha 1998).\n\n4.5.1 Simulataneity bias\nRemember what is happening when we estimate a spatial auto-regressive model.\n\nNote the circular process here: My \\(X\\) influences my \\(Y\\), which then influences your \\(Y\\), which then influences my \\(Y\\) again. We write this as\n$$\n    {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}.\n$$\nIf we ignore \\({\\bm X}{\\bm \\beta}\\) and write the pure auto-regressive term in its reduce form, we get:\n\\[\n\\bm y =\\left(\\bm I_n - \\rho\\bm W\\right)^{-1}\\varepsilon,\n\\]\nand the spatial lag term is\n\\[\n\\bm W \\bm y =\\bm W\\left(\\bm I_n - \\rho\\bm W\\right)^{-1}\\varepsilon.\n\\]\nThe OLS estimator for the spatial lag term then is\n\\[\n\\hat{\\rho}_{OLS} = \\left[\\underbrace{\\left(\\bm W\\bm y \\right)^\\top}_{(1\\times n)}\\underbrace{\\left(\\bm W\\bm y \\right)}_{(n\\times 1)}\\right]^{-1}\\underbrace{\\left(\\bm W\\bm y \\right)^\\top}_{(1\\times n)}\\underbrace{\\bm y}_{(n\\times 1)}.\n\\]\nIt can then be shown that the OLS estimators equals\n\\[\n          \\hat{\\rho}_{OLS} = \\rho + \\left[\\left(\\bm W\\bm y \\right)^\\top\\left(\\bm W\\bm y \\right)\\right]^{-1}\\left(\\bm W\\bm y \\right)^\\top\\varepsilon \\\\\n                                = \\rho + \\left(\\sum_{i = 1}^n \\bm y_{Li}^2\\right)^{-1}\\left(\\sum_{i = 1}^{n}\\bm y_{Li}\\epsilon_i\\right),\n\\]\nwith \\(\\bm y_{Li}\\) defined as the \\(i\\)th element of the spatial lag operator \\(\\bm W\\bm y = \\bm y_L\\). It can further be shown that the second part of the equation \\(\\neq 0\\), which demonstrates that OLS gives a biased estimate of \\(\\rho\\) (Franzese and Hays 2007; Sarrias 2023).\n\n\n\n\n\n\nWarning\n\n\n\nDo not estimate spatial lags of the dependent variable in OLS. It will suffer from simultaneity bias.\n\n\n\n4.5.2 Instrumental variable\nA potential way of estimating spatial lag /SAR models is 2SLS (Kelejian and Prucha 1998).\nWe start with our standard model\n\\[\n        {\\bm y}=\\alpha{\\bm \\iota}+\\rho{\\bm W}{\\bm y}+{\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}.\n\\]\nAs we have seen above, there is a problem of simultaneity: the “covariate” \\({\\bm W}{\\bm y}\\) is endogenous. One way of dealing with this endogeneity problem is the Instrumental Variable approach.\nSo, the question is what are good instruments \\(\\bm H\\) for \\({\\bm W}{\\bm y}\\)? As we have specified the mode, we are sure that \\({\\bm X}\\) determines \\({\\bm y}\\). Thus, it must be true that \\({\\bm W}{\\bm X}\\) and \\({\\bm W}^2{\\bm X},\\ldots, {\\bm W}^l{\\bm X}\\) determines \\({\\bm W}{\\bm y}\\).\nNote that \\({\\bm W}^l\\) denotes higher orders of \\({\\bm W}\\). So \\({\\bm W}^2\\) are the second order neighbours (neighbours of neighbours), and \\({\\bm W}^3\\) are the third order neighbours (the neighbours of my neighbour’s neighbours), and so on…\nWe will discuss this in more detail later, but note for now that the reduced form of the SAR always contains a series of higher order neighbours.\n\\[\n({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\n=({\\bm I_N} + \\rho{\\bm W} + \\rho^2{\\bm W}^2 + \\rho^3{\\bm W}^3 + ...)\\beta_k\n= ({\\bm I_N} + \\sum_{h=1}^\\infty \\rho^h{\\bm W}^h)\\beta_k .\n\\]\nThus, Kelejian and Prucha (1998) suggested to use a set of lagged covariates as instruments for \\(\\bm W \\bm Y\\):\n\\[\n\\bm H = \\bm X, \\bm W\\bm X, \\bm W^2\\bm X, ... , \\bm W^l\\bm X,\n\\]\nwhere \\(l\\) is a pre-defined number for the higher order neighbours included. In practice, \\(l\\) is usually restricted to \\(l=2\\).\nThis has further been developed by, for instance, using a (truncated) power series as instruments (Kelejian, Prucha, and Yuzefovich 2004):\n\\[\n\\bm H =\\left[\\bm X, \\bm W\\left(\\sum_{l = 1}^{\\infty}\\rho^{l}\\bm W^l\\right)\\bm X \\bm\\beta\\right].\n\\]\nWe can estimate this using the pacakge spatialreg with the function stsls(),\n\nmod_1.sls &lt;- stsls(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                     per_mixed + per_asian + per_black + per_other,  \n                   data = msoa.spdf, \n                   listw = queens.lw,\n                   robust = TRUE, #  heteroskedasticity robust SEs\n                   W2X = TRUE) # Second order neighbours are included as instruments (else only first)\nsummary(mod_1.sls)\n\n\nCall:\nstsls(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, robust = TRUE, W2X = TRUE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5464924 -0.1238002 -0.0052299  0.0989150  1.0793093 \n\nCoefficients: \n               Estimate HC0 std. Error z value  Pr(&gt;|z|)\nRho          0.71004211     0.04678235 15.1776 &lt; 2.2e-16\n(Intercept)  2.73582523     0.50997823  5.3646 8.113e-08\nlog(no2)     0.37752751     0.04920257  7.6729 1.688e-14\nlog(POPDEN) -0.05710992     0.01684036 -3.3913 0.0006957\nper_mixed    0.01634307     0.00588488  2.7771 0.0054842\nper_asian   -0.00205426     0.00045905 -4.4750 7.640e-06\nper_black   -0.01166456     0.00128557 -9.0734 &lt; 2.2e-16\nper_other   -0.00280423     0.00332302 -0.8439 0.3987377\n\nResidual variance (sigma squared): 0.035213, (sigma: 0.18765)"
  },
  {
    "objectID": "05_regression-theory_short.html#maximum-likelihood",
    "href": "05_regression-theory_short.html#maximum-likelihood",
    "title": "\n4  Spatial Regression Models\n",
    "section": "\n4.6 Maximum Likelihood",
    "text": "4.6 Maximum Likelihood\nMaximum Likelihood estimation of spatial models is the most common way of estimation. The procedure to estimate SAR models via ML is based on Ord (1975) and Anselin (1988). If you are interested in more details, please look at the more extensive 3-day workshop or have a look into Sarrias (2023).\nThe package spatialreg Pebesma and Bivand (2023) provides a series of functions to calculate the ML estimator for all spatial models we have considered.\nTable from Pebesma and Bivand (2023):\n\n\n\n\n\n\n\nmodel\nmodel name\nmaximum likelihood estimation function\n\n\n\nSEM\nspatial error\nerrorsarlm(..., Durbin=FALSE)\n\n\nSEM\nspatial error\nspautolm(..., family=\"SAR\")\n\n\nSDEM\nspatial Durbin error\nerrorsarlm(..., Durbin=TRUE)\n\n\nSLM\nspatial lag\nlagsarlm(..., Durbin=FALSE)\n\n\nSDM\nspatial Durbin\nlagsarlm(..., Durbin=TRUE)\n\n\nSAC\nspatial autoregressive combined\nsacsarlm(..., Durbin=FALSE)\n\n\nGNM\ngeneral nested\nsacsarlm(..., Durbin=TRUE)\n\n\n\nML SAR\n\nmod_1.sar &lt;- lagsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) + \n                        per_mixed + per_asian + per_black + per_other,  \n                      data = msoa.spdf, \n                      listw = queens.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.5281789 -0.1220524 -0.0099245  0.0992203  1.0936745 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)  3.17383180  0.29041604  10.9286 &lt; 2.2e-16\nlog(no2)     0.39705423  0.04452880   8.9168 &lt; 2.2e-16\nlog(POPDEN) -0.05583014  0.01242876  -4.4920 7.055e-06\nper_mixed    0.01851577  0.00579832   3.1933  0.001407\nper_asian   -0.00228346  0.00045876  -4.9775 6.442e-07\nper_black   -0.01263650  0.00100282 -12.6009 &lt; 2.2e-16\nper_other   -0.00161419  0.00289082  -0.5584  0.576582\n\nRho: 0.66976, LR test value: 473.23, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.025311\n    z-value: 26.461, p-value: &lt; 2.22e-16\nWald statistic: 700.19, p-value: &lt; 2.22e-16\n\nLog likelihood: 196.7203 for lag model\nML residual variance (sigma squared): 0.035402, (sigma: 0.18815)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: -375.44, (AIC for lm: 95.786)\nLM test for residual autocorrelation\ntest value: 8.609, p-value: 0.0033451\n\n\nML SEM\n\nmod_1.sem &lt;- errorsarlm(log(med_house_price) ~ log(no2) + log(POPDEN) +\n                          per_mixed + per_asian + per_black + per_other,  \n                        data = msoa.spdf, \n                        listw = queens.lw,\n                        Durbin = FALSE) # we could here extend to SDEM\nsummary(mod_1.sem)\n\n\nCall:\nerrorsarlm(formula = log(med_house_price) ~ log(no2) + log(POPDEN) + \n    per_mixed + per_asian + per_black + per_other, data = msoa.spdf, \n    listw = queens.lw, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.581785 -0.105218 -0.012758  0.094430  0.913425 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept) 12.92801104  0.35239139  36.6865 &lt; 2.2e-16\nlog(no2)     0.15735296  0.10880727   1.4462 0.1481317\nlog(POPDEN) -0.08316270  0.01254315  -6.6301 3.354e-11\nper_mixed   -0.03377962  0.00811054  -4.1649 3.115e-05\nper_asian   -0.00413115  0.00096849  -4.2656 1.994e-05\nper_black   -0.01653816  0.00126741 -13.0488 &lt; 2.2e-16\nper_other   -0.01693012  0.00462999  -3.6566 0.0002556\n\nLambda: 0.88605, LR test value: 623.55, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.015803\n    z-value: 56.068, p-value: &lt; 2.22e-16\nWald statistic: 3143.6, p-value: &lt; 2.22e-16\n\nLog likelihood: 271.8839 for error model\nML residual variance (sigma squared): 0.026911, (sigma: 0.16405)\nNumber of observations: 983 \nNumber of parameters estimated: 9 \nAIC: NA (not available for weighted model), (AIC for lm: 95.786)\n\n\n\n\n\n\n\n\nAnselin, Luc. 1988. Spatial Econometrics: Methods and Models. Studies in Operational Regional Science. Dordrecht: Kluwer.\n\n\nAnselin, Luc, and Anil K. Bera. 1998. “Spatial Dependence in Linear Regression Models with an Introduction to Spatial Econometrics.” In Handbook of Applied Economic Statistics, edited by Aman Ullah and David E. A. Giles, 237–89. New York: Dekker.\n\n\nBetz, Timm, Scott J. Cook, and Florian M. Hollenbach. 2020. “Spatial Interdependence and Instrumental Variable Models.” Political Science Research and Methods 8 (4): 646–61. https://doi.org/10.1017/psrm.2018.61.\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A Review of Software for Spatial Econometrics in R.” Mathematics 9 (11): 1276. https://doi.org/10.3390/math9111276.\n\n\nCook, Scott J., Jude C. Hays, and Robert J. Franzese. 2020. “Model Specification and Spatial Interdependence.” In The Sage Handbook of Research Methods in Political Science and International Relations, edited by Luigi Curini and Robert Franzese, 1st ed, 730–47. Thousand Oaks: SAGE Inc.\n\n\nDrukker, David M., Peter Egger, and Ingmar R. Prucha. 2013. “On Two-Step Estimation of a Spatial Autoregressive Model with Autoregressive Disturbances and Endogenous Regressors.” Econometric Reviews 32 (5-6): 686–733. https://doi.org/10.1080/07474938.2013.741020.\n\n\nFranzese, Robert J., and Jude C. Hays. 2007. “Spatial Econometric Models of Cross-Sectional Interdependence in Political Science Panel and Time-Series-Cross-Section Data.” Political Analysis 15 (2): 140–64. https://doi.org/10.1093/pan/mpm005.\n\n\nGibbons, Steve, and Henry G. Overman. 2012. “Mostly Pointless Spatial Econometrics?” Journal of Regional Science 52 (2): 172–91. https://doi.org/10.1111/j.1467-9787.2012.00760.x.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial Econometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nKelejian, Harry H., and Ingmar R. Prucha. 1998. “A Generalized Spatial Two-Stage Least Squares Procedure for Estimating a Spatial Autoregressive Model with Autoregressive Disturbances.” The Journal of Real Estate Finance and Economics 17 (1): 99–121. https://doi.org/10.1023/A:1007707430416.\n\n\n———. 2010. “Specification and Estimation of Spatial Autoregressive Models with Autoregressive and Heteroskedastic Disturbances.” Journal of Econometrics 157 (1): 53–67. https://doi.org/10.1016/j.jeconom.2009.10.025.\n\n\nKelejian, Harry H., Ingmar R. Prucha, and Yevgeny Yuzefovich. 2004. “Instrumental Variable Estimation of a Spatial Autoregressive Model with Autoregressive Disturbances: Large and Small Sample Results.” In Spatial and Spatiotemporal Econometrics, edited by James P. LeSage and R. Kelley Pace, 163–98. Advances in Econometrics. Amsterdam and Boston: Elsevier.\n\n\nLee, Lung-fei. 2004. “Asymptotic Distributions of Quasi-Maximum Likelihood Estimators for Spatial Autoregressive Models.” Econometrica 72 (6): 1899–1925.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nManski, Charles F. 1993. “Identification of Endogenous Social Effects: The Reflection Problem.” The Review of Economic Studies 60 (3): 531–42. https://doi.org/10.2307/2298123.\n\n\nOrd, John Keith. 1975. “Estimation Methods for Models of Spatial Interaction.” Journal of the American Statistical Association 70 (349): 120–26. https://doi.org/10.2307/2285387.\n\n\nPace, R. Kelley, and James P. LeSage. 2010. “Omitted Variable Biases of OLS and Spatial Lag Models.” In Progress in Spatial Analysis, edited by Antonio Páez, Julie Gallo, Ron N. Buliung, and Sandy Dall’erba, 17–28. Berlin and Heidelberg: Springer.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “Spatial Data Analysis.” arXiv. https://arxiv.org/abs/2402.09895.\n\n\nSarrias, Mauricio. 2023. Intermediate Spatial Econometrics with Applications in R.\n\n\nWimpy, Cameron, Guy D. Whitten, and Laron K. Williams. 2021. “X Marks the Spot: Unlocking the Treasure of Spatial-X Models.” The Journal of Politics 83 (2): 722–39. https://doi.org/10.1086/710089.\n\n\nWooldridge, Jeffrey M. 2010. Econometric Analysis of Cross Section and Panel Data. Cambridge, Mass.: MIT Press."
  },
  {
    "objectID": "07_impacts_short.html#coefficient-estimates-neq-marginal-effects",
    "href": "07_impacts_short.html#coefficient-estimates-neq-marginal-effects",
    "title": "\n5  Spatial Impacts\n",
    "section": "\n5.1 Coefficient estimates \\(\\neq\\) `marginal’ effects",
    "text": "5.1 Coefficient estimates \\(\\neq\\) `marginal’ effects\n\n\n\n\n\n\nWarning\n\n\n\nDo not interpret coefficients as marginal effects in SAR, SAC, and SDM!!\n\n\nAt first glance, the specifications presented above seem relatively similar in the way of modelling spatial effects. Yet, they differ in very important aspects.\nFirst, models with an endogenous spatial term (SAR, SAC, and SDM) assume a very different spatial dependence structure than models with only exogenous spatial terms as SLX and SDEM specifications. While the first three assume global spatial dependence, the second two assume local spatial dependence (Anselin 2003; Halleck Vega and Elhorst 2015; LeSage and Pace 2009).\nSecond, the interpretation of the coefficients differs greatly between models with and without endogenous effects. This becomes apparent when considering the reduced form of the equations above. Exemplary using the SAR model, the reduced form is given by:\n\\[\n\\begin{split}\n{\\bm y}-\\rho{\\bm W}{\\bm y} &={\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}, \\nonumber \\\\\n({\\bm I_N}-\\rho {\\bm W}){\\bm y} &={\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}\\nonumber, \\\\\n{\\bm y} &=({\\bm I_N}-\\rho {\\bm W})^{-1}({\\bm X}{\\bm \\beta}+ {\\bm \\varepsilon}),\n\\end{split}\n\\]\nwhere \\({\\bm I_N}\\) is an \\(N \\times N\\) diagonal matrix (diagonal elements equal 1, 0 otherwise). This contains no spatially lagged dependent variable on the right-hand side.\nIf we want to interpret coefficient, we are usually in marginal or partial effects (the association between a unit change in \\(X\\) and \\(Y\\)). We obtain these effects by looking at the first derivative.\nWhen taking the first derivative of the explanatory variable \\({\\bm x}_k\\) from the reduced form in (\\(\\ref{eq:sarred}\\)) to interpret the partial effect of a unit change in variable \\({\\bm x}_k\\) on \\({\\bm y}\\), we receive\n\\[\n\\frac{\\partial {\\bm y}}{\\partial {\\bm x}_k}=\\underbrace{({\\bm I_N}-\\rho {\\bm W})^{-1}}_{N \\times N}\\beta_k,\n\\]\nfor each covariate \\(k=\\{1,2,...,K\\}\\). As can be seen, the partial derivative with respect to \\({\\bm x}_k\\) produces an \\(N \\times N\\) matrix, thereby representing the partial effect of each unit \\(i\\) onto the focal unit \\(i\\) itself and all other units .\nNote that the diagonal elements of \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\) are not zero anymore (as they are in \\(\\bm W\\)). Look at the following minimal example:\n\\[\n\\begin{split}\n\\tilde{\\bm W} = \\begin{pmatrix}\n      0 & 1 & 0 & 1 & 0 \\\\\n      1 & 0 & 1 & 0 & 1 \\\\\n      0 & 1 & 0 & 1 & 0 \\\\\n      1 & 0 & 1 & 0 & 1 \\\\\n      0 & 1 & 0 & 1 & 0\n      \\end{pmatrix}, \\mathrm{and~normalized} ~\n\\bm W = \\begin{pmatrix}\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0\n      \\end{pmatrix}      \n\\end{split}\n\\]\nand\n\\[\n\\rho = 0.6,\n\\]\nthen\n\\[\n\\begin{split}\n\\rho \\bm W = \\begin{pmatrix}\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0\n      \\end{pmatrix}.\n\\end{split}\n\\]\nIf we want to get the total effect of \\(X\\) on \\(Y\\) we need to add the direct association within \\(i\\) and \\(j\\) and so on…\n\\[\n\\begin{split}\n\\bm I_N - \\rho \\bm W &=\n\\begin{pmatrix}\n      1 & 0 & 0 & 0 & 0 \\\\\n      0 & 1 & 0 & 0 & 0 \\\\\n      0 & 0 & 1 & 0 & 0 \\\\\n      0 & 0 & 0 & 1 & 0 \\\\\n      0 & 1 & 0 & 0 & 1\n      \\end{pmatrix} -\n\\begin{pmatrix}\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0 \\\\\n      0.2 & 0 & 0.2 & 0 & 0.2 \\\\\n      0 & 0.3 & 0 & 0.3 & 0\n      \\end{pmatrix}\\\\\n& = \\begin{pmatrix}\n      1 & -0.3 & 0 & -0.3 & 0 \\\\\n      -0.2 & 1 & -0.2 & 0 & -0.2 \\\\\n      0 & 0.3 & 1 & 0.3 & 0 \\\\\n      -0.2 & 0 & -0.2 & 1 & -0.2 \\\\\n      0 & -0.3 & 0 & -0.3 & 1\n      \\end{pmatrix}.\n\\end{split}\n\\]\nAnd finally we take the inverse of that\n\\[\n\\begin{split}\n(\\bm I_N - \\rho \\bm W)^{-1} &=\n\\begin{pmatrix}\n      1 & -0.3 & 0 & -0.3 & 0 \\\\\n      -0.2 & 1 & -0.2 & 0 & -0.2 \\\\\n      0 & 0.3 & 1 & 0.3 & 0 \\\\\n      -0.2 & 0 & -0.2 & 1 & -0.2 \\\\\n      0 & -0.3 & 0 & -0.3 & 1\n      \\end{pmatrix}^{-1}\\\\\n&=\n\\begin{pmatrix}\n      \\color{red}{1.1875} & 0.46875 & 0.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & \\color{red}{1.28125} & 0.3125 & 0.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & \\color{red}{1.1875} & 0.46875 & 0.1875 \\\\\n      0.3125 & 0.28125 & 0.3125 & \\color{red}{1.28125} & 0.3125 \\\\\n      0.1875 & 0.46875 & 0.1875 & 0.46875 & \\color{red}{1.1875}\n      \\end{pmatrix}.\n\\end{split}\n\\]\nAs you can see, \\((\\bm I_N - \\rho \\bm W)^{-1}\\) has \\(\\color{red}{diagonal~elements}\\) \\(&gt;1\\): these are feedback loops. My \\(X\\) influences my \\(Y\\) directly, but my \\(Y\\) then influences my neigbour’s \\(Y\\), which then influences my \\(Y\\) again (also also other neighbour’s \\(Y\\)s). Thus the influence of my \\(X\\) on my \\(Y\\) includes a spatial multiplier.\nCheck yourself:\n\nI = diag(5)\nrho = 0.6\nW = matrix(c(0 , 0.5 , 0 , 0.5 , 0,\n            1/3 , 0 , 1/3 , 0 , 1/3,\n            0 , 0.5 , 0 , 0.5 , 0,\n            1/3 , 0 , 1/3 , 0 , 1/3,\n            0 , 0.5 , 0 , 0.5 , 0), ncol = 5, byrow = TRUE)\n\n(IrW = I - rho*W)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  1.0 -0.3  0.0 -0.3  0.0\n[2,] -0.2  1.0 -0.2  0.0 -0.2\n[3,]  0.0 -0.3  1.0 -0.3  0.0\n[4,] -0.2  0.0 -0.2  1.0 -0.2\n[5,]  0.0 -0.3  0.0 -0.3  1.0\n\n# (I - rho*W)^-1\n(M = solve(IrW))\n\n       [,1]    [,2]   [,3]    [,4]   [,5]\n[1,] 1.1875 0.46875 0.1875 0.46875 0.1875\n[2,] 0.3125 1.28125 0.3125 0.28125 0.3125\n[3,] 0.1875 0.46875 1.1875 0.46875 0.1875\n[4,] 0.3125 0.28125 0.3125 1.28125 0.3125\n[5,] 0.1875 0.46875 0.1875 0.46875 1.1875\n\n\nThe diagonal elements of \\(M\\) indicate how each unit \\(i\\) influences itself (change of \\(x_i\\) on change of \\(y_i\\)), and each off-diagonal elements in column \\(j\\) represents the effect of \\(j\\) on each other unit \\(i\\) (change of \\(x_j\\) on change of \\(y_i\\)).\n\\[\n\\begin{split}\n\\begin{pmatrix}\n      1.1875 & \\color{red}{0.46875} & 0.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & 1.28125 & 0.3125 & 0.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & 1.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & 0.28125 & 0.3125 & 1.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & \\color{blue}{0.1875} & 0.46875 & 1.1875\n      \\end{pmatrix}.\n\\end{split}\n\\]\nFor instance, \\(\\color{red}{W_{12}}\\) indicates that unit 2 has an influence of 0.46875 on unit 1. On the other hand, \\(\\color{blue}{W_{53}}\\) indicates that unit 3 has an influence of magnitude 0.1875 on unit 5.\n\n\n\n\n\n\nQuestion\n\n\n\nWhy does unit 3 have any effect o unit 5? According to \\(\\bm W\\) those two units are no neighbours \\(w_{53} = 0\\)!"
  },
  {
    "objectID": "07_impacts_short.html#global-and-local-spillovers",
    "href": "07_impacts_short.html#global-and-local-spillovers",
    "title": "\n5  Spatial Impacts\n",
    "section": "\n5.2 Global and local spillovers",
    "text": "5.2 Global and local spillovers\nThe kind of indirect spillover effects in SAR, SAC, and SDM models differs from the kind of indirect spillover effects in SLX and SDEM models: while the first three specifications represent global spillover effects, the latter three represent local spillover effects (Anselin 2003; LeSage and Pace 2009; LeSage 2014).\n\n5.2.1 Local spillovers\nIn case of SLX and SDEM the spatial spillover effects can be interpreted as the effect of a one unit change of \\({\\bm x}_k\\) in the spatially weighted neighbouring observations on the dependent variable of the focal unit: the weighted average among neighbours; when using a row-normalised contiguity weights matrix, \\({\\bm W} {\\bm x}_k\\) is the mean value of \\({\\bm x}_k\\) in the neighbouring units.\nAssume we have \\(k =2\\) covariates, then\n\\[\n\\begin{split}\n\\underbrace{\\bm W}_{N \\times N}  \\underbrace{\\bm X}_{N \\times 2} \\underbrace{\\bm \\theta}_{2 \\times 1} & =\n\\begin{pmatrix}\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0 \\\\\n      0.33 & 0 & 0.33 & 0 & 0.33 \\\\\n      0 & 0.5 & 0 & 0.5 & 0\n  \\end{pmatrix}\n  \\begin{pmatrix}\n      3 & 100 \\\\\n      4 & 140 \\\\\n      1 & 200 \\\\\n      7 & 70  \\\\\n      5 & 250\n  \\end{pmatrix}\n    \\begin{pmatrix}\n      \\theta_1 \\\\\n      \\theta_2\n  \\end{pmatrix}\\\\\n& =   \n\\begin{pmatrix}\n      6 & 105 \\\\\n      3 & 190 \\\\\n      6 & 105 \\\\\n      3 & 190  \\\\\n      6 & 105\n  \\end{pmatrix}\n\\begin{pmatrix}\n      \\theta_1 \\\\\n      \\theta_2\n  \\end{pmatrix}\\\\\n\\end{split}\n\\]\n\nX &lt;- cbind(x1 = c(3,4,1,8,5),\n           x2 = c(100,140,200,70,270))\n(WX &lt;-  W %*% X)\n\n     x1  x2\n[1,]  6 105\n[2,]  3 190\n[3,]  6 105\n[4,]  3 190\n[5,]  6 105\n\n\nThus, only direct neighbours – as defined in \\({\\bm W}\\) – contribute to those local spillover effects. The \\(\\hat{\\bm\\theta}\\) coefficients only estimate how my direct neighbour’s \\(\\bm X\\) values influence my own outcome \\(\\bm y\\).\nThere are no higher order neighbours involved (as long as we do not model them), nor are there any feedback loops due to interdependence.\n\n5.2.2 Global spillovers\nIn contrast, spillover effects in SAR, SAC, and SDM models do not only include direct neighbours but also neighbours of neighbours (second order neighbours) and further higher-order neighbours. This can be seen by rewriting the inverse \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\) as power series:A power series of \\(\\sum\\nolimits_{k=0}^\\infty {\\bm W}^k\\) converges to \\(({\\bm I}-{\\bm W})^{-1}\\) if the maximum absolute eigenvalue of \\({\\bm W} &lt; 1\\), which is ensured by standardizing \\({\\bm W}\\).}\n\\[\n\\begin{split}\n({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\n=({\\bm I_N} + \\rho{\\bm W} + \\rho^2{\\bm W}^2 + \\rho^3{\\bm W}^3 + ...)\\beta_k\n= ({\\bm I_N} + \\sum_{h=1}^\\infty \\rho^h{\\bm W}^h)\\beta_k ,\n\\end{split}\n\\]\nwhere the identity matrix represents the direct effects and the sum represents the first and higher order indirect effects and the above mentioned feedback loops. This implies that a change in one unit \\(i\\) does not only affect the direct neighbours but passes through the whole system towards higher-order neighbours, where the impact declines with distance within the neighbouring system. Global indirect impacts thus are `multiplied’ by influencing direct neighbours as specified in \\(\\bm W\\) and indirect neighbours not connected according to \\(\\bm W\\), with additional feedback loops between those neighbours.\n\\[\n\\begin{split}\n\\underbrace{(\\underbrace{\\bm I_N}_{N \\times N} - \\underbrace{\\rho}_{\\hat{=} 0.6} \\underbrace{\\bm W}_{N \\times N})^{-1}}_{N \\times N} \\beta_k\n&=\n\\begin{pmatrix}\n      1.\\color{red}{1875} & 0.46875 & 0.1875 & 0.46875 & 0.1875 \\\\\n      0.3125 & 1.\\color{red}{28125} & 0.3125 & 0.28125 & 0.3125 \\\\\n      0.1875 & 0.46875 & 1.\\color{red}{1875} & 0.46875 & 0.1875 \\\\\n      0.3125 & 0.28125 & 0.3125 & 1.\\color{red}{28125} & 0.3125 \\\\\n      0.1875 & 0.46875 & 0.1875 & 0.46875 & 1.\\color{red}{1875}\n      \\end{pmatrix}\n  \\begin{matrix}\n      (\\beta_1 + \\beta_2)\\\\\n  \\end{matrix}\\\\.\n\\end{split}\n\\]\nAll diagonal elements of \\(\\mathrm{diag}({\\bm W})=w_{ii}=0\\). However, diagonal elements of higher order neighbours are not zero \\(\\mathrm{diag}({\\bm W}^2)=\\mathrm{diag}({\\bm W}{\\bm W})\\neq0\\).\nIntuitively, \\(\\rho{\\bm W}\\) only represents the effects between direct neighbours (and the focal unit is not a neighbour of the focal unit itself), whereas \\(\\rho^2{\\bm W}^2\\) contains the effects of second order neighbours, where the focal unit is a second order neighbour of the focal unit itself. Thus, \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\\) includes feedback effects from \\(\\rho^2{\\bm W}^2\\) on (they are part of the direct impacts according to the summary measures below). This is way the diagonal above \\(\\geq 1\\).\nIn consequence, local and global spillover effects represent two distinct kinds of spatial spillover effects (LeSage 2014). The interpretation of local spillover effects is straightforward: it represents the effect of all neighbours as defined by \\({\\bm W}\\) (the average over all neighbours in case of a row-normalised weights matrix).\nFor instance, the environmental quality in the focal unit itself but also in neighbouring units could influence the attractiveness of a district and its house prices. In this example it seems reasonable to assume that we have local spillover effects: only the environmental quality in directly contiguous units (e.g. in walking distance) is relevant for estimating the house prices.\nIn contrast, interpreting global spillover effects can be a bit more difficult. Intuitively, the global spillover effects can be seen as a kind of diffusion process. For example, an exogenous event might increase the house prices in one district of a city, thus leading to an adaptation of house prices in neighbouring districts, which then leads to further adaptations in other units (the neighbours of the neighbours), thereby globally diffusing the effect of the exogenous event due to the endogenous term.\nYet, those processes happen over time. In a cross-sectional framework, the global spillover effects are hard to interpret. Anselin (2003) proposes an interpretation as an equilibrium outcome, where the partial impact represents an estimate of how this long-run equilibrium would change due to a change in \\({\\bm x}_k\\) (LeSage 2014)."
  },
  {
    "objectID": "07_impacts_short.html#summary-impact-measures",
    "href": "07_impacts_short.html#summary-impact-measures",
    "title": "\n5  Spatial Impacts\n",
    "section": "\n5.3 Summary impact measures",
    "text": "5.3 Summary impact measures\nNote that the derivative in SAR, SAC, and SDM is a \\(N \\times N\\) matrix, returning individual effects of each unit on each other unit, differentiated in direct, indirect, and total impacts.\n\\[\n\\begin{split}\n(\\bm I_N - \\rho \\bm W)^{-1} \\beta &=\n\\begin{pmatrix}\n      \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875}\n      \\end{pmatrix} \\beta\n\\end{split}\n\\]\nHowever, the individual effects (how \\(i\\) influences \\(j\\)) mainly vary because of variation in \\({\\bm W}\\). \n\n\n\n\n\n\nDo not interpret these as “estimated” individual impacts\n\n\n\nWe estimate two scalar parameters in a SAR model: \\(\\beta\\) for the direct coefficient and \\(rho\\) for the auto-regressive parameter.\nAll variation in the effects matrix \\((\\bm I_N - \\rho \\bm W)^{-1}\\) comes from the relationship in \\(\\bm W\\) which we have given a-priori!\n\n\nSince reporting the individual partial effects is usually not of interest, LeSage and Pace (2009) proposed to average over these effect matrices. While the average diagonal elements of the effects matrix \\((\\bm I_N - \\rho \\bm W)^{-1}\\) represent the so called direct impacts of variable \\({\\bm x}_k\\), the average column-sums of the off-diagonal elements represent the so called indirect impacts (or spatial spillover effects).\ndirect impacts refer to an average effect of a unit change in \\(x_i\\) on \\(y_i\\), and the indirect (spillover) impacts indicate how a change in \\(x_i\\), on average, influences all neighbouring units \\(y_j\\).\nThough previous literature (Halleck Vega and Elhorst 2015; LeSage and Pace 2009) has established the notation of direct and indirect impacts, it is important to note that also the direct impacts comprise a spatial `multiplier’ component if we specify an endogenous lagged depended variable, as a change in \\(\\bm x_i\\) influences \\(\\bm y_i\\), which influences \\(\\bm y_j\\), which in turn influences \\(\\bm y_i\\).\nUsually, one should use summary measures to report effects in spatial models (LeSage and Pace 2009). Halleck Vega and Elhorst (2015) provide a nice summary of the impacts for each model:\n\n\n\n\n\n\n\n\nModel\nDirect Impacts\nIndirect Impacts\ntype\n\n\n\nOLS/SEM\n\\(\\beta_k\\)\n–\n–\n\n\nSAR/SAC\n\nDiagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\beta_k\\)\n\n\nOff-diagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\beta_k\\)\n\nglobal\n\n\nSLX/SDEM\n\\(\\beta_k\\)\n\\(\\theta_k\\)\nlocal\n\n\nSDM\n\nDiagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\left[\\beta_k+{\\bm W}\\theta_k\\right]\\)\n\n\nOff-diagonal elements of \\(({\\bm I}-\\rho{\\bm W})^{-1}\\left[\\beta_k+{\\bm W}\\theta_k\\right]\\)\n\nglobal\n\n\n\n\\[\n\\begin{split}\n(\\bm I_N - \\rho \\bm W)^{-1} \\beta &=\n\\begin{pmatrix}\n      \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} \\\\\n      \\color{blue}{0.3125} & \\color{blue}{0.28125} & \\color{blue}{0.3125} & \\color{red}{1.28125} & \\color{blue}{0.3125} \\\\\n      \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{blue}{0.1875} & \\color{blue}{0.46875} & \\color{red}{1.1875}\n      \\end{pmatrix} \\beta\n\\end{split}\n\\]\nThe different indirect effects / spatial effects mean conceptually different things:\n\nGlobal spillover effects: SAR, SAC, SDM\nLocal spillover effects: SLX, SDEM\n\n\n\n\n\n\n\nCommon ratio between direct and indirect impacts in SAR and SAC\n\n\n\nNote that impacts in SAR only estimate one single spatial multiplier coefficient. Thus direct and indirect impacts are bound to a common ratio, say \\(\\phi\\), across all covariates.\nif \\(\\beta_1^{direct} = \\phi\\beta_1^{indirect}\\), then \\(\\beta_2^{direct} = \\phi\\beta_2^{indirect}\\), \\(\\beta_k^{direct} = \\phi\\beta_k^{indirect}\\).\n\n\nWe can calculate these impacts using impacts() with simulated distributions, e.g. for the SAR model:\n\nmod_1.sar.imp &lt;- impacts(mod_1.sar, listw = queens.lw, R = 300)\nsummary(mod_1.sar.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (lag, exact):\n                  Direct     Indirect        Total\nlog(no2)     0.447853184  0.754466618  1.202319802\nlog(POPDEN) -0.062973027 -0.106086209 -0.169059236\nper_mixed    0.020884672  0.035182931  0.056067603\nper_asian   -0.002575602 -0.004338934 -0.006914536\nper_black   -0.014253206 -0.024011369 -0.038264575\nper_other   -0.001820705 -0.003067212 -0.004887917\n========================================================\nSimulation results ( variance matrix):\n========================================================\nSimulated standard errors\n                  Direct     Indirect       Total\nlog(no2)    0.0471443896 0.0961388132 0.131847219\nlog(POPDEN) 0.0144486774 0.0264169250 0.040078741\nper_mixed   0.0063828981 0.0112090011 0.017397327\nper_asian   0.0005440795 0.0008713069 0.001374171\nper_black   0.0010517710 0.0021671020 0.002690620\nper_other   0.0034401571 0.0059775541 0.009405043\n\nSimulated z-values:\n                 Direct    Indirect       Total\nlog(no2)      9.6647056   7.9517091   9.2539269\nlog(POPDEN)  -4.4602546  -4.1027782  -4.3122004\nper_mixed     3.2546484   3.1143407   3.2006491\nper_asian    -4.7957945  -5.0017765  -5.0702380\nper_black   -13.5797030 -11.0435775 -14.2031561\nper_other    -0.5260023  -0.5305485  -0.5296002\n\nSimulated p-values:\n            Direct     Indirect   Total     \nlog(no2)    &lt; 2.22e-16 1.7764e-15 &lt; 2.22e-16\nlog(POPDEN) 8.1862e-06 4.0822e-05 1.6164e-05\nper_mixed   0.0011353  0.0018436  0.0013712 \nper_asian   1.6203e-06 5.6804e-07 3.9732e-07\nper_black   &lt; 2.22e-16 &lt; 2.22e-16 &lt; 2.22e-16\nper_other   0.5988866  0.5957317  0.5963891 \n\n# Alternative with traces (better for large W)\nW &lt;- as(queens.lw, \"CsparseMatrix\")\ntrMatc &lt;- trW(W, type = \"mult\",\n              m = 30) # number of powers\nmod_1.sar.imp2 &lt;- impacts(mod_1.sar, \n                          tr = trMatc, # trace instead of listw\n                          R = 300, \n                          Q = 30) # number of power series used for approximation\nsummary(mod_1.sar.imp2, zstats = TRUE, short = TRUE)\n\nImpact measures (lag, trace):\n                  Direct     Indirect        Total\nlog(no2)     0.447853101  0.754459497  1.202312598\nlog(POPDEN) -0.062973015 -0.106085208 -0.169058223\nper_mixed    0.020884668  0.035182599  0.056067267\nper_asian   -0.002575601 -0.004338893 -0.006914494\nper_black   -0.014253203 -0.024011142 -0.038264346\nper_other   -0.001820704 -0.003067183 -0.004887888\n========================================================\nSimulation results ( variance matrix):\n========================================================\nSimulated standard errors\n                  Direct     Indirect       Total\nlog(no2)    0.0472008856 0.0899006803 0.126171687\nlog(POPDEN) 0.0135389561 0.0248391431 0.037622110\nper_mixed   0.0062657311 0.0113397782 0.017422033\nper_asian   0.0005111060 0.0008235602 0.001296933\nper_black   0.0009411836 0.0021719937 0.002625997\nper_other   0.0032185481 0.0055195057 0.008729329\n\nSimulated z-values:\n                 Direct    Indirect       Total\nlog(no2)      9.4873263   8.4208512   9.5492934\nlog(POPDEN)  -4.6251393  -4.2721683  -4.4850370\nper_mixed     3.3302710   3.1263263   3.2325980\nper_asian    -5.0644833  -5.2949991  -5.3582105\nper_black   -15.1162453 -11.0781735 -14.5807020\nper_other    -0.5394061  -0.5460176  -0.5441257\n\nSimulated p-values:\n            Direct     Indirect   Total     \nlog(no2)    &lt; 2.22e-16 &lt; 2.22e-16 &lt; 2.22e-16\nlog(POPDEN) 3.7435e-06 1.9358e-05 7.2901e-06\nper_mixed   0.00086762 0.0017701  0.0012267 \nper_asian   4.0951e-07 1.1902e-07 8.4050e-08\nper_black   &lt; 2.22e-16 &lt; 2.22e-16 &lt; 2.22e-16\nper_other   0.58960667 0.5850538  0.5863550 \n\n\nThe indirect effects in SAR, SAC, and SDM refer to global spillover effects. This means a change of \\(x\\) in the focal units flows through the entire system of neighbours (direct nieightbours, neighbours of neighbours, …) influencing ‘their \\(y\\)’. One can think of this as diffusion or a change in a long-term equilibrium.\nIf Log NO2 increases by one unit, this increases the house price in the focal unit by 0.448 units. Overall, a one unit change in log NO2 increases the house prices in the entire neighbourhood system (direct and higher order neighbours) by 0.754.\nFor SLX models, nothing is gained from computing the impacts, as they equal the coefficients. Again, it’s the effects of direct neighbours only.\n\nprint(impacts(mod_1.slx, listw = queens.lw))\n\nImpact measures (SlX, glht):\n                  Direct     Indirect        Total\nlog(no2)    -0.440727458  0.993602103  0.552874645\nlog(POPDEN) -0.076839828  0.113262218  0.036422390\nper_mixed   -0.033042221  0.126068686  0.093026466\nper_asian   -0.002380698 -0.003828126 -0.006208824\nper_black   -0.016229407 -0.018053503 -0.034282910\nper_other   -0.020391354  0.048139008  0.027747654"
  },
  {
    "objectID": "07_impacts_short.html#examples",
    "href": "07_impacts_short.html#examples",
    "title": "\n5  Spatial Impacts\n",
    "section": "\n5.4 Examples",
    "text": "5.4 Examples\nBoillat, Ceddia, and Bottazzi (2022)\nThe paper investigates the effects of protected areas and various land tenure regimes on deforestation and possible spillover effects in Bolivia, a global tropical deforestation hotspot.\n\nProtected areas – which in Bolivia are all based on co-management schemes - also protect forests in adjacent areas, showing an indirect protective spillover effect. Indigenous lands however only have direct forest protection effects.\nFischer et al. (2009)\nThe focus of this paper is on the role of human capital in explaining labor productivity variation among 198 European regions within a regression framework.\n\nA ceteris paribus increase in the level of human capital is found to have a significant and positive direct impact. But this positive direct impact is offset by a significant and negative indirect (spillover) impact leading to a total impact that is not significantly different from zero.\nThe intuition here arises from the notion that it is relative regional advantages in human capital that matter most for labor productivity, so changing human capital across all regions should have little or no total impact on (average) labor productivity levels.\nRüttenauer (2018)\nThis study investigates the presence of environmental inequality in Germany - the connection between the presence of foreign-minority population and objectively measured industrial pollution.\n\nResults reveal that the share of minorities within a census cell indeed positively correlates with the exposure to industrial pollution. Furthermore, spatial spillover effects are highly relevant: the characteristics of the neighbouring spatial units matter in predicting the amount of pollution. Especially within urban areas, clusters of high minority neighbourhoods are affected by high levels of environmental pollution."
  },
  {
    "objectID": "07_impacts_short.html#comparing-and-selecting-models",
    "href": "07_impacts_short.html#comparing-and-selecting-models",
    "title": "\n5  Spatial Impacts\n",
    "section": "\n5.5 Comparing and Selecting Models",
    "text": "5.5 Comparing and Selecting Models\nAs we have seen, a variety of spatial model specifications exist that can be used to account for the spatial structure of the data. Thus, selecting the correct model specification remains a crucial task in applied research.\nOne way of selecting the model specification is the application of empirical specification tests. In general, there are two different strategies: a specific-to-general or a general-to-specific approach (Florax, Folmer, and Rey 2003; Mur and Angulo 2009).\n\n5.5.1 Specific-to-general\nThe specific-to-general approach is more common in spatial econometrics. This approach starts with the most basic non-spatial model and tests for possible misspecifications due to omitted autocorrelation in the error term or the dependent variable.\nAnselin et al. (1996) proposed to use Lagrange multiplier (LM) tests for the hypotheses \\(H_0\\): \\(\\lambda=0\\) and \\(H_0\\): \\(\\rho=0\\), which are robust against the alternative source of spatial dependence.\nLagrange Multiplier Test\nWe have earlier talked about methods to detect auto-correlation – visualisation and Moran’s I. Both methodscan tell us that there is spatial autocorrelation. However, both method do not provide any information on why there is autocorrelation. Possible reasons:\n\nInterdependence (\\(\\rho\\))\nClustering on unobservables (\\(\\lambda\\))\nSpillovers in covariates (\\(\\bm \\theta\\))\n\nLagrange Multiplier test (Anselin et al. 1996):\n\n(Robust) test for spatial lag dependence \\(LM_\\rho^*\\)\n(Robust) test for spatial error dependence \\(LM_\\lambda^*\\)\n\nRobust test for lag dependence: \\(H_0\\): \\(\\rho=0\\) \\[\n        LM_\\rho^* = G^{-1} \\hat{\\sigma}_\\epsilon^2\n        \\big(\\frac{ \\hat{\\bm\\epsilon}^\\intercal \\bm{Wy}}{\\hat{\\sigma}_\\epsilon^2}\n        - \\frac{\\hat{\\bm \\epsilon}^\\intercal \\bm{W\\hat{\\epsilon}}}{\\hat{\\sigma}_\\epsilon^2} \\big)^2 \\sim \\chi^2\n\\] \nRobust test for error dependence: \\(H_0\\): \\(\\lambda=0\\)\n\\[\n        LM_\\lambda^* = \\frac{\n        \\big( \\hat{\\bm\\epsilon}^\\intercal \\bm{W\\hat{\\epsilon}} / \\hat{\\sigma}_\\epsilon^2        \n        - [T\\hat{\\sigma}_\\epsilon^2(G + T\\hat{\\sigma}_\\epsilon^2)^{-1}]\n         \\hat{\\bm\\epsilon}^\\intercal \\bm{Wy} / \\hat{\\sigma}_\\epsilon^2 \\big)^2\n        }{\n        T[1 - \\frac{\\hat{\\sigma}_\\epsilon^2}{G + \\hat{\\sigma}_\\epsilon^2}]\n        } \\sim \\chi^2\n\\] with \\[\n\\begin{split}\n     G &= (\\bm{WX\\hat{\\beta}})^\\intercal (\\bm I - \\bm X (\\bm X^\\intercal\\bm X)^{-1} \\bm X^\\intercal) (\\bm{WX\\hat{\\beta}})   \\\\\n     T &= \\tr[(\\bm W^\\intercal + \\bm W)\\bm W],\n\\end{split}     \n\\] where \\(\\tr(\\bm A)\\) is the sum of the main diagonal of any square matrix \\(\\bm A\\).\nProblem\nThe specific-to-general approach based on the robust LM test offers a good performance in distinguishing between SAR, SEM, and non-spatial OLS (Florax, Folmer, and Rey 2003).\nStill, in their original paper, Anselin et al. (1996) already note the declining power of the robust LM\\(_\\lambda\\) test for spatial error dependence with increasing autocorrelation in the dependent variable (indicating some uncertainty under a SAC-like DGP).\nMur and Angulo (2009) demonstrate strong drawbacks of the specific-to-general approach under non-optimal conditions like heteroscedasticity or endogeneity.\nMoreover, the test disregard the presence of spatial dependence from local spillover effects (\\(\\theta\\) is assumed to be zero), as resulting from an SLX-like process. Cook, Hays, and Franzese (2020), for instance, show theoretically that an SLX-like dependence structure leads to the rejection of both hypotheses \\(H_0\\): \\(\\lambda=0\\) and \\(H_0\\): \\(\\rho=0\\), though no autocorrelation is present (Elhorst and Halleck Vega 2017; Rüttenauer 2022).\n\n5.5.2 General-to-specific approach\nThe general-to-specific approach depicts the opposite method of specification search. This approach starts with the most general model and stepwise imposes restrictions on the parameters of this general model.\n\n\nHalleck Vega and Elhorst (2015): Nesting of different Spatial Econometric Model Specifications\n\nIn theory, we would\n\nstart with a GNS specification and\nsubsequently restrict the model to simplified specifications based on the significance of parameters in the GNS.\n\nThe problem with this strategy is that the GNS is only weakly identified and, thus, is of little help in selecting the correct restrictions (Burridge, Elhorst, and Zigova 2016).\nThe most intuitive alternative would be to start with one of the two-source models SDM, SDEM, or SAC. This, however, bears the risk of imposing the wrong restriction in the first place (Cook, Hays, and Franzese 2020). Furthermore, Cook, Hays, and Franzese (2020) show that more complicated restrictions are necessary to derive all single-source models from SDEM or SAC specifications.\n\n5.5.3 General advice?\nLeSage and Pace (2009), LeSage (2014), Elhorst (2014) argue that there are strong analytical reasons to restrict the model specifications to a subset, as the SDM subsumes the SLX and SAR model, and the SDEM subsumes SLX and SEM.\nIt is easily observed that SDM reduces to SLX if \\(\\rho=0\\) and to SAR if \\({\\bm \\theta}=0\\), while the SDEM reduces to SLX if \\(\\lambda=0\\) and to SEM if \\({\\bm \\theta}=0\\). Less intuitively, (Anselin 1988) has also shown that the SDM subsumes the SEM. Therefore, we can express the reduced form and rearrange terms:\n\\[\n\\begin{split}\n{\\bm y}&= {\\bm X}{\\bm \\beta} + ({\\bm I_N}-\\lambda {\\bm W})^{-1}{\\bm \\varepsilon} \\\\\n({\\bm I_N}-\\lambda {\\bm W}){\\bm y}&= ({\\bm I_N}-\\lambda {\\bm W}){\\bm X}{\\bm \\beta} + {\\bm \\varepsilon} \\\\\n({\\bm I_N}-\\lambda {\\bm W}){\\bm y}&={\\bm X}{\\bm \\beta} -\\lambda{\\bm W}{\\bm X}{\\bm \\beta} + {\\bm \\varepsilon} \\\\\n{\\bm y}&=({\\bm I_N}-\\lambda {\\bm W})^{-1}({\\bm X}{\\bm \\beta} + {\\bm W}{\\bm X}{\\bm \\theta} + {\\bm \\varepsilon}).\n\\end{split}\n\\]\nThus, the SEM constitutes a special case of an SDM with the relative simple restriction \\({\\bm \\theta}=-\\lambda{\\bm \\beta}\\), meaning direct and indirect effects are constrained to a common factor (Anselin 1988, 2003).\nThe fact that SDM subsumes SAR, SLX, and SEM leads to the conclusion that applied research should only consider SDM and SDEM as model specifications (LeSage 2014). Especially in the case of a likely omitted variable bias, (LeSage and Pace 2009, ~68) argue in favour of using the SDM.\nNonetheless, others propose to use the SLX specification as point of departure (Gibbons and Overman 2012; Halleck Vega and Elhorst 2015). First, scholars have argued that SAC and SDM models are only weakly identified in practice (Gibbons and Overman 2012; Pinkse and Slade 2010). Second, the global spillover specification in SAR, SAC, and SDM often seems to be theoretically implausible.\nAnd finally:\n\n\n“I will use spatial lags of X, not spatial lags of Y”, J. Wooldridge on twitter\n\n\n5.5.4 Design and Theory\nSome argue that the best way of choosing the appropriate model specification is to exclude one or more sources of spatial dependence – autocorrelation in the dependent variable, autocorrelation in the disturbances, or spatial spillover effects of the covariates – by design Gibbons, Overman, and Patacchini (2015).\nNatural experiments are probably the best way of making one or more sources of spatial dependence unlikely, thereby restricting the model alternatives to a subset of all available models. However, the opportunities to use natural experiments are restricted in social sciences, making it a favourable but often impractical way of model selection.\nCook, Hays, and Franzese (2020) and Rüttenauer (2022) argue that theoretical considerations should guide the model selection.\n\nRule out some sources of spatial dependence by theory, and thus restrict the specifications to a subset ( Where does the spatial dependence come from? ),\nTheoretical mechanisms may guide the choice of either global or local spillover effects.\n\n5.5.5 SLX is robust\nRüttenauer (2022) provides Monte Carlo experiments on how different spatial models perform under different scenarios of misspecification. SLX - despite its simplicity - does a very good job even if it is the wrong model for the specific situation. I personally advice for SLX (or SDEM) as the most useful specification if you do not have theoretical assumptions about spatial interdependence in the outcome.\nHaving a spatially lagged dependent variable comes with an extra layer of complexity. I suggest to only use these models if you have a-priori reasons to believe that it is the correct specification for your study.\n\n\nBias of impacts and 95% confidence interval of empirical standard deviation without omv: \\({\\bm \\beta}=(0.2, 0.5)^\\intercal\\), \\({\\bm \\gamma}=(0, 0)^\\intercal\\). \\(\\rho=\\) autocorrelation in the dependent variable (\\(\\bm W \\bm y\\)); \\(\\bm \\delta=\\) autocorrelation in the covariates (\\(\\bm x_k = f(\\bm W \\bm x_k)\\)); \\(\\lambda=\\) autocorrelation in the disturbances (\\(\\bm W \\bm u\\)); \\(\\bm \\theta=\\) spatial spillover effects of covariates (\\(\\bm W \\bm X\\)); \\(\\bm\\gamma=\\) strength of omv.\n\n\n\n\n\n\n\nAnselin, Luc. 1988. Spatial Econometrics: Methods and Models. Studies in Operational Regional Science. Dordrecht: Kluwer.\n\n\n———. 2003. “Spatial Externalities, Spatial Multipliers, and Spatial Econometrics.” International Regional Science Review 26 (2): 153–66. https://doi.org/10.1177/0160017602250972.\n\n\nAnselin, Luc, Anil K. Bera, Raymond Florax, and Mann J. Yoon. 1996. “Simple Diagnostic Tests for Spatial Dependence.” Regional Science and Urban Economics 26 (1): 77–104. https://doi.org/10.1016/0166-0462(95)02111-6.\n\n\nBoillat, Sébastien, M. Graziano Ceddia, and Patrick Bottazzi. 2022. “The Role of Protected Areas and Land Tenure Regimes on Forest Loss in Bolivia: Accounting for Spatial Spillovers.” Global Environmental Change 76 (September): 102571. https://doi.org/10.1016/j.gloenvcha.2022.102571.\n\n\nBurridge, Peter, J. Paul Elhorst, and Katarina Zigova. 2016. “Group Interaction in Research and the Use of General Nesting Spatial Models.” In Spatial Econometrics: Qualitative and Limited Dependent Variables, edited by Badi H. Baltagi, James P. LeSage, and R. Kelley Pace, 37:223–58. Advances in Econometrics. Emerald Group Publishing Limited. https://doi.org/10.1108/S0731-905320160000037016.\n\n\nCook, Scott J., Jude C. Hays, and Robert J. Franzese. 2020. “Model Specification and Spatial Interdependence.” In The Sage Handbook of Research Methods in Political Science and International Relations, edited by Luigi Curini and Robert Franzese, 1st ed, 730–47. Thousand Oaks: SAGE Inc.\n\n\nElhorst, J. Paul. 2014. Spatial Econometrics: From Cross-Sectional Data to Spatial Panels. SpringerBriefs in Regional Science. Berlin and Heidelberg: Springer. https://doi.org/10.1007/978-3-642-40340-8.\n\n\nElhorst, J. Paul, and S. Halleck Vega. 2017. “The SLX Model: Extensions and the Sensitivity of Spatial Spillovers to W.” Papeles de Economía Española 152: 34–50.\n\n\nFischer, Manfred M., Monika Bartkowska, Aleksandra Riedl, Sascha Sardadvar, and Andrea Kunnert. 2009. “The Impact of Human Capital on Regional Labor Productivity in Europe.” Letters in Spatial and Resource Sciences 2 (2-3): 97–108. https://doi.org/10.1007/s12076-009-0027-7.\n\n\nFlorax, Raymond, Hendrik Folmer, and Sergio J. Rey. 2003. “Specification Searches in Spatial Econometrics: The Relevance of Hendry’s Methodology.” Regional Science and Urban Economics 33 (5): 557–79. https://doi.org/10.1016/S0166-0462(03)00002-4.\n\n\nGibbons, Steve, and Henry G. Overman. 2012. “Mostly Pointless Spatial Econometrics?” Journal of Regional Science 52 (2): 172–91. https://doi.org/10.1111/j.1467-9787.2012.00760.x.\n\n\nGibbons, Steve, Henry G. Overman, and Eleonora Patacchini. 2015. “Spatial Methods.” In Handbook of Regional and Urban Economics, edited by Gilles Duranton, J. Vernon Henderson, and William C. Strange, 5:115–68. Amsterdam: Elsevier. https://doi.org/10.1016/B978-0-444-59517-1.00003-9.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nMur, Jesús, and Ana Angulo. 2009. “Model Selection Strategies in a Spatial Setting: Some Additional Results.” Regional Science and Urban Economics 39 (2): 200–213. https://doi.org/10.1016/j.regsciurbeco.2008.05.018.\n\n\nPinkse, Joris, and Margaret E. Slade. 2010. “The Future of Spatial Econometrics.” Journal of Regional Science 50 (1): 103–17. https://doi.org/10.1111/j.1467-9787.2009.00645.x.\n\n\nRüttenauer, Tobias. 2018. “Neighbours Matter: A Nation-wide Small-area Assessment of Environmental Inequality in Germany.” Social Science Research 70: 198–211. https://doi.org/10.1016/j.ssresearch.2017.11.009.\n\n\n———. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467."
  },
  {
    "objectID": "08_exercise2_short.html#environmental-inequality",
    "href": "08_exercise2_short.html#environmental-inequality",
    "title": "\n6  Exercise II\n",
    "section": "\n6.1 Environmental inequality",
    "text": "6.1 Environmental inequality\nHow would you investigate the following descriptive research question: Are ethnic (and immigrant) minorities in London exposed to higher levels of pollution? Also consider the spatial structure. What’s your dependent and whats your independent variable?\n1) Define a neigbours weights object of your choice\nAssume a typical neighbourhood would be 2.5km in diameter\n\ncoords &lt;- st_centroid(msoa.spdf)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Neighbours within 3km distance\ndist_15.nb &lt;- dnearneigh(coords, d1 = 0, d2 = 2500)\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15266 \nPercentage nonzero weights: 1.579859 \nAverage number of links: 15.53001 \n4 regions with no links:\n158 463 478 505\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 \n 4  5  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 \n22 23 24 25 26 27 28 29 30 31 32 33 34 \n25 19 38 29 32 38 26 16 20 10  8  1  2 \n5 least connected regions:\n160 469 474 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# There are some mpty one. Lets impute with the nearest neighbour\nk2.nb &lt;- knearneigh(coords, k = 1)\n\n# Replace zero\nnolink_ids &lt;- which(card(dist_15.nb) == 0)\ndist_15.nb[card(dist_15.nb) == 0] &lt;- k2.nb$nn[nolink_ids, ]\n\nsummary(dist_15.nb)\n\nNeighbour list object:\nNumber of regions: 983 \nNumber of nonzero links: 15270 \nPercentage nonzero weights: 1.580273 \nAverage number of links: 15.53408 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n 9  9 23 19 26 36 31 53 39 61 63 59 48 42 35 24 31 28 30 27 26 25 \n23 24 25 26 27 28 29 30 31 32 33 34 \n19 38 29 32 38 26 16 20 10  8  1  2 \n9 least connected regions:\n158 160 463 469 474 478 505 597 959 with 1 link\n2 most connected regions:\n565 567 with 34 links\n\n# listw object with row-normalization\ndist_15.lw &lt;- nb2listw(dist_15.nb, style = \"W\")\n\n2) Estimate the extent of spatial auto-correlation\n\nmoran.test(msoa.spdf$no2, listw = dist_15.lw)\n\n\n    Moran I test under randomisation\n\ndata:  msoa.spdf$no2  \nweights: dist_15.lw    \n\nMoran I statistic standard deviate = 65.197, p-value &lt;\n2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.891520698      -0.001018330       0.000187411 \n\n\n3) Estimate a spatial SAR regression model\n\nEstimate a spatial autoregressive SAR model\n\n\nmod_1.sar &lt;- lagsarlm(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                      Durbin = FALSE) # we could here extend to SDM\nsummary(mod_1.sar)\n\n\nCall:\nlagsarlm(formula = log(no2) ~ per_mixed + per_asian + per_black + \n    per_other + per_nonUK_EU + per_nonEU + log(POPDEN), data = msoa.spdf, \n    listw = dist_15.lw, Durbin = FALSE)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.2140485 -0.0267085 -0.0021421  0.0238337  0.3505513 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n                Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  -1.7004e-02  1.8122e-02 -0.9383  0.348110\nper_mixed     3.4376e-04  1.4758e-03  0.2329  0.815810\nper_asian    -8.5205e-05  1.1494e-04 -0.7413  0.458507\nper_black    -4.2754e-04  2.3468e-04 -1.8218  0.068484\nper_other     1.9693e-03  7.4939e-04  2.6279  0.008591\nper_nonUK_EU  8.9027e-04  3.9638e-04  2.2460  0.024703\nper_nonEU     1.8460e-03  3.5159e-04  5.2506 1.516e-07\nlog(POPDEN)   1.8650e-02  2.7852e-03  6.6963 2.138e-11\n\nRho: 0.9684, LR test value: 2002.5, p-value: &lt; 2.22e-16\nAsymptotic standard error: 0.0063124\n    z-value: 153.41, p-value: &lt; 2.22e-16\nWald statistic: 23535, p-value: &lt; 2.22e-16\n\nLog likelihood: 1562.401 for lag model\nML residual variance (sigma squared): 0.0020568, (sigma: 0.045352)\nNumber of observations: 983 \nNumber of parameters estimated: 10 \nAIC: -3104.8, (AIC for lm: -1104.3)\nLM test for residual autocorrelation\ntest value: 108.97, p-value: &lt; 2.22e-16\n\n\n\nHave a look into the true multiplier matrix \\(({\\bm I_N}-\\rho {\\bm W})^{-1}\\beta_k\\)\n\n\n\nW &lt;- listw2mat(dist_15.lw)\nI &lt;- diag(dim(W)[1])\n\nrho &lt;- unname(mod_1.sar$rho)\n\nM &lt;- solve(I - rho*W)\n\nM[1:10, 1:10]\n\n                1           2           3           4           5\n [1,] 1.164650997 0.002433319 0.004089559 0.004034508 0.006545994\n [2,] 0.010706605 1.407336301 0.643881932 0.370049927 0.464794934\n [3,] 0.011246286 0.402426207 1.474021599 0.429011868 0.641526285\n [4,] 0.008875918 0.185024963 0.343209495 1.684533322 0.614086824\n [5,] 0.012000989 0.193664556 0.427684190 0.511739020 1.560840834\n [6,] 0.010741524 0.192552594 0.452940016 0.631452476 0.672787841\n [7,] 0.012779708 0.141953871 0.299247377 0.418234186 0.616895800\n [8,] 0.014769006 0.125781189 0.253122442 0.295553039 0.500919513\n [9,] 0.011708131 0.147549264 0.309080773 0.568442619 0.629156269\n[10,] 0.009937859 0.152900148 0.306652041 0.727001926 0.553973310\n                6           7          8           9          10\n [1,] 0.004882511 0.005808958 0.00872714 0.005854065 0.003613767\n [2,] 0.385105188 0.283907742 0.32703109 0.324608380 0.244640236\n [3,] 0.566175019 0.374059222 0.41132397 0.424986063 0.306652041\n [4,] 0.631452476 0.418234186 0.38421895 0.625286881 0.581601541\n [5,] 0.560656534 0.514079833 0.54266281 0.576726579 0.369315540\n [6,] 1.571175245 0.558170218 0.46513922 0.661184961 0.543820047\n [7,] 0.558170218 1.475511568 0.58520461 0.614170880 0.463886540\n [8,] 0.357799398 0.450157392 1.46638195 0.474994894 0.272339890\n [9,] 0.601077237 0.558337164 0.56135760 1.581077095 0.517983092\n[10,] 0.679775059 0.579858174 0.44255232 0.712226751 1.560083138\n\n\n\nCreate an \\(N \\times N\\) effects matrix. What is the effect of unit 6 on unit 10?\n\n\n# For beta 1\n\nbeta &lt;- mod_1.sar$coefficients\n\neffM &lt;- beta[2] * M\n\neffM[1:10, 1:10]\n\n                 1            2            3            4\n [1,] 4.003610e-04 8.364789e-07 1.405829e-06 1.386904e-06\n [2,] 3.680507e-06 4.837866e-04 2.213411e-04 1.272085e-04\n [3,] 3.866028e-06 1.383382e-04 5.067103e-04 1.474773e-04\n [4,] 3.051190e-06 6.360427e-05 1.179819e-04 5.790759e-04\n [5,] 4.125465e-06 6.657422e-05 1.470209e-04 1.759156e-04\n [6,] 3.692511e-06 6.619197e-05 1.557029e-04 2.170684e-04\n [7,] 4.393158e-06 4.879813e-05 1.028694e-04 1.437724e-04\n [8,] 5.077000e-06 4.323860e-05 8.701349e-05 1.015994e-04\n [9,] 4.024792e-06 5.072160e-05 1.062497e-04 1.954081e-04\n[10,] 3.416243e-06 5.256102e-05 1.054148e-04 2.499145e-04\n                 5            6            7            8\n [1,] 2.250254e-06 1.678414e-06 1.996890e-06 3.000045e-06\n [2,] 1.597781e-04 1.323839e-04 9.759625e-05 1.124204e-04\n [3,] 2.205314e-04 1.946286e-04 1.285868e-04 1.413969e-04\n [4,] 2.110988e-04 2.170684e-04 1.437724e-04 1.320793e-04\n [5,] 5.365554e-04 1.927315e-04 1.767203e-04 1.865460e-04\n [6,] 2.312779e-04 5.401079e-04 1.918768e-04 1.598965e-04\n [7,] 2.120644e-04 1.918768e-04 5.072225e-04 2.011702e-04\n [8,] 1.721963e-04 1.229973e-04 1.547463e-04 5.040841e-04\n [9,] 2.162790e-04 2.066266e-04 1.919342e-04 1.929725e-04\n[10,] 1.904341e-04 2.336798e-04 1.993323e-04 1.521320e-04\n                 9           10\n [1,] 2.012396e-06 1.242270e-06\n [2,] 1.115875e-04 8.409764e-05\n [3,] 1.460934e-04 1.054148e-04\n [4,] 2.149489e-04 1.999316e-04\n [5,] 1.982558e-04 1.269561e-04\n [6,] 2.272892e-04 1.869438e-04\n [7,] 2.111277e-04 1.594658e-04\n [8,] 1.632845e-04 9.361968e-05\n [9,] 5.435118e-04 1.780621e-04\n[10,] 2.448354e-04 5.362949e-04\n\n# \"Effect\" of unit 6 on unit 10\neffM[10, 6]\n\n           6 \n0.0002336798 \n\n\n\nEstimate a spatial autoregressive SLX model\n\n\nmod_1.slx &lt;- lmSLX(log(no2) ~ per_mixed + per_asian + per_black + per_other\n                      + per_nonUK_EU + per_nonEU  + log(POPDEN),  \n                      data = msoa.spdf, \n                      listw = dist_15.lw,\n                  Durbin = TRUE)\n\n\nCalculate and interpret the summary impact measures for SAR and SLX.\n\n\nmod_1.sar.imp &lt;- impacts(mod_1.sar, listw = dist_15.lw, R = 300)\nsummary(mod_1.sar.imp)\n\nImpact measures (lag, exact):\n                    Direct     Indirect        Total\nper_mixed     0.0004939013  0.010385844  0.010879745\nper_asian    -0.0001224192 -0.002574253 -0.002696672\nper_black    -0.0006142789 -0.012917166 -0.013531445\nper_other     0.0028294759  0.059498722  0.062328198\nper_nonUK_EU  0.0012791011  0.026897166  0.028176267\nper_nonEU     0.0026523198  0.055773451  0.058425770\nlog(POPDEN)   0.0267960076  0.563471199  0.590267206\n========================================================\nSimulation results ( variance matrix):\nDirect:\n\nIterations = 1:300\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 300 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                   Mean        SD  Naive SE Time-series SE\nper_mixed     6.800e-04 0.0022710 1.311e-04      1.311e-04\nper_asian    -9.259e-05 0.0001711 9.877e-06      9.877e-06\nper_black    -6.341e-04 0.0003511 2.027e-05      2.027e-05\nper_other     2.852e-03 0.0010000 5.773e-05      5.773e-05\nper_nonUK_EU  1.279e-03 0.0005384 3.109e-05      2.880e-05\nper_nonEU     2.614e-03 0.0005052 2.917e-05      2.917e-05\nlog(POPDEN)   2.722e-02 0.0038099 2.200e-04      2.200e-04\n\n2. Quantiles for each variable:\n\n                   2.5%        25%        50%        75%     97.5%\nper_mixed    -0.0035235 -0.0009485  0.0007113  2.216e-03 4.967e-03\nper_asian    -0.0004007 -0.0002095 -0.0001075  1.787e-05 2.656e-04\nper_black    -0.0013209 -0.0008559 -0.0006368 -3.807e-04 3.361e-05\nper_other     0.0008672  0.0022864  0.0027634  3.480e-03 4.953e-03\nper_nonUK_EU  0.0001046  0.0009682  0.0012634  1.614e-03 2.266e-03\nper_nonEU     0.0016845  0.0022839  0.0026333  2.953e-03 3.584e-03\nlog(POPDEN)   0.0199059  0.0246439  0.0273128  2.987e-02 3.382e-02\n\n========================================================\nIndirect:\n\nIterations = 1:300\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 300 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                 Mean       SD  Naive SE Time-series SE\nper_mixed     0.01519 0.050693 0.0029268      0.0029663\nper_asian    -0.00205 0.003936 0.0002273      0.0002273\nper_black    -0.01384 0.008537 0.0004929      0.0004929\nper_other     0.06197 0.025536 0.0014743      0.0014743\nper_nonUK_EU  0.02734 0.012152 0.0007016      0.0007505\nper_nonEU     0.05714 0.017564 0.0010141      0.0010141\nlog(POPDEN)   0.58815 0.125128 0.0072243      0.0072243\n\n2. Quantiles for each variable:\n\n                  2.5%       25%      50%        75%     97.5%\nper_mixed    -0.081103 -0.018639  0.01516  0.0495997 0.1191921\nper_asian    -0.009157 -0.004675 -0.00216  0.0004143 0.0055830\nper_black    -0.033449 -0.018830 -0.01329 -0.0081513 0.0007166\nper_other     0.018597  0.046179  0.05897  0.0733611 0.1187995\nper_nonUK_EU  0.002502  0.020113  0.02698  0.0338821 0.0519077\nper_nonEU     0.030008  0.046355  0.05515  0.0642058 0.1000690\nlog(POPDEN)   0.399116  0.496140  0.56955  0.6576800 0.8764408\n\n========================================================\nTotal:\n\nIterations = 1:300\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 300 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                  Mean       SD  Naive SE Time-series SE\nper_mixed     0.015868 0.052918 0.0030552      0.0030930\nper_asian    -0.002142 0.004103 0.0002369      0.0002369\nper_black    -0.014475 0.008862 0.0005117      0.0005117\nper_other     0.064819 0.026405 0.0015245      0.0015245\nper_nonUK_EU  0.028616 0.012626 0.0007290      0.0007177\nper_nonEU     0.059757 0.017933 0.0010353      0.0010353\nlog(POPDEN)   0.615371 0.126880 0.0073254      0.0073254\n\n2. Quantiles for each variable:\n\n                  2.5%       25%       50%        75%     97.5%\nper_mixed    -0.083807 -0.019472  0.015896  0.0519753 0.1229114\nper_asian    -0.009527 -0.004868 -0.002275  0.0004299 0.0058638\nper_black    -0.034544 -0.019628 -0.013942 -0.0085527 0.0007494\nper_other     0.019464  0.048386  0.061849  0.0763229 0.1227072\nper_nonUK_EU  0.002608  0.021152  0.028136  0.0355232 0.0543880\nper_nonEU     0.031796  0.048853  0.057742  0.0672532 0.1032455\nlog(POPDEN)   0.417314  0.521477  0.598300  0.6860475 0.9008017\n\n\nFor SLX, you can just interpret the coefficients. Impacts will give you the same results.\n4) Is SAR the right model choice or would you rather estimate a different model?\n\nHow do results change once you specify a spatial Durbin model?\nPlease calculate and interpret the impacts for a spatial Durbin model."
  },
  {
    "objectID": "08_exercise2_short.html#life-expecatancy-in-germany",
    "href": "08_exercise2_short.html#life-expecatancy-in-germany",
    "title": "\n6  Exercise II\n",
    "section": "\n6.2 Life Expecatancy in Germany",
    "text": "6.2 Life Expecatancy in Germany\nBelow, we read and transform some characteristics of the INKAR data on German counties.\n\nload(\"_data/inkar2.Rdata\")\n\nVariables are\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n“Kennziffer”\nID\n\n\n“Raumeinheit”\nName\n\n\n“Aggregat”\nLevel\n\n\n“year”\nYear\n\n\n“poluation_density”\nPopulation Density\n\n\n“median_income”\nMedian Household income (only for 2020)\n\n\n“gdp_in1000EUR”\nGross Domestic Product in 1000 euros\n\n\n“unemployment_rate”\nUnemployment rate\n\n\n“share_longterm_unemployed”\nShare of longterm unemployed (among unemployed)\n\n\n“share_working_indutry”\nShare of employees in undistrial sector\n\n\n“share_foreigners”\nShare of foreign nationals\n\n\n“share_college”\nShare of school-finishers with college degree\n\n\n“recreational_space”\nRecreational space per inhabitant\n\n\n“car_density”\nDensity of cars\n\n\n“life_expectancy”\nLife expectancy\n\n\n\nAnd we get the respective county shapes:\n\nkreise.spdf &lt;- st_read(dsn = \"_data/vg5000_ebenen_1231\",\n                       layer = \"VG5000_KRS\")\n\nReading layer `VG5000_KRS' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\vg5000_ebenen_1231' \n  using driver `ESRI Shapefile'\nSimple feature collection with 400 features and 24 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 280353.1 ymin: 5235878 xmax: 921261.6 ymax: 6101302\nProjected CRS: ETRS89 / UTM zone 32N\n\n\n\n\n\n6.2.1 1) Merge data with the shape file (as with conventional data)\n\n# Merge\ninkar_2020.spdf &lt;- merge(kreise.spdf, inkar.df[inkar.df$year == 2020, ], \n                         by.x = \"AGS\", by.y = \"Kennziffer\")\n\n\n6.2.2 2) Create a map of life-expectancy\n\ncols &lt;- viridis(n = 100, direction = -1, option = \"G\")\n\nmp1 &lt;-  tm_shape(inkar_2020.spdf) + \n  tm_fill(col = \"life_expectancy\", \n          style = \"cont\", # algorithm to def cut points\n          palette = cols, # colours\n          stretch.palette = TRUE,\n          title = \"in years\"\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"Life expectancy\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\nmp1\n\n\n\n\n\n6.2.3 3) Chose some variables that could predict life expectancy. See for instance the following paper.\n\n6.2.4 4) Generate a neighbours object (e.g. the 10 nearest neighbours).\n\n# nb &lt;- poly2nb(kreise.spdf, row.names = \"ags\", queen = TRUE)\nknn &lt;- knearneigh(st_centroid(kreise.spdf), k = 10)\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\nnb &lt;- knn2nb(knn, row.names = kreise.spdf$ags)\nlistw &lt;- nb2listw(nb, style = \"W\")\n\n\n6.2.5 5) Estimate a cross-sectional spatial model for the year 2020 and calculate the impacts.\n\n### Use a spatial Durbin Error model\n\n# Spec formula\nfm &lt;- life_expectancy ~ median_income + unemployment_rate + share_college + car_density\n\n# Estimate error model with Durbin = TRUE \nmod_1.durb &lt;- errorsarlm(fm,  \n                      data = inkar_2020.spdf, \n                      listw = listw,\n                      Durbin = TRUE)\n\nsummary(mod_1.durb)\n\n\nCall:\nerrorsarlm(formula = fm, data = inkar_2020.spdf, listw = listw, \n    Durbin = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-1.343988 -0.349564  0.013309  0.333105  1.819014 \n\nType: error \nCoefficients: (asymptotic standard errors) \n                         Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)            8.4970e+01  1.4366e+00  59.1460 &lt; 2.2e-16\nmedian_income          5.4013e-04  8.2285e-05   6.5642 5.233e-11\nunemployment_rate     -3.8970e-01  2.0095e-02 -19.3923 &lt; 2.2e-16\nshare_college          6.7806e-03  3.2502e-03   2.0862  0.036957\ncar_density           -3.2042e-03  4.9774e-04  -6.4376 1.214e-10\nlag.median_income      4.9282e-04  1.8112e-04   2.7209  0.006510\nlag.unemployment_rate -3.4685e-02  4.5454e-02  -0.7631  0.445415\nlag.share_college     -1.7066e-03  7.0324e-03  -0.2427  0.808256\nlag.car_density       -5.2210e-03  1.7540e-03  -2.9766  0.002915\n\nLambda: 0.57895, LR test value: 48.146, p-value: 3.9563e-12\nAsymptotic standard error: 0.069524\n    z-value: 8.3274, p-value: &lt; 2.22e-16\nWald statistic: 69.345, p-value: &lt; 2.22e-16\n\nLog likelihood: -305.6855 for error model\nML residual variance (sigma squared): 0.26001, (sigma: 0.50991)\nNumber of observations: 400 \nNumber of parameters estimated: 11 \nAIC: NA (not available for weighted model), (AIC for lm: 679.52)\n\n# Calculate impacts (which is unnecessary in this case)\nmod_1.durb.imp &lt;- impacts(mod_1.durb, listw = listw, R = 300)\nsummary(mod_1.durb.imp, zstats = TRUE, short = TRUE)\n\nImpact measures (SDEM, glht, n):\n                         Direct      Indirect        Total\nmedian_income      0.0005401288  0.0004928219  0.001032951\nunemployment_rate -0.3896966870 -0.0346850573 -0.424381744\nshare_college      0.0067806074 -0.0017065824  0.005074025\ncar_density       -0.0032042421 -0.0052210252 -0.008425267\n========================================================\nStandard errors:\n                        Direct     Indirect        Total\nmedian_income     8.228463e-05 0.0001811231 0.0001813201\nunemployment_rate 2.009540e-02 0.0454539507 0.0455753453\nshare_college     3.250157e-03 0.0070323527 0.0069549479\ncar_density       4.977409e-04 0.0017540485 0.0018942462\n========================================================\nZ-values:\n                      Direct   Indirect      Total\nmedian_income       6.564152  2.7209218  5.6968356\nunemployment_rate -19.392336 -0.7630812 -9.3116518\nshare_college       2.086240 -0.2426759  0.7295561\ncar_density        -6.437570 -2.9765569 -4.4478205\n\np-values:\n                  Direct     Indirect  Total     \nmedian_income     5.233e-11  0.0065100 1.2205e-08\nunemployment_rate &lt; 2.22e-16 0.4454149 &lt; 2.22e-16\nshare_college     0.036957   0.8082565 0.46566   \ncar_density       1.214e-10  0.0029151 8.6746e-06\n\n\n\n6.2.6 6) Calculate the spatial lagged variables for your covariates (e.g. use create_WX(), which needs a non-spatial df as input) .\n\n# Extract covariate names\ncovars &lt;- attr(terms(fm),\"term.labels\")\n\nw_vars &lt;- create_WX(st_drop_geometry(inkar_2020.spdf)[, covars],\n                    listw = listw,\n                    prefix = \"w\")\n\ninkar_2020.spdf &lt;- cbind(inkar_2020.spdf, w_vars)\n\n\n6.2.7 6) Can you run a spatial machine learning model? (for instance, using randomForest)?\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.3.2\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n# Train\nrf.mod &lt;- randomForest(life_expectancy ~ median_income + unemployment_rate + share_college + car_density +\n                         w.median_income + w.unemployment_rate + w.share_college + w.car_density,\n                       data = st_drop_geometry(inkar_2020.spdf), \n                       ntree = 1000,\n                       importance = TRUE)\n\n# Inspect the mechanics of the model\nimportance(rf.mod)\n\n                     %IncMSE IncNodePurity\nmedian_income       34.03645      40.91834\nunemployment_rate   64.97511     115.50583\nshare_college       22.00718      25.91124\ncar_density         25.20195      33.90758\nw.median_income     36.21939      57.65676\nw.unemployment_rate 25.04768      53.52908\nw.share_college     16.97143      24.10762\nw.car_density       24.27691      31.52306\n\nvarImpPlot(rf.mod)\n\n\n\n\nYou could even go further and use higher order neighbours (e.g. nblag(queens.nb, maxlag = 3)) to check the importance of direct neighbours and the neighbours neighbours and so on …\n\n# Create higher order NB object\nlistw.lag &lt;- nblag(nb, maxlag = 3)\n\n\n# Create listwise of 1st, 2nd and 3rd order neighbours\nlistw.lw1 &lt;- nb2listw(listw.lag[[1]], style = \"W\")\nlistw.lw2 &lt;- nb2listw(listw.lag[[2]], style = \"W\")\nlistw.lw3 &lt;- nb2listw(listw.lag[[3]], style = \"W\")\n\n# Create lagged X\nw_vars2 &lt;- create_WX(st_drop_geometry(inkar_2020.spdf)[, covars],\n                    listw = listw.lw2,\n                    prefix = \"w2\")\n\nw_vars3 &lt;- create_WX(st_drop_geometry(inkar_2020.spdf)[, covars],\n                    listw = listw.lw3,\n                    prefix = \"w3\")\n\ninkar_2020.spdf &lt;- cbind(inkar_2020.spdf, w_vars2, w_vars3)\n\n# Train\nrf.mod &lt;- randomForest(life_expectancy ~ median_income + unemployment_rate + share_college + car_density +\n                         w.median_income + w.unemployment_rate + w.share_college + w.car_density +\n                         w2.median_income + w2.unemployment_rate + w2.share_college + w2.car_density +\n                         w3.median_income + w3.unemployment_rate + w3.share_college + w3.car_density,\n                       data = st_drop_geometry(inkar_2020.spdf), \n                       ntree = 1000,\n                       importance = TRUE)\n\n# Inspect the mechanics of the model\nimportance(rf.mod)\n\n                       %IncMSE IncNodePurity\nmedian_income        29.683451     22.771267\nunemployment_rate    61.152787    112.686387\nshare_college        20.939773     16.455557\ncar_density          18.722195     16.203169\nw.median_income      29.032704     37.273706\nw.unemployment_rate  19.411745     24.360074\nw.share_college      12.276134      9.474994\nw.car_density        17.882999     12.423058\nw2.median_income     22.231137     21.572744\nw2.unemployment_rate 14.455514     23.923654\nw2.share_college     13.873830     12.738961\nw2.car_density       12.539108     13.292469\nw3.median_income     15.992052     15.743698\nw3.unemployment_rate 18.499035     25.645470\nw3.share_college      8.720745     10.104429\nw3.car_density        8.589453     12.864967\n\nvarImpPlot(rf.mod)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anselin, Luc. 1988. Spatial Econometrics:\nMethods and Models. Studies in\nOperational Regional Science. Dordrecht:\nKluwer.\n\n\n———. 1995. “Local Indicators of Spatial\nAssociation-LISA.” Geographical Analysis 27 (2):\n93–115. https://doi.org/10.1111/j.1538-4632.1995.tb00338.x.\n\n\n———. 2003. “Spatial Externalities, Spatial\nMultipliers, and Spatial Econometrics.”\nInternational Regional Science Review 26 (2): 153–66. https://doi.org/10.1177/0160017602250972.\n\n\nAnselin, Luc, and Anil K. Bera. 1998. “Spatial\nDependence in Linear Regression Models with an\nIntroduction to Spatial Econometrics.”\nIn Handbook of Applied Economic Statistics, edited\nby Aman Ullah and David E. A. Giles, 237–89. New York:\nDekker.\n\n\nAnselin, Luc, Anil K. Bera, Raymond Florax, and Mann J. Yoon. 1996.\n“Simple Diagnostic Tests for Spatial\nDependence.” Regional Science and Urban Economics\n26 (1): 77–104. https://doi.org/10.1016/0166-0462(95)02111-6.\n\n\nAppelhans, Tim, Florian Detsch, Chritoph Reudenbach, and Stefan\nWoellauer. 2021. “Mapview: Interactive Viewing of\nSpatial Data in R.”\n\n\nBetz, Timm, Scott J. Cook, and Florian M. Hollenbach. 2020.\n“Spatial Interdependence and Instrumental Variable Models.”\nPolitical Science Research and Methods 8 (4): 646–61. https://doi.org/10.1017/psrm.2018.61.\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos:\nInterface to Geometry Engine - Open\nSource (’GEOS’).”\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A\nReview of Software for Spatial\nEconometrics in R.” Mathematics 9\n(11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBivand, Roger, and Gianfranco Piras. 2015. “Comparing\nImplementations of Estimation Methods for\nSpatial Econometrics.” Journal of Statistical\nSoftware 63 (18): 1–36. https://doi.org/10.18637/jss.v063.i18.\n\n\nBivand, Roger, and David W. S. Wong. 2018. “Comparing\nImplementations of Global and Local Indicators of Spatial\nAssociation.” TEST 27 (3): 716–48. https://doi.org/10.1007/s11749-018-0599-x.\n\n\nBoillat, Sébastien, M. Graziano Ceddia, and Patrick Bottazzi. 2022.\n“The Role of Protected Areas and Land Tenure Regimes on Forest\nLoss in Bolivia: Accounting for Spatial\nSpillovers.” Global Environmental Change 76 (September):\n102571. https://doi.org/10.1016/j.gloenvcha.2022.102571.\n\n\nBurridge, Peter, J. Paul Elhorst, and Katarina Zigova. 2016.\n“Group Interaction in Research and the\nUse of General Nesting Spatial Models.”\nIn Spatial Econometrics: Qualitative and\nLimited Dependent Variables, edited by Badi H.\nBaltagi, James P. LeSage, and R. Kelley Pace, 37:223–58. Advances in\nEconometrics. Emerald Group Publishing\nLimited. https://doi.org/10.1108/S0731-905320160000037016.\n\n\nCliff, Andrew, and Keith Ord. 1972. “Testing for Spatial\nAutocorrelation Among Regression Residuals.”\nGeographical Analysis 4 (3): 267–84. https://doi.org/10.1111/j.1538-4632.1972.tb00475.x.\n\n\nCook, Scott J., Jude C. Hays, and Robert J. Franzese. 2020. “Model\nSpecification and Spatial\nInterdependence.” In The Sage Handbook of\nResearch Methods in Political Science and International Relations,\nedited by Luigi Curini and Robert Franzese, 1st ed, 730–47.\nThousand Oaks: SAGE Inc.\n\n\nDrukker, David M., Peter Egger, and Ingmar R. Prucha. 2013. “On\nTwo-Step Estimation of a Spatial Autoregressive\nModel with Autoregressive Disturbances and\nEndogenous Regressors.” Econometric Reviews\n32 (5-6): 686–733. https://doi.org/10.1080/07474938.2013.741020.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods,\nand Inferences.” Journal of Geographical Systems 14 (1):\n5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\n———. 2014. Spatial Econometrics: From\nCross-Sectional Data to Spatial Panels.\nSpringerBriefs in Regional Science.\nBerlin and Heidelberg: Springer. https://doi.org/10.1007/978-3-642-40340-8.\n\n\nElhorst, J. Paul, and S. Halleck Vega. 2017. “The SLX\nModel: Extensions and the Sensitivity\nof Spatial Spillovers to W.”\nPapeles de Economía Española 152: 34–50.\n\n\nFischer, Manfred M., Monika Bartkowska, Aleksandra Riedl, Sascha\nSardadvar, and Andrea Kunnert. 2009. “The Impact of Human Capital\non Regional Labor Productivity in Europe.”\nLetters in Spatial and Resource Sciences 2 (2-3): 97–108. https://doi.org/10.1007/s12076-009-0027-7.\n\n\nFlorax, Raymond, Hendrik Folmer, and Sergio J. Rey. 2003.\n“Specification Searches in Spatial\nEconometrics: The Relevance of Hendry’s\nMethodology.” Regional Science and Urban\nEconomics 33 (5): 557–79. https://doi.org/10.1016/S0166-0462(03)00002-4.\n\n\nFranzese, Robert J., and Jude C. Hays. 2007. “Spatial\nEconometric Models of Cross-Sectional\nInterdependence in Political Science Panel and\nTime-Series-Cross-Section Data.” Political\nAnalysis 15 (2): 140–64. https://doi.org/10.1093/pan/mpm005.\n\n\nGibbons, Steve, and Henry G. Overman. 2012. “Mostly\nPointless Spatial Econometrics?” Journal of\nRegional Science 52 (2): 172–91. https://doi.org/10.1111/j.1467-9787.2012.00760.x.\n\n\nGräler, Benedikt, Edzer Pebesma, and Gerard Heuvelink. 2016.\n“Spatio-Temporal Interpolation Using Gstat.”\nThe R Journal 8 (1): 204–18.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX\nModel.” Journal of Regional Science 55 (3):\n339–63. https://doi.org/10.1111/jors.12188.\n\n\nKelejian, Harry H., and Gianfranco Piras. 2017. Spatial\nEconometrics. Elsevier. https://doi.org/10.1016/C2016-0-04332-2.\n\n\nKelejian, Harry H., and Ingmar R. Prucha. 1998. “A\nGeneralized Spatial Two-Stage Least Squares Procedure for\nEstimating a Spatial Autoregressive Model with\nAutoregressive Disturbances.” The Journal of\nReal Estate Finance and Economics 17 (1): 99–121. https://doi.org/10.1023/A:1007707430416.\n\n\n———. 2010. “Specification and Estimation of\nSpatial Autoregressive Models with\nAutoregressive and Heteroskedastic\nDisturbances.” Journal of Econometrics 157 (1):\n53–67. https://doi.org/10.1016/j.jeconom.2009.10.025.\n\n\nKelejian, Harry H., Ingmar R. Prucha, and Yevgeny Yuzefovich. 2004.\n“Instrumental Variable Estimation of a Spatial\nAutoregressive Model with Autoregressive\nDisturbances: Large and Small Sample\nResults.” In Spatial and Spatiotemporal\nEconometrics, edited by James P. LeSage and R. Kelley Pace,\n163–98. Advances in Econometrics. Amsterdam and\nBoston: Elsevier.\n\n\nLee, Barrett A., Sean F. Reardon, Glenn Firebaugh, Chad R. Farrell,\nStephen A. Matthews, and David O’Sullivan. 2008. “Beyond the\nCensus Tract: Patterns and\nDeterminants of Racial Segregation at\nMultiple Geographic Scales.” American\nSociological Review 73 (5): 766–91. https://doi.org/10.1177/000312240807300504.\n\n\nLee, Lung-fei. 2004. “Asymptotic Distributions of\nQuasi-Maximum Likelihood Estimators for Spatial\nAutoregressive Models.” Econometrica 72 (6):\n1899–1925.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need\nto Know about Spatial Econometrics.”\nThe Review of Regional Studies 44 (1): 13–32.\nhttps://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to\nSpatial Econometrics. Statistics,\nTextbooks and Monographs. Boca\nRaton: CRC Press.\n\n\n———. 2014. “The Biggest Myth in Spatial\nEconometrics.” Econometrics 2 (4): 217–49. https://doi.org/10.3390/econometrics2040217.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019.\nGeocomputation with R. 1st ed. Chapman &\nHall/CRC the R Series. Boca\nRaton: Chapman & Hall/CRC.\n\n\nManski, Charles F. 1993. “Identification of Endogenous Social\nEffects: The Reflection Problem.” The Review of\nEconomic Studies 60 (3): 531–42. https://doi.org/10.2307/2298123.\n\n\nMohai, Paul, and Robin Saha. 2007. “Racial Inequality\nin the Distribution of Hazardous Waste:\nA National-Level Reassessment.” Social\nProblems 54 (3): 343–70. https://doi.org/10.1525/sp.2007.54.3.343.\n\n\nMoran, P. A. P. 1950. “Notes on Continuous Stochastic\nPhenomena.” Biometrika 37 (1/2): 17. https://doi.org/10.2307/2332142.\n\n\nMur, Jesús, and Ana Angulo. 2009. “Model Selection\nStrategies in a Spatial Setting: Some\nAdditional Results.” Regional Science and Urban\nEconomics 39 (2): 200–213. https://doi.org/10.1016/j.regsciurbeco.2008.05.018.\n\n\nNeumayer, Eric, and Thomas Plümper. 2016. “W.”\nPolitical Science Research and Methods 4 (01): 175–93. https://doi.org/10.1017/psrm.2014.40.\n\n\nOrd, John Keith. 1975. “Estimation Methods for\nModels of Spatial Interaction.”\nJournal of the American Statistical Association 70 (349):\n120–26. https://doi.org/10.2307/2285387.\n\n\nPace, R. Kelley, and James P. LeSage. 2010. “Omitted\nVariable Biases of OLS and Spatial Lag\nModels.” In Progress in Spatial\nAnalysis, edited by Antonio Páez, Julie Gallo, Ron N.\nBuliung, and Sandy Dall’erba, 17–28. Berlin and Heidelberg:\nSpringer.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.”\nThe R Journal 10 (1): 439. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data\nScience: With Applications in R.\nFirst. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPinkse, Joris, and Margaret E. Slade. 2010. “The\nFuture of Spatial Econometrics.”\nJournal of Regional Science 50 (1): 103–17. https://doi.org/10.1111/j.1467-9787.2009.00645.x.\n\n\nRüttenauer, Tobias. 2018. “Neighbours Matter: A Nation-wide Small-area Assessment of\nEnvironmental Inequality in Germany.”\nSocial Science Research 70: 198–211. https://doi.org/10.1016/j.ssresearch.2017.11.009.\n\n\n———. 2022. “Spatial Regression Models: A\nSystematic Comparison of Different Model Specifications\nUsing Monte Carlo Experiments.” Sociological Methods\n& Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “Spatial Data Analysis.”\narXiv. https://arxiv.org/abs/2402.09895.\n\n\nSarrias, Mauricio. 2023. Intermediate Spatial\nEconometrics with Applications in\nR.\n\n\nTennekes, Martijn. 2018. “Tmap : Thematic Maps in\nR.” Journal of Statistical Software 84 (6).\nhttps://doi.org/10.18637/jss.v084.i06.\n\n\nTobler, Waldo R. 1970. “A Computer Movie Simulating Urban\nGrowth in the Detroit Region.” Economic\nGeography 46: 234–40. https://doi.org/10.2307/143141.\n\n\nWard, Michael Don, and Kristian Skrede Gleditsch. 2008. Spatial\nRegression Models. Vol. 155. Quantitative\nApplications in the Social Sciences.\nThousand Oaks: Sage.\n\n\nWimpy, Cameron, Guy D. Whitten, and Laron K. Williams. 2021. “X\nMarks the Spot: Unlocking the\nTreasure of Spatial-X Models.” The\nJournal of Politics 83 (2): 722–39. https://doi.org/10.1086/710089.\n\n\nWong, David. 2009. “The Modifiable Areal Unit Problem\n(MAUP).” In The Sage Handbook of\nSpatial Analysis, edited by A. Stewart Fotheringham\nand Peter Rogerson, 105–24. Los Angeles and London:\nSage.\n\n\nWooldridge, Jeffrey M. 2010. Econometric Analysis of\nCross Section and Panel Data.\nCambridge, Mass.: MIT Press."
  }
]
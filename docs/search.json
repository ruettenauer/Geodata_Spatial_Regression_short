[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Appelhans, Tim, Florian Detsch, Chritoph Reudenbach, and Stefan\nWoellauer. 2021. “Mapview: Interactive Viewing of\nSpatial Data in R.”\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos:\nInterface to Geometry Engine - Open\nSource (’GEOS’).”\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A\nReview of Software for Spatial\nEconometrics in R.” Mathematics 9\n(11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBivand, Roger, and Gianfranco Piras. 2015. “Comparing\nImplementations of Estimation Methods for\nSpatial Econometrics.” Journal of Statistical\nSoftware 63 (18): 1–36. https://doi.org/10.18637/jss.v063.i18.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods,\nand Inferences.” Journal of Geographical Systems 14 (1):\n5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\nGräler, Benedikt, Edzer Pebesma, and Gerard Heuvelink. 2016.\n“Spatio-Temporal Interpolation Using Gstat.”\nThe R Journal 8 (1): 204–18.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX\nModel.” Journal of Regional Science 55 (3):\n339–63. https://doi.org/10.1111/jors.12188.\n\n\nLee, Barrett A., Sean F. Reardon, Glenn Firebaugh, Chad R. Farrell,\nStephen A. Matthews, and David O’Sullivan. 2008. “Beyond the\nCensus Tract: Patterns and\nDeterminants of Racial Segregation at\nMultiple Geographic Scales.” American\nSociological Review 73 (5): 766–91. https://doi.org/10.1177/000312240807300504.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need\nto Know about Spatial Econometrics.”\nThe Review of Regional Studies 44 (1): 13–32.\nhttps://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to\nSpatial Econometrics. Statistics,\nTextbooks and Monographs. Boca\nRaton: CRC Press.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019.\nGeocomputation with R. 1st ed. Chapman &\nHall/CRC the R Series. Boca\nRaton: Chapman & Hall/CRC.\n\n\nMohai, Paul, and Robin Saha. 2007. “Racial Inequality\nin the Distribution of Hazardous Waste:\nA National-Level Reassessment.” Social\nProblems 54 (3): 343–70. https://doi.org/10.1525/sp.2007.54.3.343.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.”\nThe R Journal 10 (1): 439. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data\nScience: With Applications in R.\nFirst. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models:\nA Systematic Comparison of Different Model\nSpecifications Using Monte Carlo Experiments.”\nSociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “Spatial Data Analysis.”\narXiv. https://arxiv.org/abs/2402.09895.\n\n\nTennekes, Martijn. 2018. “Tmap : Thematic Maps in\nR.” Journal of Statistical Software 84 (6).\nhttps://doi.org/10.18637/jss.v084.i06.\n\n\nWard, Michael Don, and Kristian Skrede Gleditsch. 2008. Spatial\nRegression Models. Vol. 155. Quantitative\nApplications in the Social Sciences.\nThousand Oaks: Sage."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spatial Data Analysis",
    "section": "",
    "text": "Introduction\nThis course material is designed for a 1-day GESIS workshop on spatial data analysis. Rüttenauer (2024) is a handbook chapter accompanying these workshop materials.\nIn recent years, more and more spatial data has become available, providing the possibility to combine otherwise unrelated data, such as social, economic, and environmental data. This also opens up the possibility of analyzing spatial patterns and processes (e.g., spillover effects or diffusion).\nMany social science research questions are spatially dependent such as voting outcomes, housing prices, labour markets, protest behavior, or migration decisions. Observing an event in one region or neighborhood increases the likelihood that we observe similar processes in proximate areas. As Tobler’s first law of geography puts it: “Everything is related to everything else, but near things are more related than distant things”. This dependence can stem from spatial contagion, spatial spillovers, or common confounders. Therefore, basic assumptions of standard regression models are violated when analyzing spatial data. However, more imoprtantly, spatial processes are interesting for their own sake. Spatial regression models can detect spatial dependence and explicitly model spatial relations, identifying spatial clustering, spillovers or diffusion processes.\nThe main objective of the course is the theoretical understanding and practical application of spatial regression models. This course will first give an overview on how to perform common spatial operations using spatial information, such as aggregating spatial units, calculating distances, merging spatial data as well as visualizing them. The course will further focus on the analysis of geographic data and the application of spatial regression techniques to model and analyze spatial processes, and furthermore, the course addresses several methods for defining spatial relationships, detecting and diagnosing spatial dependence and autocorrelation. Finally, we will discuss various spatial regression techniques to model processes, clarify the assumptions of these models, and show how they differ in their applications and interpretations.\nThe field has developed very quickly over the past few years, and R now provides a rich set of packages for various spatial data operations. For a more in-depth introduction into spatial data analysis in R, have a look into the materials references below.\nThe material introduces the use of geographical information to connect and analyze different spatial data sources very briefly. This introduction is limited to the fundamentals of using geographical information in R. Stefan Jünger & Anne-Kathrin Stroppe have provided a comprehensive GESIS workshop on geospatial techniques in R. The focus of this workshop will be on techniques for spatial data analysis, such as spatial regression models."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Spatial Data Analysis",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nTime\nSession\n\n\n\n\n09:00 – 09:30\nRefresher on R for spatial data\n\n\n09:30 – 11:00\nSpatial Relationships (W) and Spatial Dependence\n\n\n11:15 – 12:00\nPractical exercise\n\n\nLunch break\n\n\n\n13:00 – 14:30\nSpatial Regression Models (SLX, Error, lagged DV)\n\n\n14:45 – 16:00\nInterpreting Results: Spatial Impacts\n\n\n16:15 – 18:00\nPractical exercise"
  },
  {
    "objectID": "index.html#some-useful-packages",
    "href": "index.html#some-useful-packages",
    "title": "Spatial Data Analysis",
    "section": "Some useful packages",
    "text": "Some useful packages\nBy now, R provides a lot of functionalities for GIS applications and spatial econometrics, and further extensions. There are lots of packages providing a huge variety of spatial functionalities and methods (see e.g. R. Bivand, Millo, and Piras 2021). Important packages for fundamental spatial operations are:\n\nSpatial data workhorses: sf (Pebesma 2018) and terra\nVisualization: mapview (Appelhans et al. 2021) and tmap (Tennekes 2018)\nSpatial weights and other relations: spdep (R. S. Bivand and Rudel 2018)\nSpatial interpolation and kriging: gstat (Gräler, Pebesma, and Heuvelink 2016)\nSpatial regression models: spatialreg and sphet (R. Bivand and Piras 2015)\nThe packages have constantly developed over the past years, and older packages such as rgdal, rgeos, and sp are currently retiring (Blog post)"
  },
  {
    "objectID": "index.html#further-readings",
    "href": "index.html#further-readings",
    "title": "Spatial Data Analysis",
    "section": "Further Readings",
    "text": "Further Readings\n\nGreat up-to-date introduction to spatial R: Lovelace, Nowosad, and Muenchow (2019), updated version available online\nGreat open-science book on Spatial Data Science Pebesma and Bivand (2023)\nComprehensive introduction to spatial econometrics: LeSage and Pace (2009)\nRelative intuitive introduction to spatial econometrics: Ward and Gleditsch (2008)\nArticle-length introductions to spatial econometrics: Elhorst (2012), Halleck Vega and Elhorst (2015), LeSage (2014), Rüttenauer (2024), and Rüttenauer (2022)"
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "Spatial Data Analysis",
    "section": "Course materials",
    "text": "Course materials\n\nI highly recommend the great Introduction to Geospatial Techniques for Social Scientists in R including, see Stefan Jünger & Anne-Kathrin Stroppe’s GESIS workshop materials. Nice materials on GIS, spatial operations and spatial data visualisation!\nFor those looking for a more in-depth introduction, I highly recommend Roger Bivand’s course on Spatial Data Analysis: Youtube recordings, Course Materials\nI’ve learned most of what I know about spatial econometrics from Scott J. Cook and his workshop on Spatial Econometrics at the Essex Summer school."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nAppelhans, Tim, Florian Detsch, Chritoph Reudenbach, and Stefan Woellauer. 2021. “Mapview: Interactive Viewing of Spatial Data in R.”\n\n\nBivand, Roger S., and Colin Rudel. 2018. “Rgeos: Interface to Geometry Engine - Open Source (’GEOS’).”\n\n\nBivand, Roger, Giovanni Millo, and Gianfranco Piras. 2021. “A Review of Software for Spatial Econometrics in R.” Mathematics 9 (11): 1276. https://doi.org/10.3390/math9111276.\n\n\nBivand, Roger, and Gianfranco Piras. 2015. “Comparing Implementations of Estimation Methods for Spatial Econometrics.” Journal of Statistical Software 63 (18): 1–36. https://doi.org/10.18637/jss.v063.i18.\n\n\nElhorst, J. Paul. 2012. “Dynamic Spatial Panels: Models, Methods, and Inferences.” Journal of Geographical Systems 14 (1): 5–28. https://doi.org/10.1007/s10109-011-0158-4.\n\n\nGräler, Benedikt, Edzer Pebesma, and Gerard Heuvelink. 2016. “Spatio-Temporal Interpolation Using Gstat.” The R Journal 8 (1): 204–18.\n\n\nHalleck Vega, Solmaria, and J. Paul Elhorst. 2015. “The SLX Model.” Journal of Regional Science 55 (3): 339–63. https://doi.org/10.1111/jors.12188.\n\n\nLeSage, James P. 2014. “What Regional Scientists Need to Know about Spatial Econometrics.” The Review of Regional Studies 44 (1): 13–32. https://doi.org/https://dx.doi.org/10.2139/ssrn.2420725.\n\n\nLeSage, James P., and R. Kelley Pace. 2009. Introduction to Spatial Econometrics. Statistics, Textbooks and Monographs. Boca Raton: CRC Press.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. Chapman & Hall/CRC the R Series. Boca Raton: Chapman & Hall/CRC.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. First. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nRüttenauer, Tobias. 2022. “Spatial Regression Models: A Systematic Comparison of Different Model Specifications Using Monte Carlo Experiments.” Sociological Methods & Research 51 (2): 728–59. https://doi.org/10.1177/0049124119882467.\n\n\n———. 2024. “Spatial Data Analysis.” arXiv. https://arxiv.org/abs/2402.09895.\n\n\nTennekes, Martijn. 2018. “Tmap : Thematic Maps in R.” Journal of Statistical Software 84 (6). https://doi.org/10.18637/jss.v084.i06.\n\n\nWard, Michael Don, and Kristian Skrede Gleditsch. 2008. Spatial Regression Models. Vol. 155. Quantitative Applications in the Social Sciences. Thousand Oaks: Sage."
  },
  {
    "objectID": "01_refresher_short.html#packages",
    "href": "01_refresher_short.html#packages",
    "title": "\n1  Refresher\n",
    "section": "\n1.1 Packages",
    "text": "1.1 Packages\nPlease make sure that you have installed the following packages:\n\npks &lt;- c(\"dplyr\",\n\"gstat\",\n\"mapview\",\n\"nngeo\",\n\"nomisr\",\n\"osmdata\",\n\"rnaturalearth\",\n\"sf\",\n\"spatialreg\",\n\"spdep\",\n\"texreg\",\n\"tidyr\",\n\"tmap\",\n\"viridisLite\")\n\nThe most important package is sf: Simple Features for R. users are strongly encouraged to install the sf binary packages from CRAN. If that does not work, please have a look at the installation instructions. It requires software packages GEOS, GDAL and PROJ."
  },
  {
    "objectID": "01_refresher_short.html#coordinates",
    "href": "01_refresher_short.html#coordinates",
    "title": "\n1  Refresher\n",
    "section": "\n1.2 Coordinates",
    "text": "1.2 Coordinates\nIn general, spatial data is structured like conventional/tidy data (e.g. data.frames, matrices), but has one additional dimension: every observation is linked to some sort of geo-spatial information. Most common types of spatial information are:\n\nPoints (one coordinate pair)\nLines (two coordinate pairs)\nPolygons (at least three coordinate pairs)\nRegular grids (one coordinate pair for centroid + raster / grid size)\n\n\n1.2.1 Coordinate reference system (CRS)\nIn its raw form, a pair of coordinates consists of two numerical values. For instance, the pair c(51.752595, -1.262801) describes the location of Nuffield College in Oxford (one point). The fist number represents the latitude (north-south direction), the second number is the longitude (west-east direction), both are in decimal degrees.\n\n\nFigure: Latitude and longitude, Source: Wikipedia\n\nHowever, we need to specify a reference point for latitudes and longitudes (in the Figure above: equator and Greenwich). For instance, the pair of coordinates above comes from Google Maps which returns GPS coordinates in ‘WGS 84’ (EPSG:4326).\n\n# Coordinate pairs of two locations\ncoords1 &lt;- c(51.752595, -1.262801)\ncoords2 &lt;- c(51.753237, -1.253904)\ncoords &lt;- rbind(coords1, coords2)\n\n# Conventional data frame\nnuffield.df &lt;- data.frame(name = c(\"Nuffield College\", \"Radcliffe Camera\"),\n                          address = c(\"New Road\", \"Radcliffe Sq\"),\n                          lat = coords[,1], lon = coords[,2])\n\nhead(nuffield.df)\n\n                    name      address      lat       lon\ncoords1 Nuffield College     New Road 51.75259 -1.262801\ncoords2 Radcliffe Camera Radcliffe Sq 51.75324 -1.253904\n\n# Combine to spatial data frame\nnuffield.spdf &lt;- st_as_sf(nuffield.df, \n                          coords = c(\"lon\", \"lat\"), # Order is important\n                          crs = 4326) # EPSG number of CRS\n\n# Map\nmapview(nuffield.spdf, zcol = \"name\")\n\n\n\n\n\n\n\n1.2.2 Projected CRS\nHowever, different data providers use different CRS. For instance, spatial data in the UK usually uses ‘OSGB 1936 / British National Grid’ (EPSG:27700). Here, coordinates are in meters, and projected onto a planar 2D space.\nThere are a lot of different CRS projections, and different national statistics offices provide data in different projections. Data providers usually specify which reference system they use. This is important as using the correct reference system and projection is crucial for plotting and manipulating spatial data.\nIf you do not know the correct CRS, try starting with a standards CRS like EPSG:4326 if you have decimal degree like coordinates. If it looks like projected coordinates, try searching for the country or region in CRS libraries like https://epsg.io/. However, you must check if the projected coordinates match their real location, e.g. using mapview().\n\n1.2.3 Why different projections?\nBy now, (most) people agree that the earth is not flat. So, to plot data on a 2D planar surface and to perform certain operations on a planar world, we need to make some re-projections. Depending on where we are, different re-projections of our data (globe in this case) might work better than others.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nclass(world)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(world)\n\nCoordinate Reference System:\n  User input: +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \n  wkt:\nBOUNDCRS[\n    SOURCECRS[\n        GEOGCRS[\"unknown\",\n            DATUM[\"World Geodetic System 1984\",\n                ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                    LENGTHUNIT[\"metre\",1]],\n                ID[\"EPSG\",6326]],\n            PRIMEM[\"Greenwich\",0,\n                ANGLEUNIT[\"degree\",0.0174532925199433],\n                ID[\"EPSG\",8901]],\n            CS[ellipsoidal,2],\n                AXIS[\"longitude\",east,\n                    ORDER[1],\n                    ANGLEUNIT[\"degree\",0.0174532925199433,\n                        ID[\"EPSG\",9122]]],\n                AXIS[\"latitude\",north,\n                    ORDER[2],\n                    ANGLEUNIT[\"degree\",0.0174532925199433,\n                        ID[\"EPSG\",9122]]]]],\n    TARGETCRS[\n        GEOGCRS[\"WGS 84\",\n            DATUM[\"World Geodetic System 1984\",\n                ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                    LENGTHUNIT[\"metre\",1]]],\n            PRIMEM[\"Greenwich\",0,\n                ANGLEUNIT[\"degree\",0.0174532925199433]],\n            CS[ellipsoidal,2],\n                AXIS[\"latitude\",north,\n                    ORDER[1],\n                    ANGLEUNIT[\"degree\",0.0174532925199433]],\n                AXIS[\"longitude\",east,\n                    ORDER[2],\n                    ANGLEUNIT[\"degree\",0.0174532925199433]],\n            ID[\"EPSG\",4326]]],\n    ABRIDGEDTRANSFORMATION[\"Transformation from unknown to WGS84\",\n        METHOD[\"Geocentric translations (geog2D domain)\",\n            ID[\"EPSG\",9603]],\n        PARAMETER[\"X-axis translation\",0,\n            ID[\"EPSG\",8605]],\n        PARAMETER[\"Y-axis translation\",0,\n            ID[\"EPSG\",8606]],\n        PARAMETER[\"Z-axis translation\",0,\n            ID[\"EPSG\",8607]]]]\n\n# Extract a country and plot in current CRS (WGS84)\nger.spdf &lt;- world[world$name == \"Germany\", ]\nplot(st_geometry(ger.spdf))\n\n\n\n# Now, let's transform Germany into a CRS optimized for Iceland\nger_rep.spdf &lt;- st_transform(ger.spdf, crs = 5325)\nplot(st_geometry(ger_rep.spdf))\n\n\n\n\nDepending on the angle, a 2D projection of the earth looks different. It is important to choose a suitable projection for the available spatial data. For more information on CRS and re-projection, see e.g. Lovelace, Nowosad, and Muenchow (2019) or Stefan Jünger & Anne-Kathrin Stroppe’s GESIS workshop materials."
  },
  {
    "objectID": "01_refresher_short.html#importing-some-real-world-data",
    "href": "01_refresher_short.html#importing-some-real-world-data",
    "title": "\n1  Refresher\n",
    "section": "\n1.3 Importing some real world data",
    "text": "1.3 Importing some real world data\nsf imports many of the most common spatial data files, like geojson, gpkg, or shp.\n\n1.3.1 London shapefile (polygon)\nLet’s get some administrative boundaries for London from the London Datastore. We use the sf package and its funtion st_read() to import the data.\n\n# Create subdir (all data withh be stored in \"_data\")\ndn &lt;- \"_data\"\nifelse(dir.exists(dn), \"Exists\", dir.create(dn))\n\n[1] \"Exists\"\n\n# Download zip file and unzip\ntmpf &lt;- tempfile()\nboundary.link &lt;- \"https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip\"\ndownload.file(boundary.link, tmpf)\nunzip(zipfile = tmpf, exdir = paste0(dn))\nunlink(tmpf)\n\n# This is a shapefile\n# We only need the MSOA layer for now\nmsoa.spdf &lt;- st_read(dsn = paste0(dn, \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"MSOA_2011_London_gen_MHW\" # Note: no file ending\n                     )\n\nReading layer `MSOA_2011_London_gen_MHW' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\statistical-gis-boundaries-london\\ESRI' \n  using driver `ESRI Shapefile'\nSimple feature collection with 983 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n\nThe object msoa.spdf is our spatial data.frame. It looks essentially like a conventional data.frame, but has some additional attributes and geo-graphical information stored with it. Most importantly, notice the column geometry, which contains a list of polygons. In most cases, we have one polygon for each line / observation.\n\nhead(msoa.spdf)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 530966.7 ymin: 180510.7 xmax: 551943.8 ymax: 191139\nProjected CRS: OSGB36 / British National Grid\n   MSOA11CD                 MSOA11NM   LAD11CD              LAD11NM\n1 E02000001       City of London 001 E09000001       City of London\n2 E02000002 Barking and Dagenham 001 E09000002 Barking and Dagenham\n3 E02000003 Barking and Dagenham 002 E09000002 Barking and Dagenham\n4 E02000004 Barking and Dagenham 003 E09000002 Barking and Dagenham\n5 E02000005 Barking and Dagenham 004 E09000002 Barking and Dagenham\n6 E02000007 Barking and Dagenham 006 E09000002 Barking and Dagenham\n    RGN11CD RGN11NM USUALRES HHOLDRES COMESTRES POPDEN HHOLDS\n1 E12000007  London     7375     7187       188   25.5   4385\n2 E12000007  London     6775     6724        51   31.3   2713\n3 E12000007  London    10045    10033        12   46.9   3834\n4 E12000007  London     6182     5937       245   24.8   2318\n5 E12000007  London     8562     8562         0   72.1   3183\n6 E12000007  London     8791     8672       119   50.6   3441\n  AVHHOLDSZ                       geometry\n1       1.6 MULTIPOLYGON (((531667.6 18...\n2       2.5 MULTIPOLYGON (((548881.6 19...\n3       2.6 MULTIPOLYGON (((549102.4 18...\n4       2.6 MULTIPOLYGON (((551550 1873...\n5       2.7 MULTIPOLYGON (((549099.6 18...\n6       2.5 MULTIPOLYGON (((549819.9 18...\n\n\nShapefiles are still among the most common formats to store and transmit spatial data, despite them being inefficient (file size and file number).\nHowever, sf reads everything spatial, such as geo.json, which usually is more efficient, but less common (but we’re getting there).\n\n# Download file\nulez.link &lt;- \"https://data.london.gov.uk/download/ultra_low_emissions_zone/936d71d8-c5fc-40ad-a392-6bec86413b48/CentralUltraLowEmissionZone.geojson\"\ndownload.file(ulez.link, paste0(dn, \"/ulez.json\"))\n\n# Read geo.json\nst_layers(paste0(dn, \"/ulez.json\"))\n\nDriver: GeoJSON \nAvailable layers:\n                   layer_name geometry_type features fields\n1 CentralUltraLowEmissionZone Multi Polygon        1      4\n                        crs_name\n1 OSGB36 / British National Grid\n\nulez.spdf &lt;- st_read(dsn = paste0(dn, \"/ulez.json\")) # here dsn is simply the file\n\nReading layer `CentralUltraLowEmissionZone' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\ulez.json' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 527271.5 ymin: 178041.5 xmax: 533866.3 ymax: 183133.4\nProjected CRS: OSGB36 / British National Grid\n\nhead(ulez.spdf)\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 527271.5 ymin: 178041.5 xmax: 533866.3 ymax: 183133.4\nProjected CRS: OSGB36 / British National Grid\n  fid OBJECTID BOUNDARY Shape_Area                       geometry\n1   1        1 CSS Area   21.37557 MULTIPOLYGON (((531562.7 18...\n\n\nAgain, this looks like a conventional data.frame but has the additional column geometry containing the coordinates of each observation. st_geometry() returns only the geographic object and st_drop_geometry() only the data.frame without the coordinates. We can plot the object using mapview().\n\nmapview(msoa.spdf[, \"POPDEN\"])\n\n\n\n\n\n\n\n1.3.2 Census API (admin units)\nNow that we have some boundaries and shapes of spatial units in London, we can start looking for different data sources to populate the geometries.\nA good source for demographic data is for instance the 2011 census. Below we use the nomis API to retrieve population data for London, See the Vignette for more information (Guest users are limited to 25,000 rows per query). Below is a wrapper to avoid some errors with sex and urban-rural cross-tabulation in some of the data.\n\n### For larger request, register and set key\n# Sys.setenv(NOMIS_API_KEY = \"XXX\")\n# nomis_api_key(check_env = TRUE)\n\nx &lt;- nomis_data_info()\n\n# Get London ids\nlondon_ids &lt;- msoa.spdf$MSOA11CD\n\n### Get key statistics ids\n# select requires tables (https://www.nomisweb.co.uk/sources/census_2011_ks)\n# Let's get KS201EW (ethnic group), KS205EW (passport held), and KS402EW (housing tenure)\n\n# Get internal ids\nstats &lt;- c(\"KS201EW\", \"KS402EW\", \"KS205EW\")\noo &lt;- which(grepl(paste(stats, collapse = \"|\"), x$name.value))\nksids &lt;- x$id[oo]\nksids # This are the internal ids\n\n[1] \"NM_608_1\" \"NM_612_1\" \"NM_619_1\"\n\n### look at meta information\nq &lt;- nomis_overview(ksids[1])\nhead(q)\n\n# A tibble: 6 × 2\n  name           value           \n  &lt;chr&gt;          &lt;list&gt;          \n1 analyses       &lt;named list [1]&gt;\n2 analysisname   &lt;chr [1]&gt;       \n3 analysisnumber &lt;int [1]&gt;       \n4 contact        &lt;named list [4]&gt;\n5 contenttypes   &lt;named list [1]&gt;\n6 coverage       &lt;chr [1]&gt;       \n\na &lt;- nomis_get_metadata(id = ksids[1], concept = \"GEOGRAPHY\", type = \"type\")\na # TYPE297 is MSOA level\n\n# A tibble: 24 × 3\n   id      label.en                                   description.en\n   &lt;chr&gt;   &lt;chr&gt;                                      &lt;chr&gt;         \n 1 TYPE265 NHS area teams                             NHS area teams\n 2 TYPE266 clinical commissioning groups              clinical comm…\n 3 TYPE267 built-up areas including subdivisions      built-up area…\n 4 TYPE269 built-up areas                             built-up areas\n 5 TYPE273 national assembly for wales electoral reg… national asse…\n 6 TYPE274 postcode areas                             postcode areas\n 7 TYPE275 postcode districts                         postcode dist…\n 8 TYPE276 postcode sectors                           postcode sect…\n 9 TYPE277 national assembly for wales constituencie… national asse…\n10 TYPE279 parishes 2011                              parishes 2011 \n# ℹ 14 more rows\n\nb &lt;- nomis_get_metadata(id = ksids[1], concept = \"MEASURES\", type = \"TYPE297\")\nb # 20100 is the measure of absolute numbers\n\n# A tibble: 2 × 3\n  id    label.en description.en\n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         \n1 20100 value    value         \n2 20301 percent  percent       \n\n### Query data in loop over the required statistics\nfor(i in ksids){\n\n  # Determin if data is divided by sex or urban-rural\n  nd &lt;- nomis_get_metadata(id = i)\n  if(\"RURAL_URBAN\" %in% nd$conceptref){\n    UR &lt;- TRUE\n  }else{\n    UR &lt;- FALSE\n  }\n  if(\"C_SEX\" %in% nd$conceptref){\n    SEX &lt;- TRUE\n  }else{\n    SEX &lt;- FALSE\n  }\n\n  # make data request\n  if(UR == TRUE){\n    if(SEX == TRUE){\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, RURAL_URBAN = 0, C_SEX = 0)\n    }else{\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, RURAL_URBAN = 0)\n    }\n  }else{\n    if(SEX == TRUE){\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100, C_SEX = 0)\n    }else{\n      tmp_en &lt;- nomis_get_data(id = i, time = \"2011\",\n                               geography = london_ids, # replace with \"TYPE297\" for all MSOAs\n                               measures = 20100)\n    }\n\n  }\n\n  # Append (in case of different regions)\n  ks_tmp &lt;- tmp_en\n\n  # Make lower case names\n  names(ks_tmp) &lt;- tolower(names(ks_tmp))\n  names(ks_tmp)[names(ks_tmp) == \"geography_code\"] &lt;- \"msoa11\"\n  names(ks_tmp)[names(ks_tmp) == \"geography_name\"] &lt;- \"name\"\n\n  # replace weird cell codes\n  onlynum &lt;- which(grepl(\"^[[:digit:]]+$\", ks_tmp$cell_code))\n  if(length(onlynum) != 0){\n    code &lt;- substr(ks_tmp$cell_code[-onlynum][1], 1, 7)\n    if(is.na(code)){\n      code &lt;- i\n    }\n    ks_tmp$cell_code[onlynum] &lt;- paste0(code, \"_\", ks_tmp$cell_code[onlynum])\n  }\n\n  # save codebook\n  ks_cb &lt;- unique(ks_tmp[, c(\"date\", \"cell_type\", \"cell\", \"cell_code\", \"cell_name\")])\n\n  ### Reshape\n  ks_res &lt;- tidyr::pivot_wider(ks_tmp, id_cols = c(\"msoa11\", \"name\"),\n                               names_from = \"cell_code\",\n                               values_from = \"obs_value\")\n\n  ### Merge\n  if(i == ksids[1]){\n    census_keystat.df &lt;- ks_res\n    census_keystat_cb.df &lt;- ks_cb\n  }else{\n    census_keystat.df &lt;- merge(census_keystat.df, ks_res, by = c(\"msoa11\", \"name\"), all = TRUE)\n    census_keystat_cb.df &lt;- rbind(census_keystat_cb.df, ks_cb)\n  }\n\n}\n\n\n# Descriptions are saved in the codebook\nhead(census_keystat_cb.df)\n\n# A tibble: 6 × 5\n   date cell_type     cell cell_code   cell_name                    \n  &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;                        \n1  2011 Ethnic Group     0 KS201EW0001 All usual residents          \n2  2011 Ethnic Group   100 KS201EW_100 White                        \n3  2011 Ethnic Group     1 KS201EW0002 White: English/Welsh/Scottis…\n4  2011 Ethnic Group     2 KS201EW0003 White: Irish                 \n5  2011 Ethnic Group     3 KS201EW0004 White: Gypsy or Irish Travel…\n6  2011 Ethnic Group     4 KS201EW0005 White: Other White           \n\nsave(census_keystat_cb.df, file = \"_data/Census_codebook.RData\")\n\nNow, we have one file containing the geometries of MSOAs and one file with the census information on ethnic groups. Obviously, we can easily merge them together using the MSOA identifiers.\n\nmsoa.spdf &lt;- merge(msoa.spdf, census_keystat.df,\n                   by.x = \"MSOA11CD\", by.y = \"msoa11\", all.x = TRUE)\n\nAnd we can, for instance, plot the spatial distribution of ethnic groups.\n\nmsoa.spdf$per_white &lt;- msoa.spdf$KS201EW_100 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_mixed &lt;- msoa.spdf$KS201EW_200 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_asian &lt;- msoa.spdf$KS201EW_300 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_black &lt;- msoa.spdf$KS201EW_400 / msoa.spdf$KS201EW0001 * 100\nmsoa.spdf$per_other &lt;- msoa.spdf$KS201EW_500 / msoa.spdf$KS201EW0001 * 100\n\nmapview(msoa.spdf[, \"per_white\"])\n\n\n\n\n\n\nIf you’re interested in more data sources, see for instance APIs for social scientists: A collaborative review by Paul C. Bauer, Camille Landesvatter, Lion Behrens. It’s a collection of several APIs for social sciences.\n\n1.3.3 Gridded data\nSo far, we have queried data on administrative units. However, often data comes on other spatial scales. For instance, we might be interested in the amount of air pollution, which is provided on a regular grid across the UK from Defra.\n\n# Download\npol.link &lt;- \"https://uk-air.defra.gov.uk/datastore/pcm/mapno22011.csv\"\ndownload.file(pol.link, paste0(dn, \"/mapno22011.csv\"))\npol.df &lt;- read.csv(paste0(dn, \"/mapno22011.csv\"), skip = 5, header = T, sep = \",\",\n                      stringsAsFactors = F, na.strings = \"MISSING\")\n\nhead(pol.df)\n\n  ukgridcode      x       y no22011\n1      54291 460500 1221500      NA\n2      54292 461500 1221500      NA\n3      54294 463500 1221500      NA\n4      54979 458500 1220500      NA\n5      54980 459500 1220500      NA\n6      54981 460500 1220500      NA\n\n\nThe data comes as point data with x and y as coordinates. We have to transform this into spatial data first. We first setup a spatial points object with st_as_sf. Subsequently, we transform the point coordinates into a regular grid. We use a buffer method st_buffer with “diameter”, and only one segment per quadrant (nQuadSegs). This gives us a 1x1km regular grid.\n\n# Build spatial object\npol.spdf &lt;- st_as_sf(pol.df, coords = c(\"x\", \"y\"),\n                    crs = 27700)\n\n# we transform the point coordinates into a regular grid with \"diameter\" 500m\npol.spdf &lt;- st_buffer(pol.spdf, dist = 500, nQuadSegs  = 1,\n                      endCapStyle = 'SQUARE')\n\n# Plot NO2\nplot(pol.spdf[, \"no22011\"], border = NA)\n\n\n\n\n\n1.3.4 OpenStreetMap (points)\nAnother interesting data source is the OpenStreetMap API, which provides information about the geographical location of a serious of different indicators. Robin Lovelace provides a nice introduction to the osmdata API. Available features can be found on OSM wiki.\nFirst we create a bounding box of where we want to query data. st_bbox() can be used to get bounding boxes of an existing spatial object (needs CRS = 4326). An alternative would be to use opq(bbox = 'greater london uk').\n\n# bounding box of where we want to query data\nq &lt;- opq(bbox = st_bbox(st_transform(msoa.spdf, 4326)))\n\nAnd we want to get data for all pubs and bars which are within this bounding box.\n\n# First build the query of location of pubs in London\nosmq &lt;- add_osm_feature(q, key = \"amenity\", value = \"pub\")\n\n# And then query the data\npubs.osm &lt;- osmdata_sf(osmq)\n\nRight now there are some results in polygons, some in points, and they overlap. Often, data from OSM needs some manual cleaning. Sometimes the same features are represented by different spatial objects (e.g. points + polygons).\n\n# Make unique points / polygons\npubs.osm &lt;- unique_osmdata(pubs.osm)\n\n# Get points and polygons (there are barley any pubs as polygons, so we ignore them)\npubs.points &lt;- pubs.osm$osm_points\npubs.polys &lt;- pubs.osm$osm_multipolygons\n\n# # Drop OSM file\n# rm(pubs.osm); gc()\n\n# Reduce to point object only\npubs.spdf &lt;- pubs.points\n\n# Reduce to a few variables\npubs.spdf &lt;- pubs.spdf[, c(\"osm_id\", \"name\", \"addr:postcode\", \"diet:vegan\")]\n\nAgain, we can inspect the results with mapview.\n\nmapview(st_geometry(pubs.spdf))\n\n\n\n\n\nNote that OSM is solely based on contribution by users, and the quality of OSM data varies. Usually data quality is better in larger cities, and better for more stable features (such as hospitals, train stations, highways) rahter than pubs or restaurants which regularly appear and disappear. However, data from London Datastore would indicate more pubs than what we find with OSM.\n\n1.3.5 Save\nWe will store the created data to use them again in the next session.\n\nsave(msoa.spdf, file = \"_data/msoa_spatial.RData\")\nsave(ulez.spdf, file = \"_data/ulez_spatial.RData\")\nsave(pol.spdf, file = \"_data/pollution_spatial.RData\")\nsave(pubs.spdf, file = \"_data/pubs_spatial.RData\")"
  },
  {
    "objectID": "01_refresher_short.html#data-manipulation",
    "href": "01_refresher_short.html#data-manipulation",
    "title": "\n1  Refresher\n",
    "section": "\n1.4 Data Manipulation",
    "text": "1.4 Data Manipulation\nRequired packages\n\npkgs &lt;- c(\"sf\", \"gstat\", \"mapview\", \"nngeo\", \"rnaturalearth\", \"dplyr\",\n          \"nomisr\", \"osmdata\", \"tidyr\", \"texreg\", \"downlit\", \"xml2\") \nlapply(pkgs, require, character.only = TRUE)\n\nHaving data with geo-spatial information allows to perform a variety of methods to manipulate and link different data sources. Commonly used methods include 1) subsetting, 2) point-in-polygon operations, 3) distance measures, 4) intersections or buffer methods.\nThe online Vignettes of the sf package provide a comprehensive overview of the multiple ways of spatial manipulations.\nCheck if data is on common projection\n\nst_crs(msoa.spdf) == st_crs(pol.spdf)\n\n[1] FALSE\n\nst_crs(msoa.spdf) == st_crs(pubs.spdf)\n\n[1] FALSE\n\nst_crs(msoa.spdf) == st_crs(ulez.spdf)\n\n[1] FALSE\n\n\nThe spatial data files are on different projections. Before we can do any spatial operations with them, we have to transform them into a common projection.\n\n# MSOA in different crs --&gt; transform\npol.spdf &lt;- st_transform(pol.spdf, crs = st_crs(msoa.spdf))\npubs.spdf &lt;- st_transform(pubs.spdf, crs = st_crs(msoa.spdf))\nulez.spdf &lt;- st_transform(ulez.spdf, crs = st_crs(msoa.spdf))\n\n\n# Check if all geometries are valid, and make valid if needed\nmsoa.spdf &lt;- st_make_valid(msoa.spdf)\n\nThe st_make_valid() can help if the spatial geometries have some problems such as holes or points that don’t match exactly.\n\n1.4.1 Subsetting\nWe can subset spatial data in a similar way as we subset conventional data.frames or matrices. For instance, below we simply reduce the pollution grid across the UK to observations in London only.\n\n# Subset to pollution estimates in London\npol_sub.spdf &lt;- pol.spdf[msoa.spdf, ] # or:\npol_sub.spdf &lt;- st_filter(pol.spdf, msoa.spdf)\nmapview(pol_sub.spdf)\n\n\n\n\n\n\nOr we can reverse the above and exclude all intersecting units by specifying st_disjoint as alternative spatial operation using the op = option (note the empty space for column selection). st_filter() with the .predicate option does the same job. See the sf Vignette for more operations.\n\n# Subset pubs to pubs not in the ulez area\nsub2.spdf &lt;- pubs.spdf[ulez.spdf, , op = st_disjoint] # or:\nsub2.spdf &lt;- st_filter(pubs.spdf, ulez.spdf, .predicate = st_disjoint)\nmapview(sub2.spdf)\n\n\n\n\n\n\nWe can easily create indicators of whether an MSOA is within ulez or not.\n\nmsoa.spdf$ulez &lt;- 0\n\n# intersecting lsoas\nwithin &lt;- msoa.spdf[ulez.spdf,]\n\n# use their ids to create binary indicator \nmsoa.spdf$ulez[which(msoa.spdf$MSOA11CD %in% within$MSOA11CD)] &lt;- 1\ntable(msoa.spdf$ulez)\n\n\n  0   1 \n955  28 \n\n\n\n1.4.2 Point in polygon\nWe are interested in the number of pubs in each MSOA. So, we count the number of points in each polygon.\n\n# Assign MSOA to each point\npubs_msoa.join &lt;- st_join(pubs.spdf, msoa.spdf, join = st_within)\n\n# Count N by MSOA code (drop geometry to speed up)\npubs_msoa.join &lt;- dplyr::count(st_drop_geometry(pubs_msoa.join),\n                               MSOA11CD = pubs_msoa.join$MSOA11CD,\n                               name = \"pubs_count\")\nsum(pubs_msoa.join$pubs_count)\n\n[1] 1601\n\n# Merge and replace NAs with zero (no matches, no pubs)\nmsoa.spdf &lt;- merge(msoa.spdf, pubs_msoa.join,\n                   by = \"MSOA11CD\", all.x = TRUE)\nmsoa.spdf$pubs_count[is.na(msoa.spdf$pubs_count)] &lt;- 0\n\n\n1.4.3 Distance measures\nWe might be interested in the distance to the nearest pub. Here, we use the package nngeo to find k nearest neighbours with the respective distance.\n\n# Use geometric centroid of each MSOA\ncent.sp &lt;- st_centroid(msoa.spdf[, \"MSOA11CD\"])\n\nWarning: st_centroid assumes attributes are constant over\ngeometries\n\n# Get K nearest neighbour with distance\nknb.dist &lt;- st_nn(cent.sp, \n                  pubs.spdf,\n                  k = 1,             # number of nearest neighbours\n                  returnDist = TRUE, # we also want the distance\n                  progress = FALSE)\n\nprojected points\n\nmsoa.spdf$dist_pubs &lt;- unlist(knb.dist$dist)\nsummary(msoa.spdf$dist_pubs)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   9.079  305.149  565.018  701.961  948.047 3735.478 \n\n\n\n1.4.4 Intersections + Buffers\nWe may also want the average pollution within 1 km radius around each MSOA centroid. Note that it is usually better to use a ego-centric method where you calculate the average within a distance rather than using the characteristic of the intersecting cells only (Lee et al. 2008; Mohai and Saha 2007).\nTherefore, we first create a buffer with st_buffer() around each midpoint and subsequently use st_intersetion() to calculate the overlap.\n\n# Create buffer (1km radius)\ncent.buf &lt;- st_buffer(cent.sp, \n                      dist = 1000) # dist in meters\nmapview(cent.buf)\n\n\n\n\n\n# Add area of each buffer (in this constant) \ncent.buf$area &lt;- as.numeric(st_area(cent.buf))\n\n# Calculate intersection of pollution grid and buffer\nint.df &lt;- st_intersection(cent.buf, pol.spdf)\n\nWarning: attribute variables are assumed to be spatially constant\nthroughout all geometries\n\nint.df$int_area &lt;- as.numeric(st_area(int.df)) # area of intersection\n\n# Area of intersection as share of buffer\nint.df$area_per &lt;- int.df$int_area / int.df$area\n\nAnd we use the percent overalp areas as the weights to calculate a weighted mean.\n\n# Aggregate as weighted mean\nint.df &lt;- st_drop_geometry(int.df)\nint.df$no2_weighted &lt;- int.df$no22011 * int.df$area_per\nint.df &lt;- aggregate(list(no2 = int.df[, \"no2_weighted\"]), \n                    by = list(MSOA11CD = int.df$MSOA11CD),\n                    sum)\n\n# Merge back to spatial data.frame\nmsoa.spdf &lt;- merge(msoa.spdf, int.df, by = \"MSOA11CD\", all.x = TRUE)\n\nmapview(msoa.spdf[, \"no2\"])\n\n\n\n\n\n\nNote: for buffer related methods, it often makes sense to use population weighted centroids instead of geographic centroids (see here for MSOA population weighted centroids). However, often this information is not available.\n\n1.4.5 and more\nThere are more spatial operation possible using sf. Have a look at the sf Cheatsheet."
  },
  {
    "objectID": "01_refresher_short.html#data-visualisation",
    "href": "01_refresher_short.html#data-visualisation",
    "title": "\n1  Refresher\n",
    "section": "\n1.5 Data visualisation",
    "text": "1.5 Data visualisation\nFor mapping\n\npkgs &lt;- c(\"tmap\", \"tmaptools\", \"viridisLite\", \n          \"ggplot2\", \"ggthemes\", \"rmapshaper\") \nlapply(pkgs, require, character.only = TRUE)\n\nA large advantage of spatial data is that different data sources can be connected and combined. Another nice advantage is: you can create very nice maps. And it’s quite easy to do! Stefan Jünger & Anne-Kathrin Stroppe provide more comprehensive materials on mapping in their GESIS workshop on geospatial techniques in R.\nMany packages and functions can be used to plot maps of spatial data. For instance, ggplot as a function to plot spatial data using geom_sf(). I am personally a fan of tmap, which makes many steps easier (but sometimes is less flexible).\nA great tool for choosing coulour is for instance Colorbrewer. viridisLite provides another great resource to chose colours.\n\n1.5.1 Tmaps\nFor instance, lets plot the NO2 estimates using tmap + tm_fill() (there are lots of alternatives like tm_shape, tm_points(), tm_dots()).\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"no2\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 7, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"NO2\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) \n\nmp1\n\n\n\n\nTmap allows to easily combine different objects by defining a new object via tm_shape().\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"no2\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 7, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = \"NO2\", \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_shape(ulez.spdf) +\n  tm_borders(col = \"red\", lwd = 1, alpha = 1) \n\nmp1\n\n\n\n\nAnd it is easy to change the layout.\n\n# Define colours\ncols &lt;- viridis(n = 7, direction = 1, option = \"C\")\n\nmp1 &lt;-  tm_shape(msoa.spdf) + \n  tm_fill(col = \"no2\", \n          style = \"fisher\", # algorithm to def cut points\n          n = 7, # Number of requested cut points\n          palette = cols, # colours\n          alpha = 1, # transparency \n          title = expression('in'~mu*'g'/m^{3}), \n          legend.hist = FALSE # histogram next to map?\n          ) +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\n  tm_shape(ulez.spdf) +\n  tm_borders(col = \"red\", lwd = 1, alpha = 1) +\n  tm_layout(frame = FALSE,\n            legend.frame = TRUE, legend.bg.color = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.outside = FALSE,\n            main.title = \"NO2\", \n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.title.size = 0.8,\n            legend.text.size = 0.8)\n\nmp1\n\n\n\n\n\n1.5.2 ggplot\nFor those of you have rather stick with the basic ggplot package, we can also use ggplot for spatial maps.\n\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = no2))+\n    scale_fill_viridis_c(option = \"B\")+\n    coord_sf(datum = NA)+\n    theme_map()+\n    theme(legend.position = c(.9, .6))\ngp\n\n\n\n\n\n# Get some larger scale boundaries\nborough.spdf &lt;- st_read(dsn = paste0(\"_data\", \"/statistical-gis-boundaries-london/ESRI\"),\n                     layer = \"London_Borough_Excluding_MHW\" # Note: no file ending\n                     )\n\nReading layer `London_Borough_Excluding_MHW' from data source \n  `C:\\work\\Lehre\\Geodata_Spatial_Regression_short\\_data\\statistical-gis-boundaries-london\\ESRI' \n  using driver `ESRI Shapefile'\nSimple feature collection with 33 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n# transform to only inner lines\nborough_inner &lt;- ms_innerlines(borough.spdf)\n\n# Plot with inner lines\ngp &lt;- ggplot(msoa.spdf)+\n    geom_sf(aes(fill = no2), color = NA)+\n    scale_fill_viridis_c(option = \"A\")+\n    geom_sf(data = borough_inner, color = \"gray92\")+\n    geom_sf(data = ulez.spdf, color = \"red\", fill = NA)+\n    coord_sf(datum = NA)+\n    theme_map()+\n    labs(fill = \"NO2\")+\n    theme(legend.position = c(.9, .6))\ngp"
  },
  {
    "objectID": "01_refresher_short.html#exercise",
    "href": "01_refresher_short.html#exercise",
    "title": "\n1  Refresher\n",
    "section": "\n1.6 Exercise",
    "text": "1.6 Exercise\n\nWhat is the difference between a spatial “sf” object and a conventional “data.frame”? What’s the purpose of the function st_drop_geometry()?\nUsing msoa.spdf, please create a spatial data frame that contains only the MSOA areas that are within the ulez zone.\nPlease create a map for London (or only the msoa-ulez subset) which shows the share of Asian residents (or any other ethnic group).\nPlease calculate the distance of each MSOA to the London city centre\n\n\nuse google maps to get lon and lat,\nus st_as_sf() to create the spatial point\nuse st_distance() to calculate the distance\n\n\nCan you create a plot with the distance to the city centre and pub counts next to each other?"
  },
  {
    "objectID": "01_refresher_short.html#references",
    "href": "01_refresher_short.html#references",
    "title": "\n1  Refresher\n",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nLee, Barrett A., Sean F. Reardon, Glenn Firebaugh, Chad R. Farrell, Stephen A. Matthews, and David O’Sullivan. 2008. “Beyond the Census Tract: Patterns and Determinants of Racial Segregation at Multiple Geographic Scales.” American Sociological Review 73 (5): 766–91. https://doi.org/10.1177/000312240807300504.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. Chapman & Hall/CRC the R Series. Boca Raton: Chapman & Hall/CRC.\n\n\nMohai, Paul, and Robin Saha. 2007. “Racial Inequality in the Distribution of Hazardous Waste: A National-Level Reassessment.” Social Problems 54 (3): 343–70. https://doi.org/10.1525/sp.2007.54.3.343."
  }
]